{"version":3,"sources":["../../../src/generated/gaussian_process/GaussianProcessClassifier.ts","../../../src/generated/gaussian_process/GaussianProcessRegressor.ts","../../../src/generated/gaussian_process/kernels/CompoundKernel.ts","../../../src/generated/gaussian_process/kernels/ConstantKernel.ts","../../../src/generated/gaussian_process/kernels/DotProduct.ts","../../../src/generated/gaussian_process/kernels/Exponentiation.ts","../../../src/generated/gaussian_process/kernels/ExpSineSquared.ts","../../../src/generated/gaussian_process/kernels/Hyperparameter.ts","../../../src/generated/gaussian_process/kernels/Kernel.ts","../../../src/generated/gaussian_process/kernels/Matern.ts","../../../src/generated/gaussian_process/kernels/PairwiseKernel.ts","../../../src/generated/gaussian_process/kernels/Product.ts","../../../src/generated/gaussian_process/kernels/RationalQuadratic.ts","../../../src/generated/gaussian_process/kernels/RBF.ts","../../../src/generated/gaussian_process/kernels/Sum.ts","../../../src/generated/gaussian_process/kernels/WhiteKernel.ts"],"sourcesContent":["/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Gaussian process classification (GPC) based on Laplace approximation.\n\n  The implementation is based on Algorithm 3.1, 3.2, and 5.1 from [\\[RW2006\\]](#r2da648a61a73-rw2006).\n\n  Internally, the Laplace approximation is used for approximating the non-Gaussian posterior by a Gaussian.\n\n  Currently, the implementation is restricted to using the logistic link function. For multi-class classification, several binary one-versus rest classifiers are fitted. Note that this class thus does not implement a true multi-class Laplace approximation.\n\n  Read more in the [User Guide](../gaussian_process.html#gaussian-process).\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html)\n */\nexport class GaussianProcessClassifier {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The kernel specifying the covariance function of the GP. If `undefined` is passed, the kernel “1.0 \\* RBF(1.0)” is used as default. Note that the kernel’s hyperparameters are optimized during fitting. Also kernel cannot be a `CompoundKernel`.\n     */\n    kernel?: any\n\n    /**\n      Can either be one of the internally supported optimizers for optimizing the kernel’s parameters, specified by a string, or an externally defined optimizer passed as a callable. If a callable is passed, it must have the signature:\n\n      @defaultValue `'fmin_l_bfgs_b'`\n     */\n    optimizer?: 'fmin_l_bfgs_b'\n\n    /**\n      The number of restarts of the optimizer for finding the kernel’s parameters which maximize the log-marginal likelihood. The first run of the optimizer is performed from the kernel’s initial parameters, the remaining ones (if any) from thetas sampled log-uniform randomly from the space of allowed theta-values. If greater than 0, all bounds must be finite. Note that n\\_restarts\\_optimizer=0 implies that one run is performed.\n\n      @defaultValue `0`\n     */\n    n_restarts_optimizer?: number\n\n    /**\n      The maximum number of iterations in Newton’s method for approximating the posterior during predict. Smaller values will reduce computation time at the cost of worse results.\n\n      @defaultValue `100`\n     */\n    max_iter_predict?: number\n\n    /**\n      If warm-starts are enabled, the solution of the last Newton iteration on the Laplace approximation of the posterior mode is used as initialization for the next call of \\_posterior\\_mode(). This can speed up convergence when \\_posterior\\_mode is called several times on similar problems as in hyperparameter optimization. See [the Glossary](../../glossary.html#term-warm_start).\n\n      @defaultValue `false`\n     */\n    warm_start?: boolean\n\n    /**\n      If `true`, a persistent copy of the training data is stored in the object. Otherwise, just a reference to the training data is stored, which might cause predictions to change if the data is modified externally.\n\n      @defaultValue `true`\n     */\n    copy_X_train?: boolean\n\n    /**\n      Determines random number generation used to initialize the centers. Pass an int for reproducible results across multiple function calls. See [Glossary](../../glossary.html#term-random_state).\n     */\n    random_state?: number\n\n    /**\n      Specifies how multi-class classification problems are handled. Supported are ‘one\\_vs\\_rest’ and ‘one\\_vs\\_one’. In ‘one\\_vs\\_rest’, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In ‘one\\_vs\\_one’, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. Note that ‘one\\_vs\\_one’ does not support predicting probability estimates.\n\n      @defaultValue `'one_vs_rest'`\n     */\n    multi_class?: 'one_vs_rest' | 'one_vs_one'\n\n    /**\n      The number of jobs to use for the computation: the specified multiclass problems are computed in parallel. `undefined` means 1 unless in a [`joblib.parallel\\_backend`](https://joblib.readthedocs.io/en/latest/generated/joblib.parallel_backend.html#joblib.parallel_backend \"(in joblib v1.4.dev0)\") context. `\\-1` means using all processors. See [Glossary](../../glossary.html#term-n_jobs) for more details.\n     */\n    n_jobs?: number\n  }) {\n    this.id = `GaussianProcessClassifier${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error(\n        'GaussianProcessClassifier.init requires a PythonBridge instance'\n      )\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process import GaussianProcessClassifier\ntry: bridgeGaussianProcessClassifier\nexcept NameError: bridgeGaussianProcessClassifier = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_GaussianProcessClassifier = {'kernel': ${\n      this.opts['kernel'] ?? undefined\n    }, 'optimizer': ${\n      this.opts['optimizer'] ?? undefined\n    }, 'n_restarts_optimizer': ${\n      this.opts['n_restarts_optimizer'] ?? undefined\n    }, 'max_iter_predict': ${\n      this.opts['max_iter_predict'] ?? undefined\n    }, 'warm_start': ${this.opts['warm_start'] ?? undefined}, 'copy_X_train': ${\n      this.opts['copy_X_train'] ?? undefined\n    }, 'random_state': ${\n      this.opts['random_state'] ?? undefined\n    }, 'multi_class': ${this.opts['multi_class'] ?? undefined}, 'n_jobs': ${\n      this.opts['n_jobs'] ?? undefined\n    }}\n\nctor_GaussianProcessClassifier = {k: v for k, v in ctor_GaussianProcessClassifier.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeGaussianProcessClassifier[${this.id}] = GaussianProcessClassifier(**ctor_GaussianProcessClassifier)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeGaussianProcessClassifier[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Fit Gaussian process classification model.\n   */\n  async fit(opts: {\n    /**\n      Feature vectors or other representations of training data.\n     */\n    X?: ArrayLike[]\n\n    /**\n      Target values, must be binary.\n     */\n    y?: ArrayLike\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('GaussianProcessClassifier must call init() before fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_GaussianProcessClassifier_fit = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None}\n\npms_GaussianProcessClassifier_fit = {k: v for k, v in pms_GaussianProcessClassifier_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessClassifier_fit = bridgeGaussianProcessClassifier[${this.id}].fit(**pms_GaussianProcessClassifier_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessClassifier_fit.tolist() if hasattr(res_GaussianProcessClassifier_fit, 'tolist') else res_GaussianProcessClassifier_fit`\n  }\n\n  /**\n    Get metadata routing of this object.\n\n    Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.\n   */\n  async get_metadata_routing(opts: {\n    /**\n      A [`MetadataRequest`](sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest \"sklearn.utils.metadata_routing.MetadataRequest\") encapsulating routing information.\n     */\n    routing?: any\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before get_metadata_routing()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_GaussianProcessClassifier_get_metadata_routing = {'routing': ${\n      opts['routing'] ?? undefined\n    }}\n\npms_GaussianProcessClassifier_get_metadata_routing = {k: v for k, v in pms_GaussianProcessClassifier_get_metadata_routing.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessClassifier_get_metadata_routing = bridgeGaussianProcessClassifier[${this.id}].get_metadata_routing(**pms_GaussianProcessClassifier_get_metadata_routing)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessClassifier_get_metadata_routing.tolist() if hasattr(res_GaussianProcessClassifier_get_metadata_routing, 'tolist') else res_GaussianProcessClassifier_get_metadata_routing`\n  }\n\n  /**\n    Return log-marginal likelihood of theta for training data.\n\n    In the case of multi-class classification, the mean log-marginal likelihood of the one-versus-rest classifiers are returned.\n   */\n  async log_marginal_likelihood(opts: {\n    /**\n      Kernel hyperparameters for which the log-marginal likelihood is evaluated. In the case of multi-class classification, theta may be the hyperparameters of the compound kernel or of an individual kernel. In the latter case, all individual kernel get assigned the same theta values. If `undefined`, the precomputed log\\_marginal\\_likelihood of `self.kernel\\_.theta` is returned.\n     */\n    theta?: ArrayLike\n\n    /**\n      If `true`, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. Note that gradient computation is not supported for non-binary classification. If `true`, theta must not be `undefined`.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n\n    /**\n      If `true`, the kernel attribute is copied. If `false`, the kernel attribute is modified, but may result in a performance improvement.\n\n      @defaultValue `true`\n     */\n    clone_kernel?: boolean\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before log_marginal_likelihood()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_GaussianProcessClassifier_log_marginal_likelihood = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }, 'clone_kernel': ${opts['clone_kernel'] ?? undefined}}\n\npms_GaussianProcessClassifier_log_marginal_likelihood = {k: v for k, v in pms_GaussianProcessClassifier_log_marginal_likelihood.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessClassifier_log_marginal_likelihood = bridgeGaussianProcessClassifier[${this.id}].log_marginal_likelihood(**pms_GaussianProcessClassifier_log_marginal_likelihood)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessClassifier_log_marginal_likelihood.tolist() if hasattr(res_GaussianProcessClassifier_log_marginal_likelihood, 'tolist') else res_GaussianProcessClassifier_log_marginal_likelihood`\n  }\n\n  /**\n    Perform classification on an array of test vectors X.\n   */\n  async predict(opts: {\n    /**\n      Query points where the GP is evaluated for classification.\n     */\n    X?: ArrayLike[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before predict()'\n      )\n    }\n\n    // set up method params\n    await this._py.ex`pms_GaussianProcessClassifier_predict = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_GaussianProcessClassifier_predict = {k: v for k, v in pms_GaussianProcessClassifier_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessClassifier_predict = bridgeGaussianProcessClassifier[${this.id}].predict(**pms_GaussianProcessClassifier_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessClassifier_predict.tolist() if hasattr(res_GaussianProcessClassifier_predict, 'tolist') else res_GaussianProcessClassifier_predict`\n  }\n\n  /**\n    Return probability estimates for the test vector X.\n   */\n  async predict_proba(opts: {\n    /**\n      Query points where the GP is evaluated for classification.\n     */\n    X?: ArrayLike[]\n  }): Promise<ArrayLike[]> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before predict_proba()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_GaussianProcessClassifier_predict_proba = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_GaussianProcessClassifier_predict_proba = {k: v for k, v in pms_GaussianProcessClassifier_predict_proba.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessClassifier_predict_proba = bridgeGaussianProcessClassifier[${this.id}].predict_proba(**pms_GaussianProcessClassifier_predict_proba)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessClassifier_predict_proba.tolist() if hasattr(res_GaussianProcessClassifier_predict_proba, 'tolist') else res_GaussianProcessClassifier_predict_proba`\n  }\n\n  /**\n    Return the mean accuracy on the given test data and labels.\n\n    In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.\n   */\n  async score(opts: {\n    /**\n      Test samples.\n     */\n    X?: ArrayLike[]\n\n    /**\n      True labels for `X`.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before score()'\n      )\n    }\n\n    // set up method params\n    await this._py.ex`pms_GaussianProcessClassifier_score = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_GaussianProcessClassifier_score = {k: v for k, v in pms_GaussianProcessClassifier_score.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessClassifier_score = bridgeGaussianProcessClassifier[${this.id}].score(**pms_GaussianProcessClassifier_score)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessClassifier_score.tolist() if hasattr(res_GaussianProcessClassifier_score, 'tolist') else res_GaussianProcessClassifier_score`\n  }\n\n  /**\n    Request metadata passed to the `score` method.\n\n    Note that this method is only relevant if `enable\\_metadata\\_routing=True` (see [`sklearn.set\\_config`](sklearn.set_config.html#sklearn.set_config \"sklearn.set_config\")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.\n\n    The options for each parameter are:\n   */\n  async set_score_request(opts: {\n    /**\n      Metadata routing for `sample\\_weight` parameter in `score`.\n     */\n    sample_weight?: string | boolean\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before set_score_request()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_GaussianProcessClassifier_set_score_request = {'sample_weight': ${\n      opts['sample_weight'] ?? undefined\n    }}\n\npms_GaussianProcessClassifier_set_score_request = {k: v for k, v in pms_GaussianProcessClassifier_set_score_request.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessClassifier_set_score_request = bridgeGaussianProcessClassifier[${this.id}].set_score_request(**pms_GaussianProcessClassifier_set_score_request)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessClassifier_set_score_request.tolist() if hasattr(res_GaussianProcessClassifier_set_score_request, 'tolist') else res_GaussianProcessClassifier_set_score_request`\n  }\n\n  /**\n    The estimator instance that defines the likelihood function using the observed data.\n   */\n  get base_estimator_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before accessing base_estimator_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessClassifier_base_estimator_ = bridgeGaussianProcessClassifier[${this.id}].base_estimator_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessClassifier_base_estimator_.tolist() if hasattr(attr_GaussianProcessClassifier_base_estimator_, 'tolist') else attr_GaussianProcessClassifier_base_estimator_`\n    })()\n  }\n\n  /**\n    The log-marginal-likelihood of `self.kernel\\_.theta`\n   */\n  get log_marginal_likelihood_value_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before accessing log_marginal_likelihood_value_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessClassifier_log_marginal_likelihood_value_ = bridgeGaussianProcessClassifier[${this.id}].log_marginal_likelihood_value_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessClassifier_log_marginal_likelihood_value_.tolist() if hasattr(attr_GaussianProcessClassifier_log_marginal_likelihood_value_, 'tolist') else attr_GaussianProcessClassifier_log_marginal_likelihood_value_`\n    })()\n  }\n\n  /**\n    Unique class labels.\n   */\n  get classes_(): Promise<ArrayLike> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before accessing classes_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessClassifier_classes_ = bridgeGaussianProcessClassifier[${this.id}].classes_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessClassifier_classes_.tolist() if hasattr(attr_GaussianProcessClassifier_classes_, 'tolist') else attr_GaussianProcessClassifier_classes_`\n    })()\n  }\n\n  /**\n    The number of classes in the training data\n   */\n  get n_classes_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before accessing n_classes_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessClassifier_n_classes_ = bridgeGaussianProcessClassifier[${this.id}].n_classes_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessClassifier_n_classes_.tolist() if hasattr(attr_GaussianProcessClassifier_n_classes_, 'tolist') else attr_GaussianProcessClassifier_n_classes_`\n    })()\n  }\n\n  /**\n    Number of features seen during [fit](../../glossary.html#term-fit).\n   */\n  get n_features_in_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before accessing n_features_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessClassifier_n_features_in_ = bridgeGaussianProcessClassifier[${this.id}].n_features_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessClassifier_n_features_in_.tolist() if hasattr(attr_GaussianProcessClassifier_n_features_in_, 'tolist') else attr_GaussianProcessClassifier_n_features_in_`\n    })()\n  }\n\n  /**\n    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.\n   */\n  get feature_names_in_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessClassifier instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessClassifier must call init() before accessing feature_names_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessClassifier_feature_names_in_ = bridgeGaussianProcessClassifier[${this.id}].feature_names_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessClassifier_feature_names_in_.tolist() if hasattr(attr_GaussianProcessClassifier_feature_names_in_, 'tolist') else attr_GaussianProcessClassifier_feature_names_in_`\n    })()\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Gaussian process regression (GPR).\n\n  The implementation is based on Algorithm 2.1 of [\\[RW2006\\]](#rf75674b0f418-rw2006).\n\n  In addition to standard scikit-learn estimator API, [`GaussianProcessRegressor`](#sklearn.gaussian_process.GaussianProcessRegressor \"sklearn.gaussian_process.GaussianProcessRegressor\"):\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html)\n */\nexport class GaussianProcessRegressor {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The kernel specifying the covariance function of the GP. If `undefined` is passed, the kernel `ConstantKernel(1.0, constant\\_value\\_bounds=\"fixed\") \\* RBF(1.0, length\\_scale\\_bounds=\"fixed\")` is used as default. Note that the kernel hyperparameters are optimized during fitting unless the bounds are marked as “fixed”.\n     */\n    kernel?: any\n\n    /**\n      Value added to the diagonal of the kernel matrix during fitting. This can prevent a potential numerical issue during fitting, by ensuring that the calculated values form a positive definite matrix. It can also be interpreted as the variance of additional Gaussian measurement noise on the training observations. Note that this is different from using a `WhiteKernel`. If an array is passed, it must have the same number of entries as the data used for fitting and is used as datapoint-dependent noise level. Allowing to specify the noise level directly as a parameter is mainly for convenience and for consistency with [`Ridge`](sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge \"sklearn.linear_model.Ridge\").\n\n      @defaultValue `1e-10`\n     */\n    alpha?: number | NDArray\n\n    /**\n      Can either be one of the internally supported optimizers for optimizing the kernel’s parameters, specified by a string, or an externally defined optimizer passed as a callable. If a callable is passed, it must have the signature:\n\n      @defaultValue `'fmin_l_bfgs_b'`\n     */\n    optimizer?: 'fmin_l_bfgs_b'\n\n    /**\n      The number of restarts of the optimizer for finding the kernel’s parameters which maximize the log-marginal likelihood. The first run of the optimizer is performed from the kernel’s initial parameters, the remaining ones (if any) from thetas sampled log-uniform randomly from the space of allowed theta-values. If greater than 0, all bounds must be finite. Note that `n\\_restarts\\_optimizer \\== 0` implies that one run is performed.\n\n      @defaultValue `0`\n     */\n    n_restarts_optimizer?: number\n\n    /**\n      Whether or not to normalize the target values `y` by removing the mean and scaling to unit-variance. This is recommended for cases where zero-mean, unit-variance priors are used. Note that, in this implementation, the normalisation is reversed before the GP predictions are reported.\n\n      @defaultValue `false`\n     */\n    normalize_y?: boolean\n\n    /**\n      If `true`, a persistent copy of the training data is stored in the object. Otherwise, just a reference to the training data is stored, which might cause predictions to change if the data is modified externally.\n\n      @defaultValue `true`\n     */\n    copy_X_train?: boolean\n\n    /**\n      The number of dimensions of the target values. Used to decide the number of outputs when sampling from the prior distributions (i.e. calling [`sample\\_y`](#sklearn.gaussian_process.GaussianProcessRegressor.sample_y \"sklearn.gaussian_process.GaussianProcessRegressor.sample_y\") before [`fit`](#sklearn.gaussian_process.GaussianProcessRegressor.fit \"sklearn.gaussian_process.GaussianProcessRegressor.fit\")). This parameter is ignored once [`fit`](#sklearn.gaussian_process.GaussianProcessRegressor.fit \"sklearn.gaussian_process.GaussianProcessRegressor.fit\") has been called.\n     */\n    n_targets?: number\n\n    /**\n      Determines random number generation used to initialize the centers. Pass an int for reproducible results across multiple function calls. See [Glossary](../../glossary.html#term-random_state).\n     */\n    random_state?: number\n  }) {\n    this.id = `GaussianProcessRegressor${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error(\n        'GaussianProcessRegressor.init requires a PythonBridge instance'\n      )\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\ntry: bridgeGaussianProcessRegressor\nexcept NameError: bridgeGaussianProcessRegressor = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_GaussianProcessRegressor = {'kernel': ${\n      this.opts['kernel'] ?? undefined\n    }, 'alpha': np.array(${this.opts['alpha'] ?? undefined}) if ${\n      this.opts['alpha'] !== undefined\n    } else None, 'optimizer': ${\n      this.opts['optimizer'] ?? undefined\n    }, 'n_restarts_optimizer': ${\n      this.opts['n_restarts_optimizer'] ?? undefined\n    }, 'normalize_y': ${\n      this.opts['normalize_y'] ?? undefined\n    }, 'copy_X_train': ${\n      this.opts['copy_X_train'] ?? undefined\n    }, 'n_targets': ${this.opts['n_targets'] ?? undefined}, 'random_state': ${\n      this.opts['random_state'] ?? undefined\n    }}\n\nctor_GaussianProcessRegressor = {k: v for k, v in ctor_GaussianProcessRegressor.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeGaussianProcessRegressor[${this.id}] = GaussianProcessRegressor(**ctor_GaussianProcessRegressor)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeGaussianProcessRegressor[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Fit Gaussian process regression model.\n   */\n  async fit(opts: {\n    /**\n      Feature vectors or other representations of training data.\n     */\n    X?: ArrayLike[]\n\n    /**\n      Target values.\n     */\n    y?: ArrayLike\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('GaussianProcessRegressor must call init() before fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_GaussianProcessRegressor_fit = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None}\n\npms_GaussianProcessRegressor_fit = {k: v for k, v in pms_GaussianProcessRegressor_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessRegressor_fit = bridgeGaussianProcessRegressor[${this.id}].fit(**pms_GaussianProcessRegressor_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessRegressor_fit.tolist() if hasattr(res_GaussianProcessRegressor_fit, 'tolist') else res_GaussianProcessRegressor_fit`\n  }\n\n  /**\n    Get metadata routing of this object.\n\n    Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.\n   */\n  async get_metadata_routing(opts: {\n    /**\n      A [`MetadataRequest`](sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest \"sklearn.utils.metadata_routing.MetadataRequest\") encapsulating routing information.\n     */\n    routing?: any\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before get_metadata_routing()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_GaussianProcessRegressor_get_metadata_routing = {'routing': ${\n      opts['routing'] ?? undefined\n    }}\n\npms_GaussianProcessRegressor_get_metadata_routing = {k: v for k, v in pms_GaussianProcessRegressor_get_metadata_routing.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessRegressor_get_metadata_routing = bridgeGaussianProcessRegressor[${this.id}].get_metadata_routing(**pms_GaussianProcessRegressor_get_metadata_routing)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessRegressor_get_metadata_routing.tolist() if hasattr(res_GaussianProcessRegressor_get_metadata_routing, 'tolist') else res_GaussianProcessRegressor_get_metadata_routing`\n  }\n\n  /**\n    Return log-marginal likelihood of theta for training data.\n   */\n  async log_marginal_likelihood(opts: {\n    /**\n      Kernel hyperparameters for which the log-marginal likelihood is evaluated. If `undefined`, the precomputed log\\_marginal\\_likelihood of `self.kernel\\_.theta` is returned.\n     */\n    theta?: any\n\n    /**\n      If `true`, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. If `true`, theta must not be `undefined`.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n\n    /**\n      If `true`, the kernel attribute is copied. If `false`, the kernel attribute is modified, but may result in a performance improvement.\n\n      @defaultValue `true`\n     */\n    clone_kernel?: boolean\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before log_marginal_likelihood()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_GaussianProcessRegressor_log_marginal_likelihood = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }, 'clone_kernel': ${opts['clone_kernel'] ?? undefined}}\n\npms_GaussianProcessRegressor_log_marginal_likelihood = {k: v for k, v in pms_GaussianProcessRegressor_log_marginal_likelihood.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessRegressor_log_marginal_likelihood = bridgeGaussianProcessRegressor[${this.id}].log_marginal_likelihood(**pms_GaussianProcessRegressor_log_marginal_likelihood)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessRegressor_log_marginal_likelihood.tolist() if hasattr(res_GaussianProcessRegressor_log_marginal_likelihood, 'tolist') else res_GaussianProcessRegressor_log_marginal_likelihood`\n  }\n\n  /**\n    Predict using the Gaussian process regression model.\n\n    We can also predict based on an unfitted model by using the GP prior. In addition to the mean of the predictive distribution, optionally also returns its standard deviation (`return\\_std=True`) or covariance (`return\\_cov=True`). Note that at most one of the two can be requested.\n   */\n  async predict(opts: {\n    /**\n      Query points where the GP is evaluated.\n     */\n    X?: ArrayLike[]\n\n    /**\n      If `true`, the standard-deviation of the predictive distribution at the query points is returned along with the mean.\n\n      @defaultValue `false`\n     */\n    return_std?: boolean\n\n    /**\n      If `true`, the covariance of the joint predictive distribution at the query points is returned along with the mean.\n\n      @defaultValue `false`\n     */\n    return_cov?: boolean\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before predict()'\n      )\n    }\n\n    // set up method params\n    await this._py.ex`pms_GaussianProcessRegressor_predict = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'return_std': ${\n      opts['return_std'] ?? undefined\n    }, 'return_cov': ${opts['return_cov'] ?? undefined}}\n\npms_GaussianProcessRegressor_predict = {k: v for k, v in pms_GaussianProcessRegressor_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessRegressor_predict = bridgeGaussianProcessRegressor[${this.id}].predict(**pms_GaussianProcessRegressor_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessRegressor_predict.tolist() if hasattr(res_GaussianProcessRegressor_predict, 'tolist') else res_GaussianProcessRegressor_predict`\n  }\n\n  /**\n    Draw samples from Gaussian process and evaluate at X.\n   */\n  async sample_y(opts: {\n    /**\n      Query points where the GP is evaluated.\n     */\n    X?: ArrayLike[]\n\n    /**\n      Number of samples drawn from the Gaussian process per query point.\n\n      @defaultValue `1`\n     */\n    n_samples?: number\n\n    /**\n      Determines random number generation to randomly draw samples. Pass an int for reproducible results across multiple function calls. See [Glossary](../../glossary.html#term-random_state).\n\n      @defaultValue `0`\n     */\n    random_state?: number\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before sample_y()'\n      )\n    }\n\n    // set up method params\n    await this._py.ex`pms_GaussianProcessRegressor_sample_y = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'n_samples': ${\n      opts['n_samples'] ?? undefined\n    }, 'random_state': ${opts['random_state'] ?? undefined}}\n\npms_GaussianProcessRegressor_sample_y = {k: v for k, v in pms_GaussianProcessRegressor_sample_y.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessRegressor_sample_y = bridgeGaussianProcessRegressor[${this.id}].sample_y(**pms_GaussianProcessRegressor_sample_y)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessRegressor_sample_y.tolist() if hasattr(res_GaussianProcessRegressor_sample_y, 'tolist') else res_GaussianProcessRegressor_sample_y`\n  }\n\n  /**\n    Return the coefficient of determination of the prediction.\n\n    The coefficient of determination \\\\(R^2\\\\) is defined as \\\\((1 - \\\\frac{u}{v})\\\\), where \\\\(u\\\\) is the residual sum of squares `((y\\_true \\- y\\_pred)\\*\\* 2).sum()` and \\\\(v\\\\) is the total sum of squares `((y\\_true \\- y\\_true.mean()) \\*\\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\\\(R^2\\\\) score of 0.0.\n   */\n  async score(opts: {\n    /**\n      Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape `(n\\_samples, n\\_samples\\_fitted)`, where `n\\_samples\\_fitted` is the number of samples used in the fitting for the estimator.\n     */\n    X?: ArrayLike[]\n\n    /**\n      True values for `X`.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before score()'\n      )\n    }\n\n    // set up method params\n    await this._py.ex`pms_GaussianProcessRegressor_score = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_GaussianProcessRegressor_score = {k: v for k, v in pms_GaussianProcessRegressor_score.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessRegressor_score = bridgeGaussianProcessRegressor[${this.id}].score(**pms_GaussianProcessRegressor_score)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessRegressor_score.tolist() if hasattr(res_GaussianProcessRegressor_score, 'tolist') else res_GaussianProcessRegressor_score`\n  }\n\n  /**\n    Request metadata passed to the `predict` method.\n\n    Note that this method is only relevant if `enable\\_metadata\\_routing=True` (see [`sklearn.set\\_config`](sklearn.set_config.html#sklearn.set_config \"sklearn.set_config\")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.\n\n    The options for each parameter are:\n   */\n  async set_predict_request(opts: {\n    /**\n      Metadata routing for `return\\_cov` parameter in `predict`.\n     */\n    return_cov?: string | boolean\n\n    /**\n      Metadata routing for `return\\_std` parameter in `predict`.\n     */\n    return_std?: string | boolean\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before set_predict_request()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_GaussianProcessRegressor_set_predict_request = {'return_cov': ${\n      opts['return_cov'] ?? undefined\n    }, 'return_std': ${opts['return_std'] ?? undefined}}\n\npms_GaussianProcessRegressor_set_predict_request = {k: v for k, v in pms_GaussianProcessRegressor_set_predict_request.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessRegressor_set_predict_request = bridgeGaussianProcessRegressor[${this.id}].set_predict_request(**pms_GaussianProcessRegressor_set_predict_request)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessRegressor_set_predict_request.tolist() if hasattr(res_GaussianProcessRegressor_set_predict_request, 'tolist') else res_GaussianProcessRegressor_set_predict_request`\n  }\n\n  /**\n    Request metadata passed to the `score` method.\n\n    Note that this method is only relevant if `enable\\_metadata\\_routing=True` (see [`sklearn.set\\_config`](sklearn.set_config.html#sklearn.set_config \"sklearn.set_config\")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.\n\n    The options for each parameter are:\n   */\n  async set_score_request(opts: {\n    /**\n      Metadata routing for `sample\\_weight` parameter in `score`.\n     */\n    sample_weight?: string | boolean\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before set_score_request()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_GaussianProcessRegressor_set_score_request = {'sample_weight': ${\n      opts['sample_weight'] ?? undefined\n    }}\n\npms_GaussianProcessRegressor_set_score_request = {k: v for k, v in pms_GaussianProcessRegressor_set_score_request.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GaussianProcessRegressor_set_score_request = bridgeGaussianProcessRegressor[${this.id}].set_score_request(**pms_GaussianProcessRegressor_set_score_request)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GaussianProcessRegressor_set_score_request.tolist() if hasattr(res_GaussianProcessRegressor_set_score_request, 'tolist') else res_GaussianProcessRegressor_set_score_request`\n  }\n\n  /**\n    Feature vectors or other representations of training data (also required for prediction).\n   */\n  get X_train_(): Promise<ArrayLike[]> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before accessing X_train_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessRegressor_X_train_ = bridgeGaussianProcessRegressor[${this.id}].X_train_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessRegressor_X_train_.tolist() if hasattr(attr_GaussianProcessRegressor_X_train_, 'tolist') else attr_GaussianProcessRegressor_X_train_`\n    })()\n  }\n\n  /**\n    Target values in training data (also required for prediction).\n   */\n  get y_train_(): Promise<ArrayLike> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before accessing y_train_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessRegressor_y_train_ = bridgeGaussianProcessRegressor[${this.id}].y_train_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessRegressor_y_train_.tolist() if hasattr(attr_GaussianProcessRegressor_y_train_, 'tolist') else attr_GaussianProcessRegressor_y_train_`\n    })()\n  }\n\n  /**\n    The kernel used for prediction. The structure of the kernel is the same as the one passed as parameter but with optimized hyperparameters.\n   */\n  get kernel_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before accessing kernel_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessRegressor_kernel_ = bridgeGaussianProcessRegressor[${this.id}].kernel_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessRegressor_kernel_.tolist() if hasattr(attr_GaussianProcessRegressor_kernel_, 'tolist') else attr_GaussianProcessRegressor_kernel_`\n    })()\n  }\n\n  /**\n    Lower-triangular Cholesky decomposition of the kernel in `X\\_train\\_`.\n   */\n  get L_(): Promise<ArrayLike[]> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before accessing L_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessRegressor_L_ = bridgeGaussianProcessRegressor[${this.id}].L_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessRegressor_L_.tolist() if hasattr(attr_GaussianProcessRegressor_L_, 'tolist') else attr_GaussianProcessRegressor_L_`\n    })()\n  }\n\n  /**\n    Dual coefficients of training data points in kernel space.\n   */\n  get alpha_(): Promise<ArrayLike> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before accessing alpha_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessRegressor_alpha_ = bridgeGaussianProcessRegressor[${this.id}].alpha_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessRegressor_alpha_.tolist() if hasattr(attr_GaussianProcessRegressor_alpha_, 'tolist') else attr_GaussianProcessRegressor_alpha_`\n    })()\n  }\n\n  /**\n    The log-marginal-likelihood of `self.kernel\\_.theta`.\n   */\n  get log_marginal_likelihood_value_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before accessing log_marginal_likelihood_value_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessRegressor_log_marginal_likelihood_value_ = bridgeGaussianProcessRegressor[${this.id}].log_marginal_likelihood_value_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessRegressor_log_marginal_likelihood_value_.tolist() if hasattr(attr_GaussianProcessRegressor_log_marginal_likelihood_value_, 'tolist') else attr_GaussianProcessRegressor_log_marginal_likelihood_value_`\n    })()\n  }\n\n  /**\n    Number of features seen during [fit](../../glossary.html#term-fit).\n   */\n  get n_features_in_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before accessing n_features_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessRegressor_n_features_in_ = bridgeGaussianProcessRegressor[${this.id}].n_features_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessRegressor_n_features_in_.tolist() if hasattr(attr_GaussianProcessRegressor_n_features_in_, 'tolist') else attr_GaussianProcessRegressor_n_features_in_`\n    })()\n  }\n\n  /**\n    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.\n   */\n  get feature_names_in_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This GaussianProcessRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GaussianProcessRegressor must call init() before accessing feature_names_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GaussianProcessRegressor_feature_names_in_ = bridgeGaussianProcessRegressor[${this.id}].feature_names_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GaussianProcessRegressor_feature_names_in_.tolist() if hasattr(attr_GaussianProcessRegressor_feature_names_in_, 'tolist') else attr_GaussianProcessRegressor_feature_names_in_`\n    })()\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Kernel which is composed of a set of other kernels.\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.CompoundKernel.html)\n */\nexport class CompoundKernel {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The other kernels\n     */\n    kernels?: any\n  }) {\n    this.id = `CompoundKernel${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This CompoundKernel instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('CompoundKernel.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import CompoundKernel\ntry: bridgeCompoundKernel\nexcept NameError: bridgeCompoundKernel = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_CompoundKernel = {'kernels': ${\n      this.opts['kernels'] ?? undefined\n    }}\n\nctor_CompoundKernel = {k: v for k, v in ctor_CompoundKernel.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeCompoundKernel[${this.id}] = CompoundKernel(**ctor_CompoundKernel)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeCompoundKernel[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n\n    Note that this compound kernel returns the results of all simple kernel stacked along an additional axis.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: ArrayLike[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) is evaluated instead.\n     */\n    Y?: ArrayLike[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[][]> {\n    if (this._isDisposed) {\n      throw new Error('This CompoundKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('CompoundKernel must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_CompoundKernel___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_CompoundKernel___call__ = {k: v for k, v in pms_CompoundKernel___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_CompoundKernel___call__ = bridgeCompoundKernel[${this.id}].__call__(**pms_CompoundKernel___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_CompoundKernel___call__.tolist() if hasattr(res_CompoundKernel___call__, 'tolist') else res_CompoundKernel___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This CompoundKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'CompoundKernel must call init() before clone_with_theta()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_CompoundKernel_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_CompoundKernel_clone_with_theta = {k: v for k, v in pms_CompoundKernel_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_CompoundKernel_clone_with_theta = bridgeCompoundKernel[${this.id}].clone_with_theta(**pms_CompoundKernel_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_CompoundKernel_clone_with_theta.tolist() if hasattr(res_CompoundKernel_clone_with_theta, 'tolist') else res_CompoundKernel_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to `np.diag(self(X))`; however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Argument to the kernel.\n     */\n    X?: ArrayLike[]\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This CompoundKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('CompoundKernel must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_CompoundKernel_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_CompoundKernel_diag = {k: v for k, v in pms_CompoundKernel_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_CompoundKernel_diag = bridgeCompoundKernel[${this.id}].diag(**pms_CompoundKernel_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_CompoundKernel_diag.tolist() if hasattr(res_CompoundKernel_diag, 'tolist') else res_CompoundKernel_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This CompoundKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('CompoundKernel must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_CompoundKernel_is_stationary = {}\n\npms_CompoundKernel_is_stationary = {k: v for k, v in pms_CompoundKernel_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_CompoundKernel_is_stationary = bridgeCompoundKernel[${this.id}].is_stationary(**pms_CompoundKernel_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_CompoundKernel_is_stationary.tolist() if hasattr(res_CompoundKernel_is_stationary, 'tolist') else res_CompoundKernel_is_stationary`\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Constant kernel.\n\n  Can be used as part of a product-kernel where it scales the magnitude of the other factor (kernel) or as part of a sum-kernel, where it modifies the mean of the Gaussian process.\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.ConstantKernel.html)\n */\nexport class ConstantKernel {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The constant value which defines the covariance: k(x\\_1, x\\_2) = constant\\_value\n\n      @defaultValue `1`\n     */\n    constant_value?: number\n\n    /**\n      The lower and upper bound on `constant\\_value`. If set to “fixed”, `constant\\_value` cannot be changed during hyperparameter tuning.\n     */\n    constant_value_bounds?: 'fixed'\n  }) {\n    this.id = `ConstantKernel${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This ConstantKernel instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('ConstantKernel.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import ConstantKernel\ntry: bridgeConstantKernel\nexcept NameError: bridgeConstantKernel = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_ConstantKernel = {'constant_value': ${\n      this.opts['constant_value'] ?? undefined\n    }, 'constant_value_bounds': ${\n      this.opts['constant_value_bounds'] ?? undefined\n    }}\n\nctor_ConstantKernel = {k: v for k, v in ctor_ConstantKernel.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeConstantKernel[${this.id}] = ConstantKernel(**ctor_ConstantKernel)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeConstantKernel[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: ArrayLike[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) is evaluated instead.\n     */\n    Y?: ArrayLike[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is `undefined`.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This ConstantKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('ConstantKernel must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_ConstantKernel___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_ConstantKernel___call__ = {k: v for k, v in pms_ConstantKernel___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_ConstantKernel___call__ = bridgeConstantKernel[${this.id}].__call__(**pms_ConstantKernel___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_ConstantKernel___call__.tolist() if hasattr(res_ConstantKernel___call__, 'tolist') else res_ConstantKernel___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This ConstantKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'ConstantKernel must call init() before clone_with_theta()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_ConstantKernel_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_ConstantKernel_clone_with_theta = {k: v for k, v in pms_ConstantKernel_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_ConstantKernel_clone_with_theta = bridgeConstantKernel[${this.id}].clone_with_theta(**pms_ConstantKernel_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_ConstantKernel_clone_with_theta.tolist() if hasattr(res_ConstantKernel_clone_with_theta, 'tolist') else res_ConstantKernel_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Argument to the kernel.\n     */\n    X?: ArrayLike[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This ConstantKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('ConstantKernel must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_ConstantKernel_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_ConstantKernel_diag = {k: v for k, v in pms_ConstantKernel_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_ConstantKernel_diag = bridgeConstantKernel[${this.id}].diag(**pms_ConstantKernel_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_ConstantKernel_diag.tolist() if hasattr(res_ConstantKernel_diag, 'tolist') else res_ConstantKernel_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This ConstantKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('ConstantKernel must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_ConstantKernel_is_stationary = {}\n\npms_ConstantKernel_is_stationary = {k: v for k, v in pms_ConstantKernel_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_ConstantKernel_is_stationary = bridgeConstantKernel[${this.id}].is_stationary(**pms_ConstantKernel_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_ConstantKernel_is_stationary.tolist() if hasattr(res_ConstantKernel_is_stationary, 'tolist') else res_ConstantKernel_is_stationary`\n  }\n\n  get hyperparameter_constant_value(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This ConstantKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'ConstantKernel must call init() before accessing hyperparameter_constant_value'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_ConstantKernel_hyperparameter_constant_value = bridgeConstantKernel[${this.id}].hyperparameter_constant_value`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_ConstantKernel_hyperparameter_constant_value.tolist() if hasattr(attr_ConstantKernel_hyperparameter_constant_value, 'tolist') else attr_ConstantKernel_hyperparameter_constant_value`\n    })()\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Dot-Product kernel.\n\n  The DotProduct kernel is non-stationary and can be obtained from linear regression by putting \\\\(N(0, 1)\\\\) priors on the coefficients of \\\\(x\\_d (d = 1, . . . , D)\\\\) and a prior of \\\\(N(0, \\\\sigma\\_0^2)\\\\) on the bias. The DotProduct kernel is invariant to a rotation of the coordinates about the origin, but not translations. It is parameterized by a parameter sigma\\_0 \\\\(\\\\sigma\\\\) which controls the inhomogenity of the kernel. For \\\\(\\\\sigma\\_0^2 =0\\\\), the kernel is called the homogeneous linear kernel, otherwise it is inhomogeneous. The kernel is given by\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.DotProduct.html)\n */\nexport class DotProduct {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      Parameter controlling the inhomogenity of the kernel. If sigma\\_0=0, the kernel is homogeneous.\n\n      @defaultValue `1`\n     */\n    sigma_0?: any\n\n    /**\n      The lower and upper bound on ‘sigma\\_0’. If set to “fixed”, ‘sigma\\_0’ cannot be changed during hyperparameter tuning.\n     */\n    sigma_0_bounds?: 'fixed'\n  }) {\n    this.id = `DotProduct${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This DotProduct instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('DotProduct.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import DotProduct\ntry: bridgeDotProduct\nexcept NameError: bridgeDotProduct = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_DotProduct = {'sigma_0': ${\n      this.opts['sigma_0'] ?? undefined\n    }, 'sigma_0_bounds': ${this.opts['sigma_0_bounds'] ?? undefined}}\n\nctor_DotProduct = {k: v for k, v in ctor_DotProduct.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeDotProduct[${this.id}] = DotProduct(**ctor_DotProduct)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeDotProduct[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: NDArray[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) if evaluated instead.\n     */\n    Y?: NDArray[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is `undefined`.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This DotProduct instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('DotProduct must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_DotProduct___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_DotProduct___call__ = {k: v for k, v in pms_DotProduct___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_DotProduct___call__ = bridgeDotProduct[${this.id}].__call__(**pms_DotProduct___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_DotProduct___call__.tolist() if hasattr(res_DotProduct___call__, 'tolist') else res_DotProduct___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This DotProduct instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('DotProduct must call init() before clone_with_theta()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_DotProduct_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_DotProduct_clone_with_theta = {k: v for k, v in pms_DotProduct_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_DotProduct_clone_with_theta = bridgeDotProduct[${this.id}].clone_with_theta(**pms_DotProduct_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_DotProduct_clone_with_theta.tolist() if hasattr(res_DotProduct_clone_with_theta, 'tolist') else res_DotProduct_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y).\n     */\n    X?: NDArray[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This DotProduct instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('DotProduct must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_DotProduct_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_DotProduct_diag = {k: v for k, v in pms_DotProduct_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_DotProduct_diag = bridgeDotProduct[${this.id}].diag(**pms_DotProduct_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_DotProduct_diag.tolist() if hasattr(res_DotProduct_diag, 'tolist') else res_DotProduct_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This DotProduct instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('DotProduct must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_DotProduct_is_stationary = {}\n\npms_DotProduct_is_stationary = {k: v for k, v in pms_DotProduct_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_DotProduct_is_stationary = bridgeDotProduct[${this.id}].is_stationary(**pms_DotProduct_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_DotProduct_is_stationary.tolist() if hasattr(res_DotProduct_is_stationary, 'tolist') else res_DotProduct_is_stationary`\n  }\n\n  get hyperparameter_sigma_0(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This DotProduct instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'DotProduct must call init() before accessing hyperparameter_sigma_0'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_DotProduct_hyperparameter_sigma_0 = bridgeDotProduct[${this.id}].hyperparameter_sigma_0`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_DotProduct_hyperparameter_sigma_0.tolist() if hasattr(attr_DotProduct_hyperparameter_sigma_0, 'tolist') else attr_DotProduct_hyperparameter_sigma_0`\n    })()\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  The Exponentiation kernel takes one base kernel and a scalar parameter \\\\(p\\\\) and combines them via\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Exponentiation.html)\n */\nexport class Exponentiation {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The base kernel\n     */\n    kernel?: any\n\n    /**\n      The exponent for the base kernel\n     */\n    exponent?: number\n  }) {\n    this.id = `Exponentiation${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This Exponentiation instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('Exponentiation.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import Exponentiation\ntry: bridgeExponentiation\nexcept NameError: bridgeExponentiation = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_Exponentiation = {'kernel': ${\n      this.opts['kernel'] ?? undefined\n    }, 'exponent': ${this.opts['exponent'] ?? undefined}}\n\nctor_Exponentiation = {k: v for k, v in ctor_Exponentiation.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeExponentiation[${this.id}] = Exponentiation(**ctor_Exponentiation)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeExponentiation[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: ArrayLike[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) is evaluated instead.\n     */\n    Y?: ArrayLike[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This Exponentiation instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Exponentiation must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Exponentiation___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_Exponentiation___call__ = {k: v for k, v in pms_Exponentiation___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Exponentiation___call__ = bridgeExponentiation[${this.id}].__call__(**pms_Exponentiation___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Exponentiation___call__.tolist() if hasattr(res_Exponentiation___call__, 'tolist') else res_Exponentiation___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Exponentiation instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'Exponentiation must call init() before clone_with_theta()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_Exponentiation_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_Exponentiation_clone_with_theta = {k: v for k, v in pms_Exponentiation_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Exponentiation_clone_with_theta = bridgeExponentiation[${this.id}].clone_with_theta(**pms_Exponentiation_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Exponentiation_clone_with_theta.tolist() if hasattr(res_Exponentiation_clone_with_theta, 'tolist') else res_Exponentiation_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Argument to the kernel.\n     */\n    X?: ArrayLike[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This Exponentiation instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Exponentiation must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Exponentiation_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_Exponentiation_diag = {k: v for k, v in pms_Exponentiation_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Exponentiation_diag = bridgeExponentiation[${this.id}].diag(**pms_Exponentiation_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Exponentiation_diag.tolist() if hasattr(res_Exponentiation_diag, 'tolist') else res_Exponentiation_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Exponentiation instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Exponentiation must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Exponentiation_is_stationary = {}\n\npms_Exponentiation_is_stationary = {k: v for k, v in pms_Exponentiation_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Exponentiation_is_stationary = bridgeExponentiation[${this.id}].is_stationary(**pms_Exponentiation_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Exponentiation_is_stationary.tolist() if hasattr(res_Exponentiation_is_stationary, 'tolist') else res_Exponentiation_is_stationary`\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Exp-Sine-Squared kernel (aka periodic kernel).\n\n  The ExpSineSquared kernel allows one to model functions which repeat themselves exactly. It is parameterized by a length scale parameter \\\\(l>0\\\\) and a periodicity parameter \\\\(p>0\\\\). Only the isotropic variant where \\\\(l\\\\) is a scalar is supported at the moment. The kernel is given by:\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.ExpSineSquared.html)\n */\nexport class ExpSineSquared {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The length scale of the kernel.\n\n      @defaultValue `1`\n     */\n    length_scale?: any\n\n    /**\n      The periodicity of the kernel.\n\n      @defaultValue `1`\n     */\n    periodicity?: any\n\n    /**\n      The lower and upper bound on ‘length\\_scale’. If set to “fixed”, ‘length\\_scale’ cannot be changed during hyperparameter tuning.\n     */\n    length_scale_bounds?: 'fixed'\n\n    /**\n      The lower and upper bound on ‘periodicity’. If set to “fixed”, ‘periodicity’ cannot be changed during hyperparameter tuning.\n     */\n    periodicity_bounds?: 'fixed'\n  }) {\n    this.id = `ExpSineSquared${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This ExpSineSquared instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('ExpSineSquared.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import ExpSineSquared\ntry: bridgeExpSineSquared\nexcept NameError: bridgeExpSineSquared = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_ExpSineSquared = {'length_scale': ${\n      this.opts['length_scale'] ?? undefined\n    }, 'periodicity': ${\n      this.opts['periodicity'] ?? undefined\n    }, 'length_scale_bounds': ${\n      this.opts['length_scale_bounds'] ?? undefined\n    }, 'periodicity_bounds': ${this.opts['periodicity_bounds'] ?? undefined}}\n\nctor_ExpSineSquared = {k: v for k, v in ctor_ExpSineSquared.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeExpSineSquared[${this.id}] = ExpSineSquared(**ctor_ExpSineSquared)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeExpSineSquared[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: NDArray[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) if evaluated instead.\n     */\n    Y?: NDArray[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is `undefined`.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This ExpSineSquared instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('ExpSineSquared must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_ExpSineSquared___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_ExpSineSquared___call__ = {k: v for k, v in pms_ExpSineSquared___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_ExpSineSquared___call__ = bridgeExpSineSquared[${this.id}].__call__(**pms_ExpSineSquared___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_ExpSineSquared___call__.tolist() if hasattr(res_ExpSineSquared___call__, 'tolist') else res_ExpSineSquared___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This ExpSineSquared instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'ExpSineSquared must call init() before clone_with_theta()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_ExpSineSquared_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_ExpSineSquared_clone_with_theta = {k: v for k, v in pms_ExpSineSquared_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_ExpSineSquared_clone_with_theta = bridgeExpSineSquared[${this.id}].clone_with_theta(**pms_ExpSineSquared_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_ExpSineSquared_clone_with_theta.tolist() if hasattr(res_ExpSineSquared_clone_with_theta, 'tolist') else res_ExpSineSquared_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: NDArray[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This ExpSineSquared instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('ExpSineSquared must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_ExpSineSquared_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_ExpSineSquared_diag = {k: v for k, v in pms_ExpSineSquared_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_ExpSineSquared_diag = bridgeExpSineSquared[${this.id}].diag(**pms_ExpSineSquared_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_ExpSineSquared_diag.tolist() if hasattr(res_ExpSineSquared_diag, 'tolist') else res_ExpSineSquared_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This ExpSineSquared instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('ExpSineSquared must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_ExpSineSquared_is_stationary = {}\n\npms_ExpSineSquared_is_stationary = {k: v for k, v in pms_ExpSineSquared_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_ExpSineSquared_is_stationary = bridgeExpSineSquared[${this.id}].is_stationary(**pms_ExpSineSquared_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_ExpSineSquared_is_stationary.tolist() if hasattr(res_ExpSineSquared_is_stationary, 'tolist') else res_ExpSineSquared_is_stationary`\n  }\n\n  get hyperparameter_periodicity(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This ExpSineSquared instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'ExpSineSquared must call init() before accessing hyperparameter_periodicity'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_ExpSineSquared_hyperparameter_periodicity = bridgeExpSineSquared[${this.id}].hyperparameter_periodicity`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_ExpSineSquared_hyperparameter_periodicity.tolist() if hasattr(attr_ExpSineSquared_hyperparameter_periodicity, 'tolist') else attr_ExpSineSquared_hyperparameter_periodicity`\n    })()\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  A kernel hyperparameter’s specification in form of a namedtuple.\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Hyperparameter.html)\n */\nexport class Hyperparameter {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The name of the hyperparameter. Note that a kernel using a hyperparameter with name “x” must have the attributes self.x and self.x\\_bounds\n     */\n    name?: string\n\n    /**\n      The type of the hyperparameter. Currently, only “numeric” hyperparameters are supported.\n     */\n    value_type?: string\n\n    /**\n      The lower and upper bound on the parameter. If n\\_elements>1, a pair of 1d array with n\\_elements each may be given alternatively. If the string “fixed” is passed as bounds, the hyperparameter’s value cannot be changed.\n     */\n    bounds?: 'fixed'\n\n    /**\n      The number of elements of the hyperparameter value. Defaults to 1, which corresponds to a scalar hyperparameter. n\\_elements > 1 corresponds to a hyperparameter which is vector-valued, such as, e.g., anisotropic length-scales.\n\n      @defaultValue `1`\n     */\n    n_elements?: number\n\n    /**\n      Whether the value of this hyperparameter is fixed, i.e., cannot be changed during hyperparameter tuning. If `undefined` is passed, the “fixed” is derived based on the given bounds.\n     */\n    fixed?: boolean\n  }) {\n    this.id = `Hyperparameter${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This Hyperparameter instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('Hyperparameter.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import Hyperparameter\ntry: bridgeHyperparameter\nexcept NameError: bridgeHyperparameter = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_Hyperparameter = {'name': ${\n      this.opts['name'] ?? undefined\n    }, 'value_type': ${this.opts['value_type'] ?? undefined}, 'bounds': ${\n      this.opts['bounds'] ?? undefined\n    }, 'n_elements': ${this.opts['n_elements'] ?? undefined}, 'fixed': ${\n      this.opts['fixed'] ?? undefined\n    }}\n\nctor_Hyperparameter = {k: v for k, v in ctor_Hyperparameter.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeHyperparameter[${this.id}] = Hyperparameter(**ctor_Hyperparameter)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeHyperparameter[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Call self as a function.\n   */\n  async __call__(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Hyperparameter instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Hyperparameter must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Hyperparameter___call__ = {}\n\npms_Hyperparameter___call__ = {k: v for k, v in pms_Hyperparameter___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Hyperparameter___call__ = bridgeHyperparameter[${this.id}].__call__(**pms_Hyperparameter___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Hyperparameter___call__.tolist() if hasattr(res_Hyperparameter___call__, 'tolist') else res_Hyperparameter___call__`\n  }\n\n  /**\n    Return number of occurrences of value.\n   */\n  async count(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Hyperparameter instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Hyperparameter must call init() before count()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Hyperparameter_count = {}\n\npms_Hyperparameter_count = {k: v for k, v in pms_Hyperparameter_count.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Hyperparameter_count = bridgeHyperparameter[${this.id}].count(**pms_Hyperparameter_count)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Hyperparameter_count.tolist() if hasattr(res_Hyperparameter_count, 'tolist') else res_Hyperparameter_count`\n  }\n\n  /**\n    Return first index of value.\n\n    Raises ValueError if the value is not present.\n   */\n  async index(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Hyperparameter instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Hyperparameter must call init() before index()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Hyperparameter_index = {}\n\npms_Hyperparameter_index = {k: v for k, v in pms_Hyperparameter_index.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Hyperparameter_index = bridgeHyperparameter[${this.id}].index(**pms_Hyperparameter_index)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Hyperparameter_index.tolist() if hasattr(res_Hyperparameter_index, 'tolist') else res_Hyperparameter_index`\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Base class for all kernels.\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Kernel.html)\n */\nexport class Kernel {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {}) {\n    this.id = `Kernel${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This Kernel instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('Kernel.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import Kernel\ntry: bridgeKernel\nexcept NameError: bridgeKernel = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_Kernel = {}\n\nctor_Kernel = {k: v for k, v in ctor_Kernel.items() if v is not None}`\n\n    await this._py.ex`bridgeKernel[${this.id}] = Kernel(**ctor_Kernel)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeKernel[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Evaluate the kernel.\n   */\n  async __call__(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Kernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Kernel must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Kernel___call__ = {}\n\npms_Kernel___call__ = {k: v for k, v in pms_Kernel___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Kernel___call__ = bridgeKernel[${this.id}].__call__(**pms_Kernel___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Kernel___call__.tolist() if hasattr(res_Kernel___call__, 'tolist') else res_Kernel___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Kernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Kernel must call init() before clone_with_theta()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Kernel_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_Kernel_clone_with_theta = {k: v for k, v in pms_Kernel_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Kernel_clone_with_theta = bridgeKernel[${this.id}].clone_with_theta(**pms_Kernel_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Kernel_clone_with_theta.tolist() if hasattr(res_Kernel_clone_with_theta, 'tolist') else res_Kernel_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: ArrayLike\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This Kernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Kernel must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Kernel_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_Kernel_diag = {k: v for k, v in pms_Kernel_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Kernel_diag = bridgeKernel[${this.id}].diag(**pms_Kernel_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Kernel_diag.tolist() if hasattr(res_Kernel_diag, 'tolist') else res_Kernel_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Kernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Kernel must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Kernel_is_stationary = {}\n\npms_Kernel_is_stationary = {k: v for k, v in pms_Kernel_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Kernel_is_stationary = bridgeKernel[${this.id}].is_stationary(**pms_Kernel_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Kernel_is_stationary.tolist() if hasattr(res_Kernel_is_stationary, 'tolist') else res_Kernel_is_stationary`\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Matern kernel.\n\n  The class of Matern kernels is a generalization of the [`RBF`](sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF \"sklearn.gaussian_process.kernels.RBF\"). It has an additional parameter \\\\(\\\\nu\\\\) which controls the smoothness of the resulting function. The smaller \\\\(\\\\nu\\\\), the less smooth the approximated function is. As \\\\(\\\\nu\\\\rightarrow\\\\infty\\\\), the kernel becomes equivalent to the [`RBF`](sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF \"sklearn.gaussian_process.kernels.RBF\") kernel. When \\\\(\\\\nu = 1/2\\\\), the Matérn kernel becomes identical to the absolute exponential kernel. Important intermediate values are \\\\(\\\\nu=1.5\\\\) (once differentiable functions) and \\\\(\\\\nu=2.5\\\\) (twice differentiable functions).\n\n  The kernel is given by:\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Matern.html)\n */\nexport class Matern {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The length scale of the kernel. If a float, an isotropic kernel is used. If an array, an anisotropic kernel is used where each dimension of l defines the length-scale of the respective feature dimension.\n\n      @defaultValue `1`\n     */\n    length_scale?: number | NDArray\n\n    /**\n      The lower and upper bound on ‘length\\_scale’. If set to “fixed”, ‘length\\_scale’ cannot be changed during hyperparameter tuning.\n     */\n    length_scale_bounds?: 'fixed'\n\n    /**\n      The parameter nu controlling the smoothness of the learned function. The smaller nu, the less smooth the approximated function is. For nu=inf, the kernel becomes equivalent to the RBF kernel and for nu=0.5 to the absolute exponential kernel. Important intermediate values are nu=1.5 (once differentiable functions) and nu=2.5 (twice differentiable functions). Note that values of nu not in \\[0.5, 1.5, 2.5, inf\\] incur a considerably higher computational cost (appr. 10 times higher) since they require to evaluate the modified Bessel function. Furthermore, in contrast to l, nu is kept fixed to its initial value and not optimized.\n\n      @defaultValue `1.5`\n     */\n    nu?: number\n  }) {\n    this.id = `Matern${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This Matern instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('Matern.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import Matern\ntry: bridgeMatern\nexcept NameError: bridgeMatern = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_Matern = {'length_scale': np.array(${\n      this.opts['length_scale'] ?? undefined\n    }) if ${\n      this.opts['length_scale'] !== undefined\n    } else None, 'length_scale_bounds': ${\n      this.opts['length_scale_bounds'] ?? undefined\n    }, 'nu': ${this.opts['nu'] ?? undefined}}\n\nctor_Matern = {k: v for k, v in ctor_Matern.items() if v is not None}`\n\n    await this._py.ex`bridgeMatern[${this.id}] = Matern(**ctor_Matern)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeMatern[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: NDArray[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) if evaluated instead.\n     */\n    Y?: NDArray[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is `undefined`.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This Matern instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Matern must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Matern___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_Matern___call__ = {k: v for k, v in pms_Matern___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Matern___call__ = bridgeMatern[${this.id}].__call__(**pms_Matern___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Matern___call__.tolist() if hasattr(res_Matern___call__, 'tolist') else res_Matern___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Matern instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Matern must call init() before clone_with_theta()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Matern_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_Matern_clone_with_theta = {k: v for k, v in pms_Matern_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Matern_clone_with_theta = bridgeMatern[${this.id}].clone_with_theta(**pms_Matern_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Matern_clone_with_theta.tolist() if hasattr(res_Matern_clone_with_theta, 'tolist') else res_Matern_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: NDArray[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This Matern instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Matern must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Matern_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_Matern_diag = {k: v for k, v in pms_Matern_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Matern_diag = bridgeMatern[${this.id}].diag(**pms_Matern_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Matern_diag.tolist() if hasattr(res_Matern_diag, 'tolist') else res_Matern_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Matern instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Matern must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Matern_is_stationary = {}\n\npms_Matern_is_stationary = {k: v for k, v in pms_Matern_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Matern_is_stationary = bridgeMatern[${this.id}].is_stationary(**pms_Matern_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Matern_is_stationary.tolist() if hasattr(res_Matern_is_stationary, 'tolist') else res_Matern_is_stationary`\n  }\n\n  get anisotropic(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Matern instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Matern must call init() before accessing anisotropic')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_Matern_anisotropic = bridgeMatern[${this.id}].anisotropic`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_Matern_anisotropic.tolist() if hasattr(attr_Matern_anisotropic, 'tolist') else attr_Matern_anisotropic`\n    })()\n  }\n\n  get hyperparameter_length_scale(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Matern instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'Matern must call init() before accessing hyperparameter_length_scale'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_Matern_hyperparameter_length_scale = bridgeMatern[${this.id}].hyperparameter_length_scale`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_Matern_hyperparameter_length_scale.tolist() if hasattr(attr_Matern_hyperparameter_length_scale, 'tolist') else attr_Matern_hyperparameter_length_scale`\n    })()\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Wrapper for kernels in sklearn.metrics.pairwise.\n\n  A thin wrapper around the functionality of the kernels in sklearn.metrics.pairwise.\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.PairwiseKernel.html)\n */\nexport class PairwiseKernel {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      Parameter gamma of the pairwise kernel specified by metric. It should be positive.\n\n      @defaultValue `1`\n     */\n    gamma?: number\n\n    /**\n      The lower and upper bound on ‘gamma’. If set to “fixed”, ‘gamma’ cannot be changed during hyperparameter tuning.\n     */\n    gamma_bounds?: 'fixed'\n\n    /**\n      The metric to use when calculating kernel between instances in a feature array. If metric is a string, it must be one of the metrics in pairwise.PAIRWISE\\_KERNEL\\_FUNCTIONS. If metric is “precomputed”, X is assumed to be a kernel matrix. Alternatively, if metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays from X as input and return a value indicating the distance between them.\n\n      @defaultValue `'linear'`\n     */\n    metric?:\n      | 'linear'\n      | 'additive_chi2'\n      | 'chi2'\n      | 'poly'\n      | 'polynomial'\n      | 'rbf'\n      | 'laplacian'\n      | 'sigmoid'\n      | 'cosine'\n\n    /**\n      All entries of this dict (if any) are passed as keyword arguments to the pairwise kernel function.\n     */\n    pairwise_kernels_kwargs?: any\n  }) {\n    this.id = `PairwiseKernel${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This PairwiseKernel instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('PairwiseKernel.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import PairwiseKernel\ntry: bridgePairwiseKernel\nexcept NameError: bridgePairwiseKernel = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_PairwiseKernel = {'gamma': ${\n      this.opts['gamma'] ?? undefined\n    }, 'gamma_bounds': ${this.opts['gamma_bounds'] ?? undefined}, 'metric': ${\n      this.opts['metric'] ?? undefined\n    }, 'pairwise_kernels_kwargs': ${\n      this.opts['pairwise_kernels_kwargs'] ?? undefined\n    }}\n\nctor_PairwiseKernel = {k: v for k, v in ctor_PairwiseKernel.items() if v is not None}`\n\n    await this._py\n      .ex`bridgePairwiseKernel[${this.id}] = PairwiseKernel(**ctor_PairwiseKernel)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgePairwiseKernel[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: NDArray[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) if evaluated instead.\n     */\n    Y?: NDArray[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is `undefined`.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This PairwiseKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('PairwiseKernel must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_PairwiseKernel___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_PairwiseKernel___call__ = {k: v for k, v in pms_PairwiseKernel___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_PairwiseKernel___call__ = bridgePairwiseKernel[${this.id}].__call__(**pms_PairwiseKernel___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_PairwiseKernel___call__.tolist() if hasattr(res_PairwiseKernel___call__, 'tolist') else res_PairwiseKernel___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This PairwiseKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'PairwiseKernel must call init() before clone_with_theta()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_PairwiseKernel_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_PairwiseKernel_clone_with_theta = {k: v for k, v in pms_PairwiseKernel_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_PairwiseKernel_clone_with_theta = bridgePairwiseKernel[${this.id}].clone_with_theta(**pms_PairwiseKernel_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_PairwiseKernel_clone_with_theta.tolist() if hasattr(res_PairwiseKernel_clone_with_theta, 'tolist') else res_PairwiseKernel_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: NDArray[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This PairwiseKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('PairwiseKernel must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_PairwiseKernel_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_PairwiseKernel_diag = {k: v for k, v in pms_PairwiseKernel_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_PairwiseKernel_diag = bridgePairwiseKernel[${this.id}].diag(**pms_PairwiseKernel_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_PairwiseKernel_diag.tolist() if hasattr(res_PairwiseKernel_diag, 'tolist') else res_PairwiseKernel_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This PairwiseKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('PairwiseKernel must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_PairwiseKernel_is_stationary = {}\n\npms_PairwiseKernel_is_stationary = {k: v for k, v in pms_PairwiseKernel_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_PairwiseKernel_is_stationary = bridgePairwiseKernel[${this.id}].is_stationary(**pms_PairwiseKernel_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_PairwiseKernel_is_stationary.tolist() if hasattr(res_PairwiseKernel_is_stationary, 'tolist') else res_PairwiseKernel_is_stationary`\n  }\n\n  get hyperparameter_gamma(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This PairwiseKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'PairwiseKernel must call init() before accessing hyperparameter_gamma'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_PairwiseKernel_hyperparameter_gamma = bridgePairwiseKernel[${this.id}].hyperparameter_gamma`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_PairwiseKernel_hyperparameter_gamma.tolist() if hasattr(attr_PairwiseKernel_hyperparameter_gamma, 'tolist') else attr_PairwiseKernel_hyperparameter_gamma`\n    })()\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  The `Product` kernel takes two kernels \\\\(k\\_1\\\\) and \\\\(k\\_2\\\\) and combines them via\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Product.html)\n */\nexport class Product {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The first base-kernel of the product-kernel\n     */\n    k1?: any\n\n    /**\n      The second base-kernel of the product-kernel\n     */\n    k2?: any\n  }) {\n    this.id = `Product${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This Product instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('Product.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import Product\ntry: bridgeProduct\nexcept NameError: bridgeProduct = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_Product = {'k1': ${\n      this.opts['k1'] ?? undefined\n    }, 'k2': ${this.opts['k2'] ?? undefined}}\n\nctor_Product = {k: v for k, v in ctor_Product.items() if v is not None}`\n\n    await this._py.ex`bridgeProduct[${this.id}] = Product(**ctor_Product)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeProduct[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: ArrayLike[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) is evaluated instead.\n     */\n    Y?: ArrayLike[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This Product instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Product must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Product___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_Product___call__ = {k: v for k, v in pms_Product___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Product___call__ = bridgeProduct[${this.id}].__call__(**pms_Product___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Product___call__.tolist() if hasattr(res_Product___call__, 'tolist') else res_Product___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Product instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Product must call init() before clone_with_theta()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Product_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_Product_clone_with_theta = {k: v for k, v in pms_Product_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Product_clone_with_theta = bridgeProduct[${this.id}].clone_with_theta(**pms_Product_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Product_clone_with_theta.tolist() if hasattr(res_Product_clone_with_theta, 'tolist') else res_Product_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Argument to the kernel.\n     */\n    X?: ArrayLike[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This Product instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Product must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Product_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_Product_diag = {k: v for k, v in pms_Product_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Product_diag = bridgeProduct[${this.id}].diag(**pms_Product_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Product_diag.tolist() if hasattr(res_Product_diag, 'tolist') else res_Product_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Product instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Product must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Product_is_stationary = {}\n\npms_Product_is_stationary = {k: v for k, v in pms_Product_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Product_is_stationary = bridgeProduct[${this.id}].is_stationary(**pms_Product_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Product_is_stationary.tolist() if hasattr(res_Product_is_stationary, 'tolist') else res_Product_is_stationary`\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Rational Quadratic kernel.\n\n  The RationalQuadratic kernel can be seen as a scale mixture (an infinite sum) of RBF kernels with different characteristic length scales. It is parameterized by a length scale parameter \\\\(l>0\\\\) and a scale mixture parameter \\\\(\\\\alpha>0\\\\). Only the isotropic variant where length\\_scale \\\\(l\\\\) is a scalar is supported at the moment. The kernel is given by:\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RationalQuadratic.html)\n */\nexport class RationalQuadratic {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The length scale of the kernel.\n\n      @defaultValue `1`\n     */\n    length_scale?: any\n\n    /**\n      Scale mixture parameter\n\n      @defaultValue `1`\n     */\n    alpha?: any\n\n    /**\n      The lower and upper bound on ‘length\\_scale’. If set to “fixed”, ‘length\\_scale’ cannot be changed during hyperparameter tuning.\n     */\n    length_scale_bounds?: 'fixed'\n\n    /**\n      The lower and upper bound on ‘alpha’. If set to “fixed”, ‘alpha’ cannot be changed during hyperparameter tuning.\n     */\n    alpha_bounds?: 'fixed'\n  }) {\n    this.id = `RationalQuadratic${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This RationalQuadratic instance has already been disposed'\n      )\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('RationalQuadratic.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import RationalQuadratic\ntry: bridgeRationalQuadratic\nexcept NameError: bridgeRationalQuadratic = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_RationalQuadratic = {'length_scale': ${\n      this.opts['length_scale'] ?? undefined\n    }, 'alpha': ${this.opts['alpha'] ?? undefined}, 'length_scale_bounds': ${\n      this.opts['length_scale_bounds'] ?? undefined\n    }, 'alpha_bounds': ${this.opts['alpha_bounds'] ?? undefined}}\n\nctor_RationalQuadratic = {k: v for k, v in ctor_RationalQuadratic.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeRationalQuadratic[${this.id}] = RationalQuadratic(**ctor_RationalQuadratic)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeRationalQuadratic[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: NDArray[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) if evaluated instead.\n     */\n    Y?: NDArray[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is `undefined`.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This RationalQuadratic instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('RationalQuadratic must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_RationalQuadratic___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_RationalQuadratic___call__ = {k: v for k, v in pms_RationalQuadratic___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_RationalQuadratic___call__ = bridgeRationalQuadratic[${this.id}].__call__(**pms_RationalQuadratic___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_RationalQuadratic___call__.tolist() if hasattr(res_RationalQuadratic___call__, 'tolist') else res_RationalQuadratic___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This RationalQuadratic instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'RationalQuadratic must call init() before clone_with_theta()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_RationalQuadratic_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_RationalQuadratic_clone_with_theta = {k: v for k, v in pms_RationalQuadratic_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_RationalQuadratic_clone_with_theta = bridgeRationalQuadratic[${this.id}].clone_with_theta(**pms_RationalQuadratic_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_RationalQuadratic_clone_with_theta.tolist() if hasattr(res_RationalQuadratic_clone_with_theta, 'tolist') else res_RationalQuadratic_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: NDArray[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This RationalQuadratic instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('RationalQuadratic must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_RationalQuadratic_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_RationalQuadratic_diag = {k: v for k, v in pms_RationalQuadratic_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_RationalQuadratic_diag = bridgeRationalQuadratic[${this.id}].diag(**pms_RationalQuadratic_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_RationalQuadratic_diag.tolist() if hasattr(res_RationalQuadratic_diag, 'tolist') else res_RationalQuadratic_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This RationalQuadratic instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'RationalQuadratic must call init() before is_stationary()'\n      )\n    }\n\n    // set up method params\n    await this._py.ex`pms_RationalQuadratic_is_stationary = {}\n\npms_RationalQuadratic_is_stationary = {k: v for k, v in pms_RationalQuadratic_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_RationalQuadratic_is_stationary = bridgeRationalQuadratic[${this.id}].is_stationary(**pms_RationalQuadratic_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_RationalQuadratic_is_stationary.tolist() if hasattr(res_RationalQuadratic_is_stationary, 'tolist') else res_RationalQuadratic_is_stationary`\n  }\n\n  get hyperparameter_alpha(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This RationalQuadratic instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'RationalQuadratic must call init() before accessing hyperparameter_alpha'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_RationalQuadratic_hyperparameter_alpha = bridgeRationalQuadratic[${this.id}].hyperparameter_alpha`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_RationalQuadratic_hyperparameter_alpha.tolist() if hasattr(attr_RationalQuadratic_hyperparameter_alpha, 'tolist') else attr_RationalQuadratic_hyperparameter_alpha`\n    })()\n  }\n\n  get hyperparameter_length_scale(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This RationalQuadratic instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'RationalQuadratic must call init() before accessing hyperparameter_length_scale'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_RationalQuadratic_hyperparameter_length_scale = bridgeRationalQuadratic[${this.id}].hyperparameter_length_scale`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_RationalQuadratic_hyperparameter_length_scale.tolist() if hasattr(attr_RationalQuadratic_hyperparameter_length_scale, 'tolist') else attr_RationalQuadratic_hyperparameter_length_scale`\n    })()\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Radial basis function kernel (aka squared-exponential kernel).\n\n  The RBF kernel is a stationary kernel. It is also known as the “squared exponential” kernel. It is parameterized by a length scale parameter \\\\(l>0\\\\), which can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs X (anisotropic variant of the kernel). The kernel is given by:\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html)\n */\nexport class RBF {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The length scale of the kernel. If a float, an isotropic kernel is used. If an array, an anisotropic kernel is used where each dimension of l defines the length-scale of the respective feature dimension.\n\n      @defaultValue `1`\n     */\n    length_scale?: number | NDArray\n\n    /**\n      The lower and upper bound on ‘length\\_scale’. If set to “fixed”, ‘length\\_scale’ cannot be changed during hyperparameter tuning.\n     */\n    length_scale_bounds?: 'fixed'\n  }) {\n    this.id = `RBF${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This RBF instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('RBF.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import RBF\ntry: bridgeRBF\nexcept NameError: bridgeRBF = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_RBF = {'length_scale': np.array(${\n      this.opts['length_scale'] ?? undefined\n    }) if ${\n      this.opts['length_scale'] !== undefined\n    } else None, 'length_scale_bounds': ${\n      this.opts['length_scale_bounds'] ?? undefined\n    }}\n\nctor_RBF = {k: v for k, v in ctor_RBF.items() if v is not None}`\n\n    await this._py.ex`bridgeRBF[${this.id}] = RBF(**ctor_RBF)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeRBF[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: NDArray[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) if evaluated instead.\n     */\n    Y?: NDArray[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is `undefined`.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This RBF instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('RBF must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_RBF___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_RBF___call__ = {k: v for k, v in pms_RBF___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_RBF___call__ = bridgeRBF[${this.id}].__call__(**pms_RBF___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_RBF___call__.tolist() if hasattr(res_RBF___call__, 'tolist') else res_RBF___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This RBF instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('RBF must call init() before clone_with_theta()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_RBF_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_RBF_clone_with_theta = {k: v for k, v in pms_RBF_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_RBF_clone_with_theta = bridgeRBF[${this.id}].clone_with_theta(**pms_RBF_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_RBF_clone_with_theta.tolist() if hasattr(res_RBF_clone_with_theta, 'tolist') else res_RBF_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: NDArray[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This RBF instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('RBF must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_RBF_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_RBF_diag = {k: v for k, v in pms_RBF_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py.ex`res_RBF_diag = bridgeRBF[${this.id}].diag(**pms_RBF_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_RBF_diag.tolist() if hasattr(res_RBF_diag, 'tolist') else res_RBF_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This RBF instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('RBF must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_RBF_is_stationary = {}\n\npms_RBF_is_stationary = {k: v for k, v in pms_RBF_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_RBF_is_stationary = bridgeRBF[${this.id}].is_stationary(**pms_RBF_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_RBF_is_stationary.tolist() if hasattr(res_RBF_is_stationary, 'tolist') else res_RBF_is_stationary`\n  }\n\n  get anisotropic(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This RBF instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('RBF must call init() before accessing anisotropic')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_RBF_anisotropic = bridgeRBF[${this.id}].anisotropic`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_RBF_anisotropic.tolist() if hasattr(attr_RBF_anisotropic, 'tolist') else attr_RBF_anisotropic`\n    })()\n  }\n\n  get hyperparameter_length_scale(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This RBF instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'RBF must call init() before accessing hyperparameter_length_scale'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_RBF_hyperparameter_length_scale = bridgeRBF[${this.id}].hyperparameter_length_scale`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_RBF_hyperparameter_length_scale.tolist() if hasattr(attr_RBF_hyperparameter_length_scale, 'tolist') else attr_RBF_hyperparameter_length_scale`\n    })()\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  The `Sum` kernel takes two kernels \\\\(k\\_1\\\\) and \\\\(k\\_2\\\\) and combines them via\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Sum.html)\n */\nexport class Sum {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The first base-kernel of the sum-kernel\n     */\n    k1?: any\n\n    /**\n      The second base-kernel of the sum-kernel\n     */\n    k2?: any\n  }) {\n    this.id = `Sum${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This Sum instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('Sum.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import Sum\ntry: bridgeSum\nexcept NameError: bridgeSum = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_Sum = {'k1': ${\n      this.opts['k1'] ?? undefined\n    }, 'k2': ${this.opts['k2'] ?? undefined}}\n\nctor_Sum = {k: v for k, v in ctor_Sum.items() if v is not None}`\n\n    await this._py.ex`bridgeSum[${this.id}] = Sum(**ctor_Sum)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeSum[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: ArrayLike[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) is evaluated instead.\n     */\n    Y?: ArrayLike[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This Sum instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Sum must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Sum___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_Sum___call__ = {k: v for k, v in pms_Sum___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Sum___call__ = bridgeSum[${this.id}].__call__(**pms_Sum___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Sum___call__.tolist() if hasattr(res_Sum___call__, 'tolist') else res_Sum___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Sum instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Sum must call init() before clone_with_theta()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Sum_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_Sum_clone_with_theta = {k: v for k, v in pms_Sum_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Sum_clone_with_theta = bridgeSum[${this.id}].clone_with_theta(**pms_Sum_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Sum_clone_with_theta.tolist() if hasattr(res_Sum_clone_with_theta, 'tolist') else res_Sum_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to `np.diag(self(X))`; however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Argument to the kernel.\n     */\n    X?: ArrayLike[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This Sum instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Sum must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Sum_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_Sum_diag = {k: v for k, v in pms_Sum_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py.ex`res_Sum_diag = bridgeSum[${this.id}].diag(**pms_Sum_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Sum_diag.tolist() if hasattr(res_Sum_diag, 'tolist') else res_Sum_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Sum instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Sum must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Sum_is_stationary = {}\n\npms_Sum_is_stationary = {k: v for k, v in pms_Sum_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Sum_is_stationary = bridgeSum[${this.id}].is_stationary(**pms_Sum_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Sum_is_stationary.tolist() if hasattr(res_Sum_is_stationary, 'tolist') else res_Sum_is_stationary`\n  }\n}\n","/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  White kernel.\n\n  The main use-case of this kernel is as part of a sum-kernel where it explains the noise of the signal as independently and identically normally-distributed. The parameter noise\\_level equals the variance of this noise.\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.html)\n */\nexport class WhiteKernel {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      Parameter controlling the noise level (variance)\n\n      @defaultValue `1`\n     */\n    noise_level?: number\n\n    /**\n      The lower and upper bound on ‘noise\\_level’. If set to “fixed”, ‘noise\\_level’ cannot be changed during hyperparameter tuning.\n     */\n    noise_level_bounds?: 'fixed'\n  }) {\n    this.id = `WhiteKernel${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This WhiteKernel instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('WhiteKernel.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.gaussian_process.kernels import WhiteKernel\ntry: bridgeWhiteKernel\nexcept NameError: bridgeWhiteKernel = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_WhiteKernel = {'noise_level': ${\n      this.opts['noise_level'] ?? undefined\n    }, 'noise_level_bounds': ${this.opts['noise_level_bounds'] ?? undefined}}\n\nctor_WhiteKernel = {k: v for k, v in ctor_WhiteKernel.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeWhiteKernel[${this.id}] = WhiteKernel(**ctor_WhiteKernel)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeWhiteKernel[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Return the kernel k(X, Y) and optionally its gradient.\n   */\n  async __call__(opts: {\n    /**\n      Left argument of the returned kernel k(X, Y)\n     */\n    X?: ArrayLike[]\n\n    /**\n      Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) is evaluated instead.\n     */\n    Y?: ArrayLike[]\n\n    /**\n      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is `undefined`.\n\n      @defaultValue `false`\n     */\n    eval_gradient?: boolean\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This WhiteKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('WhiteKernel must call init() before __call__()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_WhiteKernel___call__ = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'Y': np.array(${\n      opts['Y'] ?? undefined\n    }) if ${opts['Y'] !== undefined} else None, 'eval_gradient': ${\n      opts['eval_gradient'] ?? undefined\n    }}\n\npms_WhiteKernel___call__ = {k: v for k, v in pms_WhiteKernel___call__.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_WhiteKernel___call__ = bridgeWhiteKernel[${this.id}].__call__(**pms_WhiteKernel___call__)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_WhiteKernel___call__.tolist() if hasattr(res_WhiteKernel___call__, 'tolist') else res_WhiteKernel___call__`\n  }\n\n  /**\n    Returns a clone of self with given hyperparameters theta.\n   */\n  async clone_with_theta(opts: {\n    /**\n      The hyperparameters\n     */\n    theta?: NDArray\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This WhiteKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('WhiteKernel must call init() before clone_with_theta()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_WhiteKernel_clone_with_theta = {'theta': np.array(${\n      opts['theta'] ?? undefined\n    }) if ${opts['theta'] !== undefined} else None}\n\npms_WhiteKernel_clone_with_theta = {k: v for k, v in pms_WhiteKernel_clone_with_theta.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_WhiteKernel_clone_with_theta = bridgeWhiteKernel[${this.id}].clone_with_theta(**pms_WhiteKernel_clone_with_theta)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_WhiteKernel_clone_with_theta.tolist() if hasattr(res_WhiteKernel_clone_with_theta, 'tolist') else res_WhiteKernel_clone_with_theta`\n  }\n\n  /**\n    Returns the diagonal of the kernel k(X, X).\n\n    The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.\n   */\n  async diag(opts: {\n    /**\n      Argument to the kernel.\n     */\n    X?: ArrayLike[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This WhiteKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('WhiteKernel must call init() before diag()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_WhiteKernel_diag = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_WhiteKernel_diag = {k: v for k, v in pms_WhiteKernel_diag.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_WhiteKernel_diag = bridgeWhiteKernel[${this.id}].diag(**pms_WhiteKernel_diag)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_WhiteKernel_diag.tolist() if hasattr(res_WhiteKernel_diag, 'tolist') else res_WhiteKernel_diag`\n  }\n\n  /**\n    Returns whether the kernel is stationary.\n   */\n  async is_stationary(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This WhiteKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('WhiteKernel must call init() before is_stationary()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_WhiteKernel_is_stationary = {}\n\npms_WhiteKernel_is_stationary = {k: v for k, v in pms_WhiteKernel_is_stationary.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_WhiteKernel_is_stationary = bridgeWhiteKernel[${this.id}].is_stationary(**pms_WhiteKernel_is_stationary)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_WhiteKernel_is_stationary.tolist() if hasattr(res_WhiteKernel_is_stationary, 'tolist') else res_WhiteKernel_is_stationary`\n  }\n\n  get hyperparameter_noise_level(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This WhiteKernel instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'WhiteKernel must call init() before accessing hyperparameter_noise_level'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_WhiteKernel_hyperparameter_noise_level = bridgeWhiteKernel[${this.id}].hyperparameter_noise_level`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_WhiteKernel_hyperparameter_noise_level.tolist() if hasattr(attr_WhiteKernel_hyperparameter_noise_level, 'tolist') else attr_WhiteKernel_hyperparameter_noise_level`\n    })()\n  }\n}\n"],"mappings":";AAGA,OAAO,YAAY;AAiBZ,IAAM,4BAAN,MAAgC;AAAA,EAQrC,YAAY,MAyDT;AA5DH,0BAA0B;AAC1B,uBAAuB;AA4DrB,SAAK,KAAK,4BAA4B,OAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AACtE,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,iDACb,KAAK,KAAK,QAAQ,KAAK,wBAEvB,KAAK,KAAK,WAAW,KAAK,mCAE1B,KAAK,KAAK,sBAAsB,KAAK,+BAErC,KAAK,KAAK,kBAAkB,KAAK,yBAChB,KAAK,KAAK,YAAY,KAAK,2BAC5C,KAAK,KAAK,cAAc,KAAK,2BAE7B,KAAK,KAAK,cAAc,KAAK,0BACX,KAAK,KAAK,aAAa,KAAK,qBAC9C,KAAK,KAAK,QAAQ,KAAK;AAAA;AAAA;AAKzB,UAAM,KAAK,IACR,qCAAqC,KAAK;AAE7C,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,yCAAyC,KAAK;AAE7D,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,IAAI,MAUO;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,yDAAyD;AAAA,IAC3E;AAGA,UAAM,KAAK,IAAI,wDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,yEAAyE,KAAK;AAGjF,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,qBAAqB,MAKV;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,sEACD,KAAK,SAAS,KAAK;AAAA;AAAA;AAMrB,UAAM,KAAK,IACR,0FAA0F,KAAK;AAGlG,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,wBAAwB,MAmBV;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,gFACD,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM,sCACxB,KAAK,eAAe,KAAK,2BACN,KAAK,cAAc,KAAK;AAAA;AAAA;AAK7C,UAAM,KAAK,IACR,6FAA6F,KAAK;AAGrG,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAQ,MAKO;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IAAI,4DACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,6EAA6E,KAAK;AAGrF,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAKK;AACvB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,kEACD,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,mFAAmF,KAAK;AAG3F,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,MAAM,MAeQ;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IAAI,0DACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,2EAA2E,KAAK;AAGnF,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,kBAAkB,MAKP;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,yEACD,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,uFAAuF,KAAK;AAG/F,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,kBAAgC;AAClC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,sFAAsF,KAAK;AAG9F,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iCAAkD;AACpD,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,qGAAqG,KAAK;AAG7G,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,WAA+B;AACjC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,+EAA+E,KAAK;AAGvF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,aAA8B;AAChC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,iFAAiF,KAAK;AAGzF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iBAAkC;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,qFAAqF,KAAK;AAG7F,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAsC;AACxC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,wFAAwF,KAAK;AAGhG,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;;;AC/nBA,OAAOA,aAAY;AAaZ,IAAM,2BAAN,MAA+B;AAAA,EAQpC,YAAY,MAkDT;AArDH,0BAA0B;AAC1B,uBAAuB;AAqDrB,SAAK,KAAK,2BAA2BA,QAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AACrE,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,gDACb,KAAK,KAAK,QAAQ,KAAK,6BACF,KAAK,KAAK,OAAO,KAAK,cAC3C,KAAK,KAAK,OAAO,MAAM,kCAEvB,KAAK,KAAK,WAAW,KAAK,mCAE1B,KAAK,KAAK,sBAAsB,KAAK,0BAErC,KAAK,KAAK,aAAa,KAAK,2BAE5B,KAAK,KAAK,cAAc,KAAK,wBACb,KAAK,KAAK,WAAW,KAAK,2BAC1C,KAAK,KAAK,cAAc,KAAK;AAAA;AAAA;AAK/B,UAAM,KAAK,IACR,oCAAoC,KAAK;AAE5C,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,wCAAwC,KAAK;AAE5D,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,IAAI,MAUO;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAGA,UAAM,KAAK,IAAI,uDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,uEAAuE,KAAK;AAG/E,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,qBAAqB,MAKV;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,qEACD,KAAK,SAAS,KAAK;AAAA;AAAA;AAMrB,UAAM,KAAK,IACR,wFAAwF,KAAK;AAGhG,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,wBAAwB,MAmBV;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,+EACD,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM,sCACxB,KAAK,eAAe,KAAK,2BACN,KAAK,cAAc,KAAK;AAAA;AAAA;AAK7C,UAAM,KAAK,IACR,2FAA2F,KAAK;AAGnG,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,QAAQ,MAmBO;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IAAI,2DACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,YAAY,KAAK,yBACL,KAAK,YAAY,KAAK;AAAA;AAAA;AAKzC,UAAM,KAAK,IACR,2EAA2E,KAAK;AAGnF,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAmBE;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IAAI,4DACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,kCACpB,KAAK,WAAW,KAAK,2BACF,KAAK,cAAc,KAAK;AAAA;AAAA;AAK7C,UAAM,KAAK,IACR,4EAA4E,KAAK;AAGpF,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,MAAM,MAeQ;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IAAI,yDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,yEAAyE,KAAK;AAGjF,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,oBAAoB,MAUT;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,uEACD,KAAK,YAAY,KAAK,yBACL,KAAK,YAAY,KAAK;AAAA;AAAA;AAKzC,UAAM,KAAK,IACR,uFAAuF,KAAK;AAG/F,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,kBAAkB,MAKP;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,wEACD,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,qFAAqF,KAAK;AAG7F,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,WAAiC;AACnC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,6EAA6E,KAAK;AAGrF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,WAA+B;AACjC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,6EAA6E,KAAK;AAGrF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,UAAwB;AAC1B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,4EAA4E,KAAK;AAGpF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,KAA2B;AAC7B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,uEAAuE,KAAK;AAG/E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,SAA6B;AAC/B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,2EAA2E,KAAK;AAGnF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iCAAkD;AACpD,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,mGAAmG,KAAK;AAG3G,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iBAAkC;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,mFAAmF,KAAK;AAG3F,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAsC;AACxC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,sFAAsF,KAAK;AAG9F,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;;;ACxvBA,OAAOC,aAAY;AASZ,IAAM,iBAAN,MAAqB;AAAA,EAQ1B,YAAY,MAKT;AARH,0BAA0B;AAC1B,uBAAuB;AAQrB,SAAK,KAAK,iBAAiBA,QAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC3D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,uCACb,KAAK,KAAK,SAAS,KAAK;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,0BAA0B,KAAK;AAElC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,8BAA8B,KAAK;AAElD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,SAAS,MAiBU;AACvB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAGA,UAAM,KAAK,IAAI,kDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,8DACD,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,gEAAgE,KAAK;AAGxE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKY;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,+CAA+C;AAAA,IACjE;AAGA,UAAM,KAAK,IAAI,8CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,oDAAoD,KAAK;AAG5D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,6DAA6D,KAAK;AAGrE,WAAO,KACJ;AAAA,EACL;AACF;;;ACjPA,OAAOC,aAAY;AAWZ,IAAM,iBAAN,MAAqB;AAAA,EAQ1B,YAAY,MAYT;AAfH,0BAA0B;AAC1B,uBAAuB;AAerB,SAAK,KAAK,iBAAiBA,QAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC3D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,8CACb,KAAK,KAAK,gBAAgB,KAAK,oCAE/B,KAAK,KAAK,uBAAuB,KAAK;AAAA;AAAA;AAKxC,UAAM,KAAK,IACR,0BAA0B,KAAK;AAElC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,8BAA8B,KAAK;AAElD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAiBQ;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAGA,UAAM,KAAK,IAAI,kDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,8DACD,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,gEAAgE,KAAK;AAGxE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,+CAA+C;AAAA,IACjE;AAGA,UAAM,KAAK,IAAI,8CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,oDAAoD,KAAK;AAG5D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,6DAA6D,KAAK;AAGrE,WAAO,KACJ;AAAA,EACL;AAAA,EAEA,IAAI,gCAA8C;AAChD,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,8EAA8E,KAAK;AAGtF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;;;AChRA,OAAOC,aAAY;AAWZ,IAAM,aAAN,MAAiB;AAAA,EAQtB,YAAY,MAYT;AAfH,0BAA0B;AAC1B,uBAAuB;AAerB,SAAK,KAAK,aAAaA,QAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AACvD,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,kDAAkD;AAAA,IACpE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,mCACb,KAAK,KAAK,SAAS,KAAK,6BACH,KAAK,KAAK,gBAAgB,KAAK;AAAA;AAAA;AAItD,UAAM,KAAK,IACR,sBAAsB,KAAK;AAE9B,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,0BAA0B,KAAK;AAE9C,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAiBQ;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,+CAA+C;AAAA,IACjE;AAGA,UAAM,KAAK,IAAI,8CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,gDAAgD,KAAK;AAGxD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,uDAAuD;AAAA,IACzE;AAGA,UAAM,KAAK,IAAI,0DACb,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,2CAA2C;AAAA,IAC7D;AAGA,UAAM,KAAK,IAAI,0CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,4CAA4C,KAAK;AAGpD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,qDAAqD,KAAK;AAG7D,WAAO,KACJ;AAAA,EACL;AAAA,EAEA,IAAI,yBAAuC;AACzC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,+DAA+D,KAAK;AAGvE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;;;AC3QA,OAAOC,aAAY;AASZ,IAAM,iBAAN,MAAqB;AAAA,EAQ1B,YAAY,MAUT;AAbH,0BAA0B;AAC1B,uBAAuB;AAarB,SAAK,KAAK,iBAAiBA,QAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC3D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,sCACb,KAAK,KAAK,QAAQ,KAAK,uBACR,KAAK,KAAK,UAAU,KAAK;AAAA;AAAA;AAI1C,UAAM,KAAK,IACR,0BAA0B,KAAK;AAElC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,8BAA8B,KAAK;AAElD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAiBQ;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAGA,UAAM,KAAK,IAAI,kDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,8DACD,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,gEAAgE,KAAK;AAGxE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,+CAA+C;AAAA,IACjE;AAGA,UAAM,KAAK,IAAI,8CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,oDAAoD,KAAK;AAG5D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,6DAA6D,KAAK;AAGrE,WAAO,KACJ;AAAA,EACL;AACF;;;ACpPA,OAAOC,aAAY;AAWZ,IAAM,iBAAN,MAAqB;AAAA,EAQ1B,YAAY,MAwBT;AA3BH,0BAA0B;AAC1B,uBAAuB;AA2BrB,SAAK,KAAK,iBAAiBA,QAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC3D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,4CACb,KAAK,KAAK,cAAc,KAAK,0BAE7B,KAAK,KAAK,aAAa,KAAK,kCAE5B,KAAK,KAAK,qBAAqB,KAAK,iCACX,KAAK,KAAK,oBAAoB,KAAK;AAAA;AAAA;AAI9D,UAAM,KAAK,IACR,0BAA0B,KAAK;AAElC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,8BAA8B,KAAK;AAElD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAiBQ;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAGA,UAAM,KAAK,IAAI,kDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,8DACD,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,gEAAgE,KAAK;AAGxE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,+CAA+C;AAAA,IACjE;AAGA,UAAM,KAAK,IAAI,8CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,oDAAoD,KAAK;AAG5D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,6DAA6D,KAAK;AAGrE,WAAO,KACJ;AAAA,EACL;AAAA,EAEA,IAAI,6BAA2C;AAC7C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,2EAA2E,KAAK;AAGnF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;;;AC9RA,OAAOC,aAAY;AASZ,IAAM,iBAAN,MAAqB;AAAA,EAQ1B,YAAY,MA2BT;AA9BH,0BAA0B;AAC1B,uBAAuB;AA8BrB,SAAK,KAAK,iBAAiBA,QAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC3D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,oCACb,KAAK,KAAK,MAAM,KAAK,yBACJ,KAAK,KAAK,YAAY,KAAK,qBAC5C,KAAK,KAAK,QAAQ,KAAK,yBACN,KAAK,KAAK,YAAY,KAAK,oBAC5C,KAAK,KAAK,OAAO,KAAK;AAAA;AAAA;AAKxB,UAAM,KAAK,IACR,0BAA0B,KAAK;AAElC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,8BAA8B,KAAK;AAElD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAAwB;AACrC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,MAAM,MAAwB;AAClC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,qDAAqD,KAAK;AAG7D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,MAAM,MAAwB;AAClC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,qDAAqD,KAAK;AAG7D,WAAO,KACJ;AAAA,EACL;AACF;;;ACvMA,OAAOC,aAAY;AASZ,IAAM,SAAN,MAAa;AAAA,EAQlB,YAAY,MAAW;AAHvB,0BAA0B;AAC1B,uBAAuB;AAGrB,SAAK,KAAK,SAASA,QAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AACnD,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,8CAA8C;AAAA,IAChE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI;AAAA;AAAA;AAIf,UAAM,KAAK,IAAI,kBAAkB,KAAK;AAEtC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,sBAAsB,KAAK;AAE1C,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAAwB;AACrC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,2CAA2C;AAAA,IAC7D;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,wCAAwC,KAAK;AAGhD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAGA,UAAM,KAAK,IAAI,sDACb,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,gDAAgD,KAAK;AAGxD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,uCAAuC;AAAA,IACzD;AAGA,UAAM,KAAK,IAAI,sCACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,oCAAoC,KAAK;AAG5C,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,6CAA6C,KAAK;AAGrD,WAAO,KACJ;AAAA,EACL;AACF;;;AC7MA,OAAOC,cAAY;AAaZ,IAAM,SAAN,MAAa;AAAA,EAQlB,YAAY,MAmBT;AAtBH,0BAA0B;AAC1B,uBAAuB;AAsBrB,SAAK,KAAK,SAASA,SAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AACnD,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,8CAA8C;AAAA,IAChE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,6CACb,KAAK,KAAK,cAAc,KAAK,cAE7B,KAAK,KAAK,cAAc,MAAM,4CAE9B,KAAK,KAAK,qBAAqB,KAAK,iBAC3B,KAAK,KAAK,IAAI,KAAK;AAAA;AAAA;AAI9B,UAAM,KAAK,IAAI,kBAAkB,KAAK;AAEtC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,sBAAsB,KAAK;AAE1C,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAiBQ;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,2CAA2C;AAAA,IAC7D;AAGA,UAAM,KAAK,IAAI,0CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,wCAAwC,KAAK;AAGhD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAGA,UAAM,KAAK,IAAI,sDACb,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,gDAAgD,KAAK;AAGxD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,uCAAuC;AAAA,IACzD;AAGA,UAAM,KAAK,IAAI,sCACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,oCAAoC,KAAK;AAG5C,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,6CAA6C,KAAK;AAGrD,WAAO,KACJ;AAAA,EACL;AAAA,EAEA,IAAI,cAA4B;AAC9B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,4CAA4C,KAAK;AAGpD,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA,EAEA,IAAI,8BAA4C;AAC9C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,4DAA4D,KAAK;AAGpE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;;;AC3SA,OAAOC,cAAY;AAWZ,IAAM,iBAAN,MAAqB;AAAA,EAQ1B,YAAY,MAiCT;AApCH,0BAA0B;AAC1B,uBAAuB;AAoCrB,SAAK,KAAK,iBAAiBA,SAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC3D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,qCACb,KAAK,KAAK,OAAO,KAAK,2BACH,KAAK,KAAK,cAAc,KAAK,qBAChD,KAAK,KAAK,QAAQ,KAAK,sCAEvB,KAAK,KAAK,yBAAyB,KAAK;AAAA;AAAA;AAK1C,UAAM,KAAK,IACR,0BAA0B,KAAK;AAElC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,8BAA8B,KAAK;AAElD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAiBQ;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAGA,UAAM,KAAK,IAAI,kDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,8DACD,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,gEAAgE,KAAK;AAGxE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,+CAA+C;AAAA,IACjE;AAGA,UAAM,KAAK,IAAI,8CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,oDAAoD,KAAK;AAG5D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,6DAA6D,KAAK;AAGrE,WAAO,KACJ;AAAA,EACL;AAAA,EAEA,IAAI,uBAAqC;AACvC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,qEAAqE,KAAK;AAG7E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;;;ACvSA,OAAOC,cAAY;AASZ,IAAM,UAAN,MAAc;AAAA,EAQnB,YAAY,MAUT;AAbH,0BAA0B;AAC1B,uBAAuB;AAarB,SAAK,KAAK,UAAUA,SAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AACpD,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACnE;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,+CAA+C;AAAA,IACjE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,2BACb,KAAK,KAAK,IAAI,KAAK,iBACV,KAAK,KAAK,IAAI,KAAK;AAAA;AAAA;AAI9B,UAAM,KAAK,IAAI,mBAAmB,KAAK;AAEvC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,uBAAuB,KAAK;AAE3C,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAiBQ;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACnE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,4CAA4C;AAAA,IAC9D;AAGA,UAAM,KAAK,IAAI,2CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,0CAA0C,KAAK;AAGlD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACnE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAGA,UAAM,KAAK,IAAI,uDACb,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,kDAAkD,KAAK;AAG1D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACnE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wCAAwC;AAAA,IAC1D;AAGA,UAAM,KAAK,IAAI,uCACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,sCAAsC,KAAK;AAG9C,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACnE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACnE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,+CAA+C,KAAK;AAGvD,WAAO,KACJ;AAAA,EACL;AACF;;;AChPA,OAAOC,cAAY;AAWZ,IAAM,oBAAN,MAAwB;AAAA,EAQ7B,YAAY,MAwBT;AA3BH,0BAA0B;AAC1B,uBAAuB;AA2BrB,SAAK,KAAK,oBAAoBA,SAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC9D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,yDAAyD;AAAA,IAC3E;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,+CACb,KAAK,KAAK,cAAc,KAAK,oBACjB,KAAK,KAAK,OAAO,KAAK,kCAClC,KAAK,KAAK,qBAAqB,KAAK,2BACjB,KAAK,KAAK,cAAc,KAAK;AAAA;AAAA;AAIlD,UAAM,KAAK,IACR,6BAA6B,KAAK;AAErC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,iCAAiC,KAAK;AAErD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAiBQ;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAGA,UAAM,KAAK,IAAI,qDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,8DAA8D,KAAK;AAGtE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,iEACD,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,sEAAsE,KAAK;AAG9E,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,kDAAkD;AAAA,IACpE;AAGA,UAAM,KAAK,IAAI,iDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,0DAA0D,KAAK;AAGlE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,mEAAmE,KAAK;AAG3E,WAAO,KACJ;AAAA,EACL;AAAA,EAEA,IAAI,uBAAqC;AACvC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,2EAA2E,KAAK;AAGnF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA,EAEA,IAAI,8BAA4C;AAC9C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,kFAAkF,KAAK;AAG1F,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;;;AClUA,OAAOC,cAAY;AAWZ,IAAM,MAAN,MAAU;AAAA,EAQf,YAAY,MAYT;AAfH,0BAA0B;AAC1B,uBAAuB;AAerB,SAAK,KAAK,MAAMA,SAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAChD,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,2CAA2C;AAAA,IAC7D;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,0CACb,KAAK,KAAK,cAAc,KAAK,cAE7B,KAAK,KAAK,cAAc,MAAM,4CAE9B,KAAK,KAAK,qBAAqB,KAAK;AAAA;AAAA;AAKtC,UAAM,KAAK,IAAI,eAAe,KAAK;AAEnC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,mBAAmB,KAAK;AAEvC,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAiBQ;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wCAAwC;AAAA,IAC1D;AAGA,UAAM,KAAK,IAAI,uCACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,kCAAkC,KAAK;AAG1C,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAGA,UAAM,KAAK,IAAI,mDACb,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,0CAA0C,KAAK;AAGlD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,oCAAoC;AAAA,IACtD;AAGA,UAAM,KAAK,IAAI,mCACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IAAI,8BAA8B,KAAK;AAGlD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,uCAAuC,KAAK;AAG/C,WAAO,KACJ;AAAA,EACL;AAAA,EAEA,IAAI,cAA4B;AAC9B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,sCAAsC,KAAK;AAG9C,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA,EAEA,IAAI,8BAA4C;AAC9C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,sDAAsD,KAAK;AAG9D,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;;;ACjSA,OAAOC,cAAY;AASZ,IAAM,MAAN,MAAU;AAAA,EAQf,YAAY,MAUT;AAbH,0BAA0B;AAC1B,uBAAuB;AAarB,SAAK,KAAK,MAAMA,SAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAChD,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,2CAA2C;AAAA,IAC7D;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,uBACb,KAAK,KAAK,IAAI,KAAK,iBACV,KAAK,KAAK,IAAI,KAAK;AAAA;AAAA;AAI9B,UAAM,KAAK,IAAI,eAAe,KAAK;AAEnC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,mBAAmB,KAAK;AAEvC,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAiBQ;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wCAAwC;AAAA,IAC1D;AAGA,UAAM,KAAK,IAAI,uCACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,kCAAkC,KAAK;AAG1C,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAGA,UAAM,KAAK,IAAI,mDACb,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,0CAA0C,KAAK;AAGlD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,oCAAoC;AAAA,IACtD;AAGA,UAAM,KAAK,IAAI,mCACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IAAI,8BAA8B,KAAK;AAGlD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,uCAAuC,KAAK;AAG/C,WAAO,KACJ;AAAA,EACL;AACF;;;AC/OA,OAAOC,cAAY;AAWZ,IAAM,cAAN,MAAkB;AAAA,EAQvB,YAAY,MAYT;AAfH,0BAA0B;AAC1B,uBAAuB;AAerB,SAAK,KAAK,cAAcA,SAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AACxD,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,wCACb,KAAK,KAAK,aAAa,KAAK,iCACH,KAAK,KAAK,oBAAoB,KAAK;AAAA;AAAA;AAI9D,UAAM,KAAK,IACR,uBAAuB,KAAK;AAE/B,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,2BAA2B,KAAK;AAE/C,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,MAiBQ;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAGA,UAAM,KAAK,IAAI,+CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,sCACpB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,kDAAkD,KAAK;AAG1D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,iBAAiB,MAKN;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAGA,UAAM,KAAK,IAAI,2DACb,KAAK,OAAO,KAAK,cACX,KAAK,OAAO,MAAM;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,0DAA0D,KAAK;AAGlE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,MAKU;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,4CAA4C;AAAA,IAC9D;AAGA,UAAM,KAAK,IAAI,2CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,8CAA8C,KAAK;AAGtD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAAwB;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,uDAAuD,KAAK;AAG/D,WAAO,KACJ;AAAA,EACL;AAAA,EAEA,IAAI,6BAA2C;AAC7C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,qEAAqE,KAAK;AAG7E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;","names":["crypto","crypto","crypto","crypto","crypto","crypto","crypto","crypto","crypto","crypto","crypto","crypto","crypto","crypto","crypto"]}