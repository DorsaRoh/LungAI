import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  C-Support Vector Classification.

  The implementation is based on libsvm. The fit time scales at least quadratically with the number of samples and may be impractical beyond tens of thousands of samples. For large datasets consider using [`LinearSVC`](sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC "sklearn.svm.LinearSVC") or [`SGDClassifier`](sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier "sklearn.linear_model.SGDClassifier") instead, possibly after a [`Nystroem`](sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem "sklearn.kernel_approximation.Nystroem") transformer or other [Kernel Approximation](../kernel_approximation.html#kernel-approximation).

  The multiclass support is handled according to a one-vs-one scheme.

  For details on the precise mathematical formulation of the provided kernel functions and how `gamma`, `coef0` and `degree` affect each other, see the corresponding section in the narrative documentation: [Kernel functions](../svm.html#svm-kernels).

  Read more in the [User Guide](../svm.html#svm-classification).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)
 */
export declare class SVC {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.
    
          @defaultValue `1`
         */
        C?: number;
        /**
          Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape `(n\_samples, n\_samples)`. For an intuitive visualization of different kernel types see [Plot classification boundaries with different SVM Kernels](../../auto_examples/svm/plot_svm_kernels.html#sphx-glr-auto-examples-svm-plot-svm-kernels-py).
    
          @defaultValue `'rbf'`
         */
        kernel?: 'linear' | 'poly' | 'rbf' | 'sigmoid' | 'precomputed';
        /**
          Degree of the polynomial kernel function (‘poly’). Must be non-negative. Ignored by all other kernels.
    
          @defaultValue `3`
         */
        degree?: number;
        /**
          Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.
    
          @defaultValue `'scale'`
         */
        gamma?: 'scale' | 'auto' | number;
        /**
          Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.
    
          @defaultValue `0`
         */
        coef0?: number;
        /**
          Whether to use the shrinking heuristic. See the [User Guide](../svm.html#shrinking-svm).
    
          @defaultValue `true`
         */
        shrinking?: boolean;
        /**
          Whether to enable probability estimates. This must be enabled prior to calling `fit`, will slow down that method as it internally uses 5-fold cross-validation, and `predict\_proba` may be inconsistent with `predict`. Read more in the [User Guide](../svm.html#scores-probabilities).
    
          @defaultValue `false`
         */
        probability?: boolean;
        /**
          Tolerance for stopping criterion.
    
          @defaultValue `0.001`
         */
        tol?: number;
        /**
          Specify the size of the kernel cache (in MB).
    
          @defaultValue `200`
         */
        cache_size?: number;
        /**
          Set the parameter C of class i to class\_weight\[i\]\*C for SVC. If not given, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as `n\_samples / (n\_classes \* np.bincount(y))`.
         */
        class_weight?: any | 'balanced';
        /**
          Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.
    
          @defaultValue `false`
         */
        verbose?: boolean;
        /**
          Hard limit on iterations within solver, or -1 for no limit.
    
          @defaultValue `-1`
         */
        max_iter?: number;
        /**
          Whether to return a one-vs-rest (‘ovr’) decision function of shape (n\_samples, n\_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n\_samples, n\_classes \* (n\_classes - 1) / 2). However, note that internally, one-vs-one (‘ovo’) is always used as a multi-class strategy to train models; an ovr matrix is only constructed from the ovo matrix. The parameter is ignored for binary classification.
    
          @defaultValue `'ovr'`
         */
        decision_function_shape?: 'ovo' | 'ovr';
        /**
          If true, `decision\_function\_shape='ovr'`, and number of classes > 2, [predict](../../glossary.html#term-predict) will break ties according to the confidence values of [decision\_function](../../glossary.html#term-decision_function); otherwise the first class among the tied classes is returned. Please note that breaking ties comes at a relatively high computational cost compared to a simple predict.
    
          @defaultValue `false`
         */
        break_ties?: boolean;
        /**
          Controls the pseudo random number generation for shuffling the data for probability estimates. Ignored when `probability` is `false`. Pass an int for reproducible output across multiple function calls. See [Glossary](../../glossary.html#term-random_state).
         */
        random_state?: number;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Evaluate the decision function for the samples in X.
     */
    decision_function(opts: {
        /**
          The input samples.
         */
        X?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Fit the SVM model according to the given training data.
     */
    fit(opts: {
        /**
          Training vectors, where `n\_samples` is the number of samples and `n\_features` is the number of features. For kernel=”precomputed”, the expected shape of X is (n\_samples, n\_samples).
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          Target values (class labels in classification, real numbers in regression).
         */
        y?: ArrayLike;
        /**
          Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.
         */
        sample_weight?: ArrayLike;
    }): Promise<any>;
    /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
    get_metadata_routing(opts: {
        /**
          A [`MetadataRequest`](sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest "sklearn.utils.metadata_routing.MetadataRequest") encapsulating routing information.
         */
        routing?: any;
    }): Promise<any>;
    /**
      Perform classification on samples in X.
  
      For an one-class model, +1 or -1 is returned.
     */
    predict(opts: {
        /**
          For kernel=”precomputed”, the expected shape of X is (n\_samples\_test, n\_samples\_train).
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray>;
    /**
      Compute log probabilities of possible outcomes for samples in X.
  
      The model need to have probability information computed at training time: fit with attribute `probability` set to `true`.
     */
    predict_log_proba(opts: {
        /**
          For kernel=”precomputed”, the expected shape of X is (n\_samples\_test, n\_samples\_train).
         */
        X?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Compute probabilities of possible outcomes for samples in X.
  
      The model needs to have probability information computed at training time: fit with attribute `probability` set to `true`.
     */
    predict_proba(opts: {
        /**
          For kernel=”precomputed”, the expected shape of X is (n\_samples\_test, n\_samples\_train).
         */
        X?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
    score(opts: {
        /**
          Test samples.
         */
        X?: ArrayLike[];
        /**
          True labels for `X`.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
    set_fit_request(opts: {
        /**
          Metadata routing for `sample\_weight` parameter in `fit`.
         */
        sample_weight?: string | boolean;
    }): Promise<any>;
    /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
    set_score_request(opts: {
        /**
          Metadata routing for `sample\_weight` parameter in `score`.
         */
        sample_weight?: string | boolean;
    }): Promise<any>;
    /**
      Multipliers of parameter C for each class. Computed based on the `class\_weight` parameter.
     */
    get class_weight_(): Promise<NDArray>;
    /**
      The classes labels.
     */
    get classes_(): Promise<NDArray>;
    /**
      Dual coefficients of the support vector in the decision function (see [Mathematical formulation](../sgd.html#sgd-mathematical-formulation)), multiplied by their targets. For multiclass, coefficient for all 1-vs-1 classifiers. The layout of the coefficients in the multiclass case is somewhat non-trivial. See the [multi-class section of the User Guide](../svm.html#svm-multi-class) for details.
     */
    get dual_coef_(): Promise<NDArray[]>;
    /**
      0 if correctly fitted, 1 otherwise (will raise warning)
     */
    get fit_status_(): Promise<number>;
    /**
      Constants in decision function.
     */
    get intercept_(): Promise<NDArray>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      Number of iterations run by the optimization routine to fit the model. The shape of this attribute depends on the number of models optimized which in turn depends on the number of classes.
     */
    get n_iter_(): Promise<NDArray>;
    /**
      Indices of support vectors.
     */
    get support_(): Promise<NDArray>;
    /**
      Support vectors. An empty array if kernel is precomputed.
     */
    get support_vectors_(): Promise<NDArray[]>;
    /**
      Array dimensions of training vector `X`.
     */
    get shape_fit_(): Promise<any[]>;
}
//# sourceMappingURL=SVC.d.ts.map