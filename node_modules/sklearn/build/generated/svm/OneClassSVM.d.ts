import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Unsupervised Outlier Detection.

  Estimate the support of a high-dimensional distribution.

  The implementation is based on libsvm.

  Read more in the [User Guide](../outlier_detection.html#outlier-detection).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html)
 */
export declare class OneClassSVM {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. If a callable is given it is used to precompute the kernel matrix.
    
          @defaultValue `'rbf'`
         */
        kernel?: 'linear' | 'poly' | 'rbf' | 'sigmoid' | 'precomputed';
        /**
          Degree of the polynomial kernel function (‘poly’). Must be non-negative. Ignored by all other kernels.
    
          @defaultValue `3`
         */
        degree?: number;
        /**
          Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.
    
          @defaultValue `'scale'`
         */
        gamma?: 'scale' | 'auto' | number;
        /**
          Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.
    
          @defaultValue `0`
         */
        coef0?: number;
        /**
          Tolerance for stopping criterion.
    
          @defaultValue `0.001`
         */
        tol?: number;
        /**
          An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. Should be in the interval (0, 1\]. By default 0.5 will be taken.
    
          @defaultValue `0.5`
         */
        nu?: number;
        /**
          Whether to use the shrinking heuristic. See the [User Guide](../svm.html#shrinking-svm).
    
          @defaultValue `true`
         */
        shrinking?: boolean;
        /**
          Specify the size of the kernel cache (in MB).
    
          @defaultValue `200`
         */
        cache_size?: number;
        /**
          Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.
    
          @defaultValue `false`
         */
        verbose?: boolean;
        /**
          Hard limit on iterations within solver, or -1 for no limit.
    
          @defaultValue `-1`
         */
        max_iter?: number;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Signed distance to the separating hyperplane.
  
      Signed distance is positive for an inlier and negative for an outlier.
     */
    decision_function(opts: {
        /**
          The data matrix.
         */
        X?: ArrayLike[];
    }): Promise<NDArray>;
    /**
      Detect the soft boundary of the set of samples X.
     */
    fit(opts: {
        /**
          Set of samples, where `n\_samples` is the number of samples and `n\_features` is the number of features.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          Not used, present for API consistency by convention.
         */
        y?: any;
        /**
          Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.
         */
        sample_weight?: ArrayLike;
    }): Promise<any>;
    /**
      Perform fit on X and returns labels for X.
  
      Returns -1 for outliers and 1 for inliers.
     */
    fit_predict(opts: {
        /**
          The input samples.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          Not used, present for API consistency by convention.
         */
        y?: any;
    }): Promise<NDArray>;
    /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
    get_metadata_routing(opts: {
        /**
          A [`MetadataRequest`](sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest "sklearn.utils.metadata_routing.MetadataRequest") encapsulating routing information.
         */
        routing?: any;
    }): Promise<any>;
    /**
      Perform classification on samples in X.
  
      For a one-class model, +1 or -1 is returned.
     */
    predict(opts: {
        /**
          For kernel=”precomputed”, the expected shape of X is (n\_samples\_test, n\_samples\_train).
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray>;
    /**
      Raw scoring function of the samples.
     */
    score_samples(opts: {
        /**
          The data matrix.
         */
        X?: ArrayLike[];
    }): Promise<NDArray>;
    /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
    set_fit_request(opts: {
        /**
          Metadata routing for `sample\_weight` parameter in `fit`.
         */
        sample_weight?: string | boolean;
    }): Promise<any>;
    /**
      Multipliers of parameter C for each class. Computed based on the `class\_weight` parameter.
     */
    get class_weight_(): Promise<NDArray>;
    /**
      Coefficients of the support vectors in the decision function.
     */
    get dual_coef_(): Promise<NDArray[]>;
    /**
      0 if correctly fitted, 1 otherwise (will raise warning)
     */
    get fit_status_(): Promise<number>;
    /**
      Constant in the decision function.
     */
    get intercept_(): Promise<NDArray>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      Number of iterations run by the optimization routine to fit the model.
     */
    get n_iter_(): Promise<number>;
    /**
      Offset used to define the decision function from the raw scores. We have the relation: decision\_function = score\_samples - `offset\_`. The offset is the opposite of `intercept\_` and is provided for consistency with other outlier detection algorithms.
     */
    get offset_(): Promise<number>;
    /**
      Array dimensions of training vector `X`.
     */
    get shape_fit_(): Promise<any[]>;
    /**
      Indices of support vectors.
     */
    get support_(): Promise<NDArray>;
    /**
      Support vectors.
     */
    get support_vectors_(): Promise<NDArray[]>;
}
//# sourceMappingURL=OneClassSVM.d.ts.map