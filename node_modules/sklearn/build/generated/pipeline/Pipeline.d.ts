import { PythonBridge, NDArray, ArrayLike } from '@/sklearn/types';
/**
  Pipeline of transforms with a final estimator.

  Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement `fit` and `transform` methods. The final estimator only needs to implement `fit`. The transformers in the pipeline can be cached using `memory` argument.

  The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a `'\_\_'`, as in the example below. A step’s estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting it to `'passthrough'` or `undefined`.

  For an example use case of `Pipeline` combined with [`GridSearchCV`](sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV "sklearn.model_selection.GridSearchCV"), refer to [Selecting dimensionality reduction with Pipeline and GridSearchCV](../../auto_examples/compose/plot_compare_reduction.html#sphx-glr-auto-examples-compose-plot-compare-reduction-py). The example [Pipelining: chaining a PCA and a logistic regression](../../auto_examples/compose/plot_digits_pipe.html#sphx-glr-auto-examples-compose-plot-digits-pipe-py) shows how to grid search on a pipeline using `'\_\_'` as a separator in the parameter names.

  Read more in the [User Guide](../compose.html#pipeline).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)
 */
export declare class Pipeline {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          List of (name, transform) tuples (implementing `fit`/`transform`) that are chained in sequential order. The last transform must be an estimator.
         */
        steps?: any;
        /**
          Used to cache the fitted transformers of the pipeline. The last step will never be cached, even if it is a transformer. By default, no caching is performed. If a string is given, it is the path to the caching directory. Enabling caching triggers a clone of the transformers before fitting. Therefore, the transformer instance given to the pipeline cannot be inspected directly. Use the attribute `named\_steps` or `steps` to inspect estimators within the pipeline. Caching the transformers is advantageous when fitting is time consuming.
         */
        memory?: string;
        /**
          If `true`, the time elapsed while fitting each step will be printed as it is completed.
    
          @defaultValue `false`
         */
        verbose?: boolean;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Transform the data, and apply `decision\_function` with the final estimator.
  
      Call `transform` of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls `decision\_function` method. Only valid if the final estimator implements `decision\_function`.
     */
    decision_function(opts: {
        /**
          Data to predict on. Must fulfill input requirements of first step of the pipeline.
         */
        X?: any;
    }): Promise<NDArray[]>;
    /**
      Fit the model.
  
      Fit all the transformers one after the other and transform the data. Finally, fit the transformed data using the final estimator.
     */
    fit(opts: {
        /**
          Training data. Must fulfill input requirements of first step of the pipeline.
         */
        X?: any;
        /**
          Training targets. Must fulfill label requirements for all steps of the pipeline.
         */
        y?: any;
        /**
          Parameters passed to the `fit` method of each step, where each parameter name is prefixed such that parameter `p` for step `s` has key `s\_\_p`.
         */
        fit_params?: any;
    }): Promise<any>;
    /**
      Transform the data, and apply `fit\_predict` with the final estimator.
  
      Call `fit\_transform` of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls `fit\_predict` method. Only valid if the final estimator implements `fit\_predict`.
     */
    fit_predict(opts: {
        /**
          Training data. Must fulfill input requirements of first step of the pipeline.
         */
        X?: any;
        /**
          Training targets. Must fulfill label requirements for all steps of the pipeline.
         */
        y?: any;
        /**
          Parameters passed to the `fit` method of each step, where each parameter name is prefixed such that parameter `p` for step `s` has key `s\_\_p`.
         */
        fit_params?: any;
    }): Promise<NDArray>;
    /**
      Fit the model and transform with the final estimator.
  
      Fits all the transformers one after the other and transform the data. Then uses `fit\_transform` on transformed data with the final estimator.
     */
    fit_transform(opts: {
        /**
          Training data. Must fulfill input requirements of first step of the pipeline.
         */
        X?: any;
        /**
          Training targets. Must fulfill label requirements for all steps of the pipeline.
         */
        y?: any;
        /**
          Parameters passed to the `fit` method of each step, where each parameter name is prefixed such that parameter `p` for step `s` has key `s\_\_p`.
         */
        fit_params?: any;
    }): Promise<NDArray[]>;
    /**
      Get output feature names for transformation.
  
      Transform input features using the pipeline.
     */
    get_feature_names_out(opts: {
        /**
          Input features.
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
    get_metadata_routing(opts: {
        /**
          A [`MetadataRequest`](sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest "sklearn.utils.metadata_routing.MetadataRequest") encapsulating routing information.
         */
        routing?: any;
    }): Promise<any>;
    /**
      Apply `inverse\_transform` for each step in a reverse order.
  
      All estimators in the pipeline must support `inverse\_transform`.
     */
    inverse_transform(opts: {
        /**
          Data samples, where `n\_samples` is the number of samples and `n\_features` is the number of features. Must fulfill input requirements of last step of pipeline’s `inverse\_transform` method.
         */
        Xt?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Transform the data, and apply `predict` with the final estimator.
  
      Call `transform` of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls `predict` method. Only valid if the final estimator implements `predict`.
     */
    predict(opts: {
        /**
          Data to predict on. Must fulfill input requirements of first step of the pipeline.
         */
        X?: any;
        /**
          Parameters to the `predict` called at the end of all transformations in the pipeline. Note that while this may be used to return uncertainties from some models with return\_std or return\_cov, uncertainties that are generated by the transformations in the pipeline are not propagated to the final estimator.
         */
        predict_params?: any;
    }): Promise<NDArray>;
    /**
      Transform the data, and apply `predict\_log\_proba` with the final estimator.
  
      Call `transform` of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls `predict\_log\_proba` method. Only valid if the final estimator implements `predict\_log\_proba`.
     */
    predict_log_proba(opts: {
        /**
          Data to predict on. Must fulfill input requirements of first step of the pipeline.
         */
        X?: any;
        /**
          Parameters to the `predict\_log\_proba` called at the end of all transformations in the pipeline.
         */
        predict_log_proba_params?: any;
    }): Promise<NDArray[]>;
    /**
      Transform the data, and apply `predict\_proba` with the final estimator.
  
      Call `transform` of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls `predict\_proba` method. Only valid if the final estimator implements `predict\_proba`.
     */
    predict_proba(opts: {
        /**
          Data to predict on. Must fulfill input requirements of first step of the pipeline.
         */
        X?: any;
        /**
          Parameters to the `predict\_proba` called at the end of all transformations in the pipeline.
         */
        predict_proba_params?: any;
    }): Promise<NDArray[]>;
    /**
      Transform the data, and apply `score` with the final estimator.
  
      Call `transform` of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls `score` method. Only valid if the final estimator implements `score`.
     */
    score(opts: {
        /**
          Data to predict on. Must fulfill input requirements of first step of the pipeline.
         */
        X?: any;
        /**
          Targets used for scoring. Must fulfill label requirements for all steps of the pipeline.
         */
        y?: any;
        /**
          If not `undefined`, this argument is passed as `sample\_weight` keyword argument to the `score` method of the final estimator.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      Transform the data, and apply `score\_samples` with the final estimator.
  
      Call `transform` of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls `score\_samples` method. Only valid if the final estimator implements `score\_samples`.
     */
    score_samples(opts: {
        /**
          Data to predict on. Must fulfill input requirements of first step of the pipeline.
         */
        X?: any;
    }): Promise<NDArray>;
    /**
      Set the output container when `"transform"` and `"fit\_transform"` are called.
  
      Calling `set\_output` will set the output of all estimators in `steps`.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
    set_score_request(opts: {
        /**
          Metadata routing for `sample\_weight` parameter in `score`.
         */
        sample_weight?: string | boolean;
    }): Promise<any>;
    /**
      Transform the data, and apply `transform` with the final estimator.
  
      Call `transform` of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls `transform` method. Only valid if the final estimator implements `transform`.
  
      This also works where final estimator is `undefined` in which case all prior transformations are applied.
     */
    transform(opts: {
        /**
          Data to transform. Must fulfill input requirements of first step of the pipeline.
         */
        X?: any;
    }): Promise<NDArray[]>;
}
//# sourceMappingURL=Pipeline.d.ts.map