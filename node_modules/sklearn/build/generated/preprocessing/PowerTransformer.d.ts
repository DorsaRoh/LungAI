import { PythonBridge, NDArray, ArrayLike } from '@/sklearn/types';
/**
  Apply a power transform featurewise to make data more Gaussian-like.

  Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like. This is useful for modeling issues related to heteroscedasticity (non-constant variance), or other situations where normality is desired.

  Currently, PowerTransformer supports the Box-Cox transform and the Yeo-Johnson transform. The optimal parameter for stabilizing variance and minimizing skewness is estimated through maximum likelihood.

  Box-Cox requires input data to be strictly positive, while Yeo-Johnson supports both positive or negative data.

  By default, zero-mean, unit-variance normalization is applied to the transformed data.

  For an example visualization, refer to [Compare PowerTransformer with other scalers](../../auto_examples/preprocessing/plot_all_scaling.html#plot-all-scaling-power-transformer-section). To see the effect of Box-Cox and Yeo-Johnson transformations on different distributions, see: [Map data to a normal distribution](../../auto_examples/preprocessing/plot_map_data_to_normal.html#sphx-glr-auto-examples-preprocessing-plot-map-data-to-normal-py).

  Read more in the [User Guide](../preprocessing.html#preprocessing-transformer).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html)
 */
export declare class PowerTransformer {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          The power transform method. Available methods are:
    
          @defaultValue `'yeo-johnson'`
         */
        method?: 'yeo-johnson' | 'box-cox';
        /**
          Set to `true` to apply zero-mean, unit-variance normalization to the transformed output.
    
          @defaultValue `true`
         */
        standardize?: boolean;
        /**
          Set to `false` to perform inplace computation during transformation.
    
          @defaultValue `true`
         */
        copy?: boolean;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Estimate the optimal parameter lambda for each feature.
  
      The optimal lambda parameter for minimizing skewness is estimated on each feature independently using maximum likelihood.
     */
    fit(opts: {
        /**
          The data used to estimate the optimal transformation parameters.
         */
        X?: ArrayLike[];
        /**
          Ignored.
         */
        y?: any;
    }): Promise<any>;
    /**
      Fit `PowerTransformer` to `X`, then transform `X`.
     */
    fit_transform(opts: {
        /**
          The data used to estimate the optimal transformation parameters and to be transformed using a power transformation.
         */
        X?: ArrayLike[];
        /**
          Not used, present for API consistency by convention.
         */
        y?: any;
    }): Promise<NDArray[]>;
    /**
      Get output feature names for transformation.
     */
    get_feature_names_out(opts: {
        /**
          Input features.
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
    get_metadata_routing(opts: {
        /**
          A [`MetadataRequest`](sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest "sklearn.utils.metadata_routing.MetadataRequest") encapsulating routing information.
         */
        routing?: any;
    }): Promise<any>;
    /**
      Apply the inverse power transformation using the fitted lambdas.
  
      The inverse of the Box-Cox transformation is given by:
     */
    inverse_transform(opts: {
        /**
          The transformed data.
         */
        X?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Apply the power transform to each feature using the fitted lambdas.
     */
    transform(opts: {
        /**
          The data to be transformed using a power transformation.
         */
        X?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      The parameters of the power transformation for the selected features.
     */
    get lambdas_(): Promise<any[]>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
//# sourceMappingURL=PowerTransformer.d.ts.map