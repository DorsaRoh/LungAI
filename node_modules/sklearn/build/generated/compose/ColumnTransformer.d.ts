import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Applies transformers to columns of an array or pandas DataFrame.

  This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer.

  Read more in the [User Guide](../compose.html#column-transformer).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)
 */
export declare class ColumnTransformer {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          List of (name, transformer, columns) tuples specifying the transformer objects to be applied to subsets of the data.
         */
        transformers?: any;
        /**
          By default, only the specified columns in `transformers` are transformed and combined in the output, and the non-specified columns are dropped. (default of `'drop'`). By specifying `remainder='passthrough'`, all remaining columns that were not specified in `transformers`, but present in the data passed to `fit` will be automatically passed through. This subset of columns is concatenated with the output of the transformers. For dataframes, extra columns not seen during `fit` will be excluded from the output of `transform`. By setting `remainder` to be an estimator, the remaining non-specified columns will use the `remainder` estimator. The estimator must support [fit](../../glossary.html#term-fit) and [transform](../../glossary.html#term-transform). Note that using this feature requires that the DataFrame columns input at [fit](../../glossary.html#term-fit) and [transform](../../glossary.html#term-transform) have identical order.
    
          @defaultValue `'drop'`
         */
        remainder?: 'drop' | 'passthrough';
        /**
          If the output of the different transformers contains sparse matrices, these will be stacked as a sparse matrix if the overall density is lower than this value. Use `sparse\_threshold=0` to always return dense. When the transformed output consists of all dense data, the stacked result will be dense, and this keyword will be ignored.
    
          @defaultValue `0.3`
         */
        sparse_threshold?: number;
        /**
          Number of jobs to run in parallel. `undefined` means 1 unless in a [`joblib.parallel\_backend`](https://joblib.readthedocs.io/en/latest/generated/joblib.parallel_backend.html#joblib.parallel_backend "(in joblib v1.4.dev0)") context. `\-1` means using all processors. See [Glossary](../../glossary.html#term-n_jobs) for more details.
         */
        n_jobs?: number;
        /**
          Multiplicative weights for features per transformer. The output of the transformer is multiplied by these weights. Keys are transformer names, values the weights.
         */
        transformer_weights?: any;
        /**
          If `true`, the time elapsed while fitting each transformer will be printed as it is completed.
    
          @defaultValue `false`
         */
        verbose?: boolean;
        /**
          If `true`, [`ColumnTransformer.get\_feature\_names\_out`](#sklearn.compose.ColumnTransformer.get_feature_names_out "sklearn.compose.ColumnTransformer.get_feature_names_out") will prefix all feature names with the name of the transformer that generated that feature. If `false`, [`ColumnTransformer.get\_feature\_names\_out`](#sklearn.compose.ColumnTransformer.get_feature_names_out "sklearn.compose.ColumnTransformer.get_feature_names_out") will not prefix any feature names and will error if feature names are not unique.
    
          @defaultValue `true`
         */
        verbose_feature_names_out?: boolean;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit all transformers using X.
     */
    fit(opts: {
        /**
          Input data, of which specified subsets are used to fit the transformers.
         */
        X?: ArrayLike[];
        /**
          Targets for supervised learning.
         */
        y?: ArrayLike[];
    }): Promise<any>;
    /**
      Fit all transformers, transform the data and concatenate results.
     */
    fit_transform(opts: {
        /**
          Input data, of which specified subsets are used to fit the transformers.
         */
        X?: ArrayLike[];
        /**
          Targets for supervised learning.
         */
        y?: ArrayLike;
    }): Promise<ArrayLike | SparseMatrix[]>;
    /**
      Get output feature names for transformation.
     */
    get_feature_names_out(opts: {
        /**
          Input features.
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
    get_metadata_routing(opts: {
        /**
          A [`MetadataRequest`](sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest "sklearn.utils.metadata_routing.MetadataRequest") encapsulating routing information.
         */
        routing?: any;
    }): Promise<any>;
    /**
      Set the output container when `"transform"` and `"fit\_transform"` are called.
  
      Calling `set\_output` will set the output of all estimators in `transformers` and `transformers\_`.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Transform X separately by each transformer, concatenate results.
     */
    transform(opts: {
        /**
          The data to be transformed by subset.
         */
        X?: ArrayLike[];
    }): Promise<ArrayLike | SparseMatrix[]>;
    /**
      The collection of fitted transformers as tuples of (name, fitted\_transformer, column). `fitted\_transformer` can be an estimator, ‘drop’, or ‘passthrough’. In case there were no columns selected, this will be the unfitted transformer. If there are remaining columns, the final element is a tuple of the form: (‘remainder’, transformer, remaining\_columns) corresponding to the `remainder` parameter. If there are remaining columns, then `len(transformers\_)==len(transformers)+1`, otherwise `len(transformers\_)==len(transformers)`.
     */
    get transformers_(): Promise<any[]>;
    /**
      Boolean flag indicating whether the output of `transform` is a sparse matrix or a dense numpy array, which depends on the output of the individual transformers and the `sparse\_threshold` keyword.
     */
    get sparse_output_(): Promise<boolean>;
    /**
      A dictionary from each transformer name to a slice, where the slice corresponds to indices in the transformed output. This is useful to inspect which transformer is responsible for which transformed feature(s).
     */
    get output_indices_(): Promise<any>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying transformers expose such an attribute when fit.
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
//# sourceMappingURL=ColumnTransformer.d.ts.map