import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Reduce dimensionality through sparse random projection.

  Sparse random matrix is an alternative to dense random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.

  If we note `s \= 1 / density` the components of the random matrix are drawn from:

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.random_projection.SparseRandomProjection.html)
 */
export declare class SparseRandomProjection {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Dimensionality of the target projection space.
    
          n\_components can be automatically adjusted according to the number of samples in the dataset and the bound given by the Johnson-Lindenstrauss lemma. In that case the quality of the embedding is controlled by the `eps` parameter.
    
          It should be noted that Johnson-Lindenstrauss lemma can yield very conservative estimated of the required number of components as it makes no assumption on the structure of the dataset.
    
          @defaultValue `'auto'`
         */
        n_components?: number | 'auto';
        /**
          Ratio in the range (0, 1\] of non-zero component in the random projection matrix.
    
          If density = ‘auto’, the value is set to the minimum density as recommended by Ping Li et al.: 1 / sqrt(n\_features).
    
          Use density = 1 / 3.0 if you want to reproduce the results from Achlioptas, 2001.
    
          @defaultValue `'auto'`
         */
        density?: number | 'auto';
        /**
          Parameter to control the quality of the embedding according to the Johnson-Lindenstrauss lemma when n\_components is set to ‘auto’. This value should be strictly positive.
    
          Smaller values lead to better embedding and higher number of dimensions (n\_components) in the target projection space.
    
          @defaultValue `0.1`
         */
        eps?: number;
        /**
          If `true`, ensure that the output of the random projection is a dense numpy array even if the input and random projection matrix are both sparse. In practice, if the number of components is small the number of zero components in the projected data will be very small and it will be more CPU and memory efficient to use a dense representation.
    
          If `false`, the projected data uses a sparse representation if the input is sparse.
    
          @defaultValue `false`
         */
        dense_output?: boolean;
        /**
          Learn the inverse transform by computing the pseudo-inverse of the components during fit. Note that the pseudo-inverse is always a dense array, even if the training data was sparse. This means that it might be necessary to call `inverse\_transform` on a small batch of samples at a time to avoid exhausting the available memory on the host. Moreover, computing the pseudo-inverse does not scale well to large matrices.
    
          @defaultValue `false`
         */
        compute_inverse_components?: boolean;
        /**
          Controls the pseudo random number generator used to generate the projection matrix at fit time. Pass an int for reproducible output across multiple function calls. See [Glossary](../../glossary.html#term-random_state).
         */
        random_state?: number;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Generate a sparse random projection matrix.
     */
    fit(opts: {
        /**
          Training set: only the shape is used to find optimal random matrix dimensions based on the theory referenced in the afore mentioned papers.
         */
        X?: NDArray | SparseMatrix[];
        /**
          Not used, present here for API consistency by convention.
         */
        y?: any;
    }): Promise<any>;
    /**
      Fit to data, then transform it.
  
      Fits transformer to `X` and `y` with optional parameters `fit\_params` and returns a transformed version of `X`.
     */
    fit_transform(opts: {
        /**
          Input samples.
         */
        X?: ArrayLike[];
        /**
          Target values (`undefined` for unsupervised transformations).
         */
        y?: ArrayLike;
        /**
          Additional fit parameters.
         */
        fit_params?: any;
    }): Promise<any[]>;
    /**
      Get output feature names for transformation.
  
      The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: `\["class\_name0", "class\_name1", "class\_name2"\]`.
     */
    get_feature_names_out(opts: {
        /**
          Only used to validate feature names with the names seen in `fit`.
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
    get_metadata_routing(opts: {
        /**
          A [`MetadataRequest`](sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest "sklearn.utils.metadata_routing.MetadataRequest") encapsulating routing information.
         */
        routing?: any;
    }): Promise<any>;
    /**
      Project data back to its original space.
  
      Returns an array X\_original whose transform would be X. Note that even if X is sparse, X\_original is dense: this may use a lot of RAM.
  
      If `compute\_inverse\_components` is `false`, the inverse of the components is computed during each call to `inverse\_transform` which can be costly.
     */
    inverse_transform(opts: {
        /**
          Data to be transformed back.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray[]>;
    /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Project the data by using matrix product with the random matrix.
     */
    transform(opts: {
        /**
          The input data to project into a smaller dimensional space.
         */
        X?: NDArray | SparseMatrix[];
    }): Promise<NDArray | SparseMatrix[]>;
    /**
      Concrete number of components computed when n\_components=”auto”.
     */
    get n_components_(): Promise<number>;
    /**
      Random matrix used for the projection. Sparse matrix will be of CSR format.
     */
    get components_(): Promise<SparseMatrix[]>;
    /**
      Pseudo-inverse of the components, only computed if `compute\_inverse\_components` is `true`.
     */
    get inverse_components_(): Promise<NDArray[]>;
    /**
      Concrete density computed from when density = “auto”.
     */
    get density_(): Promise<any>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
//# sourceMappingURL=SparseRandomProjection.d.ts.map