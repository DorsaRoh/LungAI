// src/generated/neural_network/MLPRegressor.ts
import crypto from "node:crypto";
var MLPRegressor = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `MLPRegressor${crypto.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("MLPRegressor.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.neural_network import MLPRegressor
try: bridgeMLPRegressor
except NameError: bridgeMLPRegressor = {}
`;
    await this._py.ex`ctor_MLPRegressor = {'hidden_layer_sizes': np.array(${this.opts["hidden_layer_sizes"] ?? void 0}) if ${this.opts["hidden_layer_sizes"] !== void 0} else None, 'activation': ${this.opts["activation"] ?? void 0}, 'solver': ${this.opts["solver"] ?? void 0}, 'alpha': ${this.opts["alpha"] ?? void 0}, 'batch_size': ${this.opts["batch_size"] ?? void 0}, 'learning_rate': ${this.opts["learning_rate"] ?? void 0}, 'learning_rate_init': ${this.opts["learning_rate_init"] ?? void 0}, 'power_t': ${this.opts["power_t"] ?? void 0}, 'max_iter': ${this.opts["max_iter"] ?? void 0}, 'shuffle': ${this.opts["shuffle"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'tol': ${this.opts["tol"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'momentum': ${this.opts["momentum"] ?? void 0}, 'nesterovs_momentum': ${this.opts["nesterovs_momentum"] ?? void 0}, 'early_stopping': ${this.opts["early_stopping"] ?? void 0}, 'validation_fraction': ${this.opts["validation_fraction"] ?? void 0}, 'beta_1': ${this.opts["beta_1"] ?? void 0}, 'beta_2': ${this.opts["beta_2"] ?? void 0}, 'epsilon': ${this.opts["epsilon"] ?? void 0}, 'n_iter_no_change': ${this.opts["n_iter_no_change"] ?? void 0}, 'max_fun': ${this.opts["max_fun"] ?? void 0}}

ctor_MLPRegressor = {k: v for k, v in ctor_MLPRegressor.items() if v is not None}`;
    await this._py.ex`bridgeMLPRegressor[${this.id}] = MLPRegressor(**ctor_MLPRegressor)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeMLPRegressor[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Fit the model to data matrix X and target(s) y.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("MLPRegressor must call init() before fit()");
    }
    await this._py.ex`pms_MLPRegressor_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None}

pms_MLPRegressor_fit = {k: v for k, v in pms_MLPRegressor_fit.items() if v is not None}`;
    await this._py.ex`res_MLPRegressor_fit = bridgeMLPRegressor[${this.id}].fit(**pms_MLPRegressor_fit)`;
    return this._py`res_MLPRegressor_fit.tolist() if hasattr(res_MLPRegressor_fit, 'tolist') else res_MLPRegressor_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_MLPRegressor_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_MLPRegressor_get_metadata_routing = {k: v for k, v in pms_MLPRegressor_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_MLPRegressor_get_metadata_routing = bridgeMLPRegressor[${this.id}].get_metadata_routing(**pms_MLPRegressor_get_metadata_routing)`;
    return this._py`res_MLPRegressor_get_metadata_routing.tolist() if hasattr(res_MLPRegressor_get_metadata_routing, 'tolist') else res_MLPRegressor_get_metadata_routing`;
  }
  /**
    Update the model with a single iteration over the given data.
   */
  async partial_fit(opts) {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("MLPRegressor must call init() before partial_fit()");
    }
    await this._py.ex`pms_MLPRegressor_partial_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None}

pms_MLPRegressor_partial_fit = {k: v for k, v in pms_MLPRegressor_partial_fit.items() if v is not None}`;
    await this._py.ex`res_MLPRegressor_partial_fit = bridgeMLPRegressor[${this.id}].partial_fit(**pms_MLPRegressor_partial_fit)`;
    return this._py`res_MLPRegressor_partial_fit.tolist() if hasattr(res_MLPRegressor_partial_fit, 'tolist') else res_MLPRegressor_partial_fit`;
  }
  /**
    Predict using the multi-layer perceptron model.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("MLPRegressor must call init() before predict()");
    }
    await this._py.ex`pms_MLPRegressor_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_MLPRegressor_predict = {k: v for k, v in pms_MLPRegressor_predict.items() if v is not None}`;
    await this._py.ex`res_MLPRegressor_predict = bridgeMLPRegressor[${this.id}].predict(**pms_MLPRegressor_predict)`;
    return this._py`res_MLPRegressor_predict.tolist() if hasattr(res_MLPRegressor_predict, 'tolist') else res_MLPRegressor_predict`;
  }
  /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("MLPRegressor must call init() before score()");
    }
    await this._py.ex`pms_MLPRegressor_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_MLPRegressor_score = {k: v for k, v in pms_MLPRegressor_score.items() if v is not None}`;
    await this._py.ex`res_MLPRegressor_score = bridgeMLPRegressor[${this.id}].score(**pms_MLPRegressor_score)`;
    return this._py`res_MLPRegressor_score.tolist() if hasattr(res_MLPRegressor_score, 'tolist') else res_MLPRegressor_score`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_MLPRegressor_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_MLPRegressor_set_score_request = {k: v for k, v in pms_MLPRegressor_set_score_request.items() if v is not None}`;
    await this._py.ex`res_MLPRegressor_set_score_request = bridgeMLPRegressor[${this.id}].set_score_request(**pms_MLPRegressor_set_score_request)`;
    return this._py`res_MLPRegressor_set_score_request.tolist() if hasattr(res_MLPRegressor_set_score_request, 'tolist') else res_MLPRegressor_set_score_request`;
  }
  /**
    The current loss computed with the loss function.
   */
  get loss_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("MLPRegressor must call init() before accessing loss_");
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_loss_ = bridgeMLPRegressor[${this.id}].loss_`;
      return this._py`attr_MLPRegressor_loss_.tolist() if hasattr(attr_MLPRegressor_loss_, 'tolist') else attr_MLPRegressor_loss_`;
    })();
  }
  /**
    The minimum loss reached by the solver throughout fitting. If `early\_stopping=True`, this attribute is set to `undefined`. Refer to the `best\_validation\_score\_` fitted attribute instead. Only accessible when solver=’sgd’ or ‘adam’.
   */
  get best_loss_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before accessing best_loss_"
      );
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_best_loss_ = bridgeMLPRegressor[${this.id}].best_loss_`;
      return this._py`attr_MLPRegressor_best_loss_.tolist() if hasattr(attr_MLPRegressor_best_loss_, 'tolist') else attr_MLPRegressor_best_loss_`;
    })();
  }
  /**
    Loss value evaluated at the end of each training step. The ith element in the list represents the loss at the ith iteration. Only accessible when solver=’sgd’ or ‘adam’.
   */
  get loss_curve_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before accessing loss_curve_"
      );
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_loss_curve_ = bridgeMLPRegressor[${this.id}].loss_curve_`;
      return this._py`attr_MLPRegressor_loss_curve_.tolist() if hasattr(attr_MLPRegressor_loss_curve_, 'tolist') else attr_MLPRegressor_loss_curve_`;
    })();
  }
  /**
    The score at each iteration on a held-out validation set. The score reported is the R2 score. Only available if `early\_stopping=True`, otherwise the attribute is set to `undefined`. Only accessible when solver=’sgd’ or ‘adam’.
   */
  get validation_scores_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before accessing validation_scores_"
      );
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_validation_scores_ = bridgeMLPRegressor[${this.id}].validation_scores_`;
      return this._py`attr_MLPRegressor_validation_scores_.tolist() if hasattr(attr_MLPRegressor_validation_scores_, 'tolist') else attr_MLPRegressor_validation_scores_`;
    })();
  }
  /**
    The best validation score (i.e. R2 score) that triggered the early stopping. Only available if `early\_stopping=True`, otherwise the attribute is set to `undefined`. Only accessible when solver=’sgd’ or ‘adam’.
   */
  get best_validation_score_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before accessing best_validation_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_best_validation_score_ = bridgeMLPRegressor[${this.id}].best_validation_score_`;
      return this._py`attr_MLPRegressor_best_validation_score_.tolist() if hasattr(attr_MLPRegressor_best_validation_score_, 'tolist') else attr_MLPRegressor_best_validation_score_`;
    })();
  }
  /**
    The number of training samples seen by the solver during fitting. Mathematically equals `n\_iters \* X.shape\[0\]`, it means `time\_step` and it is used by optimizer’s learning rate scheduler.
   */
  get t_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("MLPRegressor must call init() before accessing t_");
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_t_ = bridgeMLPRegressor[${this.id}].t_`;
      return this._py`attr_MLPRegressor_t_.tolist() if hasattr(attr_MLPRegressor_t_, 'tolist') else attr_MLPRegressor_t_`;
    })();
  }
  /**
    The ith element in the list represents the weight matrix corresponding to layer i.
   */
  get coefs_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("MLPRegressor must call init() before accessing coefs_");
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_coefs_ = bridgeMLPRegressor[${this.id}].coefs_`;
      return this._py`attr_MLPRegressor_coefs_.tolist() if hasattr(attr_MLPRegressor_coefs_, 'tolist') else attr_MLPRegressor_coefs_`;
    })();
  }
  /**
    The ith element in the list represents the bias vector corresponding to layer i + 1.
   */
  get intercepts_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before accessing intercepts_"
      );
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_intercepts_ = bridgeMLPRegressor[${this.id}].intercepts_`;
      return this._py`attr_MLPRegressor_intercepts_.tolist() if hasattr(attr_MLPRegressor_intercepts_, 'tolist') else attr_MLPRegressor_intercepts_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_n_features_in_ = bridgeMLPRegressor[${this.id}].n_features_in_`;
      return this._py`attr_MLPRegressor_n_features_in_.tolist() if hasattr(attr_MLPRegressor_n_features_in_, 'tolist') else attr_MLPRegressor_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_feature_names_in_ = bridgeMLPRegressor[${this.id}].feature_names_in_`;
      return this._py`attr_MLPRegressor_feature_names_in_.tolist() if hasattr(attr_MLPRegressor_feature_names_in_, 'tolist') else attr_MLPRegressor_feature_names_in_`;
    })();
  }
  /**
    The number of iterations the solver has run.
   */
  get n_iter_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("MLPRegressor must call init() before accessing n_iter_");
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_n_iter_ = bridgeMLPRegressor[${this.id}].n_iter_`;
      return this._py`attr_MLPRegressor_n_iter_.tolist() if hasattr(attr_MLPRegressor_n_iter_, 'tolist') else attr_MLPRegressor_n_iter_`;
    })();
  }
  /**
    Number of layers.
   */
  get n_layers_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before accessing n_layers_"
      );
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_n_layers_ = bridgeMLPRegressor[${this.id}].n_layers_`;
      return this._py`attr_MLPRegressor_n_layers_.tolist() if hasattr(attr_MLPRegressor_n_layers_, 'tolist') else attr_MLPRegressor_n_layers_`;
    })();
  }
  /**
    Number of outputs.
   */
  get n_outputs_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before accessing n_outputs_"
      );
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_n_outputs_ = bridgeMLPRegressor[${this.id}].n_outputs_`;
      return this._py`attr_MLPRegressor_n_outputs_.tolist() if hasattr(attr_MLPRegressor_n_outputs_, 'tolist') else attr_MLPRegressor_n_outputs_`;
    })();
  }
  /**
    Name of the output activation function.
   */
  get out_activation_() {
    if (this._isDisposed) {
      throw new Error("This MLPRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "MLPRegressor must call init() before accessing out_activation_"
      );
    }
    return (async () => {
      await this._py.ex`attr_MLPRegressor_out_activation_ = bridgeMLPRegressor[${this.id}].out_activation_`;
      return this._py`attr_MLPRegressor_out_activation_.tolist() if hasattr(attr_MLPRegressor_out_activation_, 'tolist') else attr_MLPRegressor_out_activation_`;
    })();
  }
};
export {
  MLPRegressor
};
//# sourceMappingURL=MLPRegressor.js.map