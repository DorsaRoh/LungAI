// src/generated/dummy/DummyRegressor.ts
import crypto from "node:crypto";
var DummyRegressor = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `DummyRegressor${crypto.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error("This DummyRegressor instance has already been disposed");
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("DummyRegressor.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.dummy import DummyRegressor
try: bridgeDummyRegressor
except NameError: bridgeDummyRegressor = {}
`;
    await this._py.ex`ctor_DummyRegressor = {'strategy': ${this.opts["strategy"] ?? void 0}, 'constant': np.array(${this.opts["constant"] ?? void 0}) if ${this.opts["constant"] !== void 0} else None, 'quantile': ${this.opts["quantile"] ?? void 0}}

ctor_DummyRegressor = {k: v for k, v in ctor_DummyRegressor.items() if v is not None}`;
    await this._py.ex`bridgeDummyRegressor[${this.id}] = DummyRegressor(**ctor_DummyRegressor)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeDummyRegressor[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Fit the random regressor.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error("This DummyRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("DummyRegressor must call init() before fit()");
    }
    await this._py.ex`pms_DummyRegressor_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_DummyRegressor_fit = {k: v for k, v in pms_DummyRegressor_fit.items() if v is not None}`;
    await this._py.ex`res_DummyRegressor_fit = bridgeDummyRegressor[${this.id}].fit(**pms_DummyRegressor_fit)`;
    return this._py`res_DummyRegressor_fit.tolist() if hasattr(res_DummyRegressor_fit, 'tolist') else res_DummyRegressor_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error("This DummyRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "DummyRegressor must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_DummyRegressor_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_DummyRegressor_get_metadata_routing = {k: v for k, v in pms_DummyRegressor_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_DummyRegressor_get_metadata_routing = bridgeDummyRegressor[${this.id}].get_metadata_routing(**pms_DummyRegressor_get_metadata_routing)`;
    return this._py`res_DummyRegressor_get_metadata_routing.tolist() if hasattr(res_DummyRegressor_get_metadata_routing, 'tolist') else res_DummyRegressor_get_metadata_routing`;
  }
  /**
    Perform classification on test vectors X.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error("This DummyRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("DummyRegressor must call init() before predict()");
    }
    await this._py.ex`pms_DummyRegressor_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'return_std': ${opts["return_std"] ?? void 0}}

pms_DummyRegressor_predict = {k: v for k, v in pms_DummyRegressor_predict.items() if v is not None}`;
    await this._py.ex`res_DummyRegressor_predict = bridgeDummyRegressor[${this.id}].predict(**pms_DummyRegressor_predict)`;
    return this._py`res_DummyRegressor_predict.tolist() if hasattr(res_DummyRegressor_predict, 'tolist') else res_DummyRegressor_predict`;
  }
  /**
      Return the coefficient of determination R^2 of the prediction.
  
      The coefficient R^2 is defined as `(1 \- u/v)`, where `u` is the residual sum of squares `((y\_true \- y\_pred) \*\* 2).sum()` and `v` is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error("This DummyRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("DummyRegressor must call init() before score()");
    }
    await this._py.ex`pms_DummyRegressor_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_DummyRegressor_score = {k: v for k, v in pms_DummyRegressor_score.items() if v is not None}`;
    await this._py.ex`res_DummyRegressor_score = bridgeDummyRegressor[${this.id}].score(**pms_DummyRegressor_score)`;
    return this._py`res_DummyRegressor_score.tolist() if hasattr(res_DummyRegressor_score, 'tolist') else res_DummyRegressor_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error("This DummyRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "DummyRegressor must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_DummyRegressor_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_DummyRegressor_set_fit_request = {k: v for k, v in pms_DummyRegressor_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_DummyRegressor_set_fit_request = bridgeDummyRegressor[${this.id}].set_fit_request(**pms_DummyRegressor_set_fit_request)`;
    return this._py`res_DummyRegressor_set_fit_request.tolist() if hasattr(res_DummyRegressor_set_fit_request, 'tolist') else res_DummyRegressor_set_fit_request`;
  }
  /**
      Request metadata passed to the `predict` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_predict_request(opts) {
    if (this._isDisposed) {
      throw new Error("This DummyRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "DummyRegressor must call init() before set_predict_request()"
      );
    }
    await this._py.ex`pms_DummyRegressor_set_predict_request = {'return_std': ${opts["return_std"] ?? void 0}}

pms_DummyRegressor_set_predict_request = {k: v for k, v in pms_DummyRegressor_set_predict_request.items() if v is not None}`;
    await this._py.ex`res_DummyRegressor_set_predict_request = bridgeDummyRegressor[${this.id}].set_predict_request(**pms_DummyRegressor_set_predict_request)`;
    return this._py`res_DummyRegressor_set_predict_request.tolist() if hasattr(res_DummyRegressor_set_predict_request, 'tolist') else res_DummyRegressor_set_predict_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error("This DummyRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "DummyRegressor must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_DummyRegressor_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_DummyRegressor_set_score_request = {k: v for k, v in pms_DummyRegressor_set_score_request.items() if v is not None}`;
    await this._py.ex`res_DummyRegressor_set_score_request = bridgeDummyRegressor[${this.id}].set_score_request(**pms_DummyRegressor_set_score_request)`;
    return this._py`res_DummyRegressor_set_score_request.tolist() if hasattr(res_DummyRegressor_set_score_request, 'tolist') else res_DummyRegressor_set_score_request`;
  }
  /**
    Mean or median or quantile of the training targets or constant value given by the user.
   */
  get constant_() {
    if (this._isDisposed) {
      throw new Error("This DummyRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "DummyRegressor must call init() before accessing constant_"
      );
    }
    return (async () => {
      await this._py.ex`attr_DummyRegressor_constant_ = bridgeDummyRegressor[${this.id}].constant_`;
      return this._py`attr_DummyRegressor_constant_.tolist() if hasattr(attr_DummyRegressor_constant_, 'tolist') else attr_DummyRegressor_constant_`;
    })();
  }
  /**
    Number of outputs.
   */
  get n_outputs_() {
    if (this._isDisposed) {
      throw new Error("This DummyRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "DummyRegressor must call init() before accessing n_outputs_"
      );
    }
    return (async () => {
      await this._py.ex`attr_DummyRegressor_n_outputs_ = bridgeDummyRegressor[${this.id}].n_outputs_`;
      return this._py`attr_DummyRegressor_n_outputs_.tolist() if hasattr(attr_DummyRegressor_n_outputs_, 'tolist') else attr_DummyRegressor_n_outputs_`;
    })();
  }
};
export {
  DummyRegressor
};
//# sourceMappingURL=DummyRegressor.js.map