import { PythonBridge } from '@/sklearn/types';
/**
  Tweak of [`joblib.Parallel`](https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html#joblib.Parallel "(in joblib v1.4.dev0)") that propagates the scikit-learn configuration.

  This subclass of [`joblib.Parallel`](https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html#joblib.Parallel "(in joblib v1.4.dev0)") ensures that the active configuration (thread-local) of scikit-learn is propagated to the parallel workers for the duration of the execution of the parallel tasks.

  The API does not change and you can refer to [`joblib.Parallel`](https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html#joblib.Parallel "(in joblib v1.4.dev0)") documentation for more details.

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.utils.parallel.Parallel.html)
 */
export declare class Parallel {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {});
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Dispatch more data for parallel processing
  
      This method is meant to be called concurrently by the multiprocessing callback. We rely on the thread-safety of dispatch\_one\_batch to protect against concurrent consumption of the unprotected iterator.
     */
    dispatch_next(opts: {}): Promise<any>;
    /**
      Prefetch the tasks for the next batch and dispatch them.
  
      The effective size of the batch is computed here. If there are no more jobs to dispatch, return `false`, else return `true`.
  
      The iterator consumption and dispatching is protected by the same lock so calling this function should be thread safe.
     */
    dispatch_one_batch(opts: {}): Promise<any>;
    /**
      Return the formatted representation of the object.
     */
    format(opts: {}): Promise<any>;
    /**
      Display the process of the parallel execution only a fraction of time, controlled by self.verbose.
     */
    print_progress(opts: {}): Promise<any>;
}
//# sourceMappingURL=Parallel.d.ts.map