import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Transform a count matrix to a normalized tf or tf-idf representation.

  Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification.

  The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus.

  The formula that is used to compute the tf-idf for a term t of a document d in a document set is tf-idf(t, d) = tf(t, d) \* idf(t), and the idf is computed as idf(t) = log \[ n / df(t) \] + 1 (if `smooth\_idf=False`), where n is the total number of documents in the document set and df(t) is the document frequency of t; the document frequency is the number of documents in the document set that contain the term t. The effect of adding “1” to the idf in the equation above is that terms with zero idf, i.e., terms that occur in all documents in a training set, will not be entirely ignored. (Note that the idf formula above differs from the standard textbook notation that defines the idf as idf(t) = log \[ n / (df(t) + 1) \]).

  If `smooth\_idf=True` (the default), the constant “1” is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: idf(t) = log \[ (1 + n) / (1 + df(t)) \] + 1.

  Furthermore, the formulas used to compute tf and idf depend on parameter settings that correspond to the SMART notation used in IR as follows:

  Tf is “n” (natural) by default, “l” (logarithmic) when `sublinear\_tf=True`. Idf is “t” when use\_idf is given, “n” (none) otherwise. Normalization is “c” (cosine) when `norm='l2'`, “n” (none) when `norm=None`.

  Read more in the [User Guide](../feature_extraction.html#text-feature-extraction).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)
 */
export declare class TfidfTransformer {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Each output row will have unit norm, either:
    
          @defaultValue `'l2'`
         */
        norm?: 'l1' | 'l2';
        /**
          Enable inverse-document-frequency reweighting. If `false`, idf(t) = 1.
    
          @defaultValue `true`
         */
        use_idf?: boolean;
        /**
          Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.
    
          @defaultValue `true`
         */
        smooth_idf?: boolean;
        /**
          Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).
    
          @defaultValue `false`
         */
        sublinear_tf?: boolean;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Learn the idf vector (global term weights).
     */
    fit(opts: {
        /**
          A matrix of term/token counts.
         */
        X?: any;
        /**
          This parameter is not needed to compute tf-idf.
         */
        y?: any;
    }): Promise<any>;
    /**
      Fit to data, then transform it.
  
      Fits transformer to `X` and `y` with optional parameters `fit\_params` and returns a transformed version of `X`.
     */
    fit_transform(opts: {
        /**
          Input samples.
         */
        X?: ArrayLike[];
        /**
          Target values (`undefined` for unsupervised transformations).
         */
        y?: ArrayLike;
        /**
          Additional fit parameters.
         */
        fit_params?: any;
    }): Promise<any[]>;
    /**
      Get output feature names for transformation.
     */
    get_feature_names_out(opts: {
        /**
          Input features.
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
    get_metadata_routing(opts: {
        /**
          A [`MetadataRequest`](sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest "sklearn.utils.metadata_routing.MetadataRequest") encapsulating routing information.
         */
        routing?: any;
    }): Promise<any>;
    /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Request metadata passed to the `transform` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
    set_transform_request(opts: {
        /**
          Metadata routing for `copy` parameter in `transform`.
         */
        copy?: string | boolean;
    }): Promise<any>;
    /**
      Transform a count matrix to a tf or tf-idf representation.
     */
    transform(opts: {
        /**
          A matrix of term/token counts.
         */
        X?: any;
        /**
          Whether to copy X and operate on the copy or perform in-place operations.
    
          @defaultValue `true`
         */
        copy?: boolean;
    }): Promise<SparseMatrix[]>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
//# sourceMappingURL=TfidfTransformer.d.ts.map