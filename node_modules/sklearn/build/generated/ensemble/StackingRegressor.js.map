{"version":3,"sources":["../../../src/generated/ensemble/StackingRegressor.ts"],"sourcesContent":["/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Stack of estimators with a final regressor.\n\n  Stacked generalization consists in stacking the output of individual estimator and use a regressor to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.\n\n  Note that `estimators\\_` are fitted on the full `X` while `final\\_estimator\\_` is trained using cross-validated predictions of the base estimators using `cross\\_val\\_predict`.\n\n  Read more in the [User Guide](../ensemble.html#stacking).\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html)\n */\nexport class StackingRegressor {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      Base estimators which will be stacked together. Each element of the list is defined as a tuple of string (i.e. name) and an estimator instance. An estimator can be set to ‘drop’ using `set\\_params`.\n     */\n    estimators?: any\n\n    /**\n      A regressor which will be used to combine the base estimators. The default regressor is a [`RidgeCV`](sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV \"sklearn.linear_model.RidgeCV\").\n     */\n    final_estimator?: any\n\n    /**\n      Determines the cross-validation splitting strategy used in `cross\\_val\\_predict` to train `final\\_estimator`. Possible inputs for cv are:\n     */\n    cv?: number | 'prefit'\n\n    /**\n      The number of jobs to run in parallel for `fit` of all `estimators`. `undefined` means 1 unless in a `joblib.parallel\\_backend` context. -1 means using all processors. See Glossary for more details.\n     */\n    n_jobs?: number\n\n    /**\n      When `false`, only the predictions of estimators will be used as training data for `final\\_estimator`. When `true`, the `final\\_estimator` is trained on the predictions as well as the original training data.\n\n      @defaultValue `false`\n     */\n    passthrough?: boolean\n\n    /**\n      Verbosity level.\n\n      @defaultValue `0`\n     */\n    verbose?: number\n  }) {\n    this.id = `StackingRegressor${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('StackingRegressor.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.ensemble import StackingRegressor\ntry: bridgeStackingRegressor\nexcept NameError: bridgeStackingRegressor = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_StackingRegressor = {'estimators': ${\n      this.opts['estimators'] ?? undefined\n    }, 'final_estimator': ${this.opts['final_estimator'] ?? undefined}, 'cv': ${\n      this.opts['cv'] ?? undefined\n    }, 'n_jobs': ${this.opts['n_jobs'] ?? undefined}, 'passthrough': ${\n      this.opts['passthrough'] ?? undefined\n    }, 'verbose': ${this.opts['verbose'] ?? undefined}}\n\nctor_StackingRegressor = {k: v for k, v in ctor_StackingRegressor.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeStackingRegressor[${this.id}] = StackingRegressor(**ctor_StackingRegressor)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeStackingRegressor[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Fit the estimators.\n   */\n  async fit(opts: {\n    /**\n      Training vectors, where `n\\_samples` is the number of samples and `n\\_features` is the number of features.\n     */\n    X?: ArrayLike | SparseMatrix[]\n\n    /**\n      Target values.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights. If `undefined`, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('StackingRegressor must call init() before fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_StackingRegressor_fit = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_StackingRegressor_fit = {k: v for k, v in pms_StackingRegressor_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_StackingRegressor_fit = bridgeStackingRegressor[${this.id}].fit(**pms_StackingRegressor_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_StackingRegressor_fit.tolist() if hasattr(res_StackingRegressor_fit, 'tolist') else res_StackingRegressor_fit`\n  }\n\n  /**\n    Fit the estimators and return the predictions for X for each estimator.\n   */\n  async fit_transform(opts: {\n    /**\n      Training vectors, where `n\\_samples` is the number of samples and `n\\_features` is the number of features.\n     */\n    X?: ArrayLike | SparseMatrix[]\n\n    /**\n      Target values.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights. If `undefined`, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'StackingRegressor must call init() before fit_transform()'\n      )\n    }\n\n    // set up method params\n    await this._py.ex`pms_StackingRegressor_fit_transform = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_StackingRegressor_fit_transform = {k: v for k, v in pms_StackingRegressor_fit_transform.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_StackingRegressor_fit_transform = bridgeStackingRegressor[${this.id}].fit_transform(**pms_StackingRegressor_fit_transform)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_StackingRegressor_fit_transform.tolist() if hasattr(res_StackingRegressor_fit_transform, 'tolist') else res_StackingRegressor_fit_transform`\n  }\n\n  /**\n    Get output feature names for transformation.\n   */\n  async get_feature_names_out(opts: {\n    /**\n      Input features. The input feature names are only used when `passthrough` is `true`.\n     */\n    input_features?: any\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'StackingRegressor must call init() before get_feature_names_out()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_StackingRegressor_get_feature_names_out = {'input_features': ${\n      opts['input_features'] ?? undefined\n    }}\n\npms_StackingRegressor_get_feature_names_out = {k: v for k, v in pms_StackingRegressor_get_feature_names_out.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_StackingRegressor_get_feature_names_out = bridgeStackingRegressor[${this.id}].get_feature_names_out(**pms_StackingRegressor_get_feature_names_out)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_StackingRegressor_get_feature_names_out.tolist() if hasattr(res_StackingRegressor_get_feature_names_out, 'tolist') else res_StackingRegressor_get_feature_names_out`\n  }\n\n  /**\n    Get metadata routing of this object.\n\n    Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.\n   */\n  async get_metadata_routing(opts: {\n    /**\n      A [`MetadataRequest`](sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest \"sklearn.utils.metadata_routing.MetadataRequest\") encapsulating routing information.\n     */\n    routing?: any\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'StackingRegressor must call init() before get_metadata_routing()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_StackingRegressor_get_metadata_routing = {'routing': ${\n      opts['routing'] ?? undefined\n    }}\n\npms_StackingRegressor_get_metadata_routing = {k: v for k, v in pms_StackingRegressor_get_metadata_routing.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_StackingRegressor_get_metadata_routing = bridgeStackingRegressor[${this.id}].get_metadata_routing(**pms_StackingRegressor_get_metadata_routing)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_StackingRegressor_get_metadata_routing.tolist() if hasattr(res_StackingRegressor_get_metadata_routing, 'tolist') else res_StackingRegressor_get_metadata_routing`\n  }\n\n  /**\n    Predict target for X.\n   */\n  async predict(opts: {\n    /**\n      Training vectors, where `n\\_samples` is the number of samples and `n\\_features` is the number of features.\n     */\n    X?: ArrayLike | SparseMatrix[]\n\n    /**\n      Parameters to the `predict` called by the `final\\_estimator`. Note that this may be used to return uncertainties from some estimators with `return\\_std` or `return\\_cov`. Be aware that it will only accounts for uncertainty in the final estimator.\n     */\n    predict_params?: any\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('StackingRegressor must call init() before predict()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_StackingRegressor_predict = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'predict_params': ${\n      opts['predict_params'] ?? undefined\n    }}\n\npms_StackingRegressor_predict = {k: v for k, v in pms_StackingRegressor_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_StackingRegressor_predict = bridgeStackingRegressor[${this.id}].predict(**pms_StackingRegressor_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_StackingRegressor_predict.tolist() if hasattr(res_StackingRegressor_predict, 'tolist') else res_StackingRegressor_predict`\n  }\n\n  /**\n    Return the coefficient of determination of the prediction.\n\n    The coefficient of determination \\\\(R^2\\\\) is defined as \\\\((1 - \\\\frac{u}{v})\\\\), where \\\\(u\\\\) is the residual sum of squares `((y\\_true \\- y\\_pred)\\*\\* 2).sum()` and \\\\(v\\\\) is the total sum of squares `((y\\_true \\- y\\_true.mean()) \\*\\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\\\(R^2\\\\) score of 0.0.\n   */\n  async score(opts: {\n    /**\n      Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape `(n\\_samples, n\\_samples\\_fitted)`, where `n\\_samples\\_fitted` is the number of samples used in the fitting for the estimator.\n     */\n    X?: ArrayLike[]\n\n    /**\n      True values for `X`.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('StackingRegressor must call init() before score()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_StackingRegressor_score = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_StackingRegressor_score = {k: v for k, v in pms_StackingRegressor_score.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_StackingRegressor_score = bridgeStackingRegressor[${this.id}].score(**pms_StackingRegressor_score)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_StackingRegressor_score.tolist() if hasattr(res_StackingRegressor_score, 'tolist') else res_StackingRegressor_score`\n  }\n\n  /**\n    Request metadata passed to the `fit` method.\n\n    Note that this method is only relevant if `enable\\_metadata\\_routing=True` (see [`sklearn.set\\_config`](sklearn.set_config.html#sklearn.set_config \"sklearn.set_config\")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.\n\n    The options for each parameter are:\n   */\n  async set_fit_request(opts: {\n    /**\n      Metadata routing for `sample\\_weight` parameter in `fit`.\n     */\n    sample_weight?: string | boolean\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'StackingRegressor must call init() before set_fit_request()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_StackingRegressor_set_fit_request = {'sample_weight': ${\n      opts['sample_weight'] ?? undefined\n    }}\n\npms_StackingRegressor_set_fit_request = {k: v for k, v in pms_StackingRegressor_set_fit_request.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_StackingRegressor_set_fit_request = bridgeStackingRegressor[${this.id}].set_fit_request(**pms_StackingRegressor_set_fit_request)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_StackingRegressor_set_fit_request.tolist() if hasattr(res_StackingRegressor_set_fit_request, 'tolist') else res_StackingRegressor_set_fit_request`\n  }\n\n  /**\n    Set output container.\n\n    See [Introducing the set\\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.\n   */\n  async set_output(opts: {\n    /**\n      Configure output of `transform` and `fit\\_transform`.\n     */\n    transform?: 'default' | 'pandas'\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('StackingRegressor must call init() before set_output()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_StackingRegressor_set_output = {'transform': ${\n      opts['transform'] ?? undefined\n    }}\n\npms_StackingRegressor_set_output = {k: v for k, v in pms_StackingRegressor_set_output.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_StackingRegressor_set_output = bridgeStackingRegressor[${this.id}].set_output(**pms_StackingRegressor_set_output)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_StackingRegressor_set_output.tolist() if hasattr(res_StackingRegressor_set_output, 'tolist') else res_StackingRegressor_set_output`\n  }\n\n  /**\n    Request metadata passed to the `score` method.\n\n    Note that this method is only relevant if `enable\\_metadata\\_routing=True` (see [`sklearn.set\\_config`](sklearn.set_config.html#sklearn.set_config \"sklearn.set_config\")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.\n\n    The options for each parameter are:\n   */\n  async set_score_request(opts: {\n    /**\n      Metadata routing for `sample\\_weight` parameter in `score`.\n     */\n    sample_weight?: string | boolean\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'StackingRegressor must call init() before set_score_request()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_StackingRegressor_set_score_request = {'sample_weight': ${\n      opts['sample_weight'] ?? undefined\n    }}\n\npms_StackingRegressor_set_score_request = {k: v for k, v in pms_StackingRegressor_set_score_request.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_StackingRegressor_set_score_request = bridgeStackingRegressor[${this.id}].set_score_request(**pms_StackingRegressor_set_score_request)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_StackingRegressor_set_score_request.tolist() if hasattr(res_StackingRegressor_set_score_request, 'tolist') else res_StackingRegressor_set_score_request`\n  }\n\n  /**\n    Return the predictions for X for each estimator.\n   */\n  async transform(opts: {\n    /**\n      Training vectors, where `n\\_samples` is the number of samples and `n\\_features` is the number of features.\n     */\n    X?: ArrayLike | SparseMatrix[]\n  }): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('StackingRegressor must call init() before transform()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_StackingRegressor_transform = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_StackingRegressor_transform = {k: v for k, v in pms_StackingRegressor_transform.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_StackingRegressor_transform = bridgeStackingRegressor[${this.id}].transform(**pms_StackingRegressor_transform)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_StackingRegressor_transform.tolist() if hasattr(res_StackingRegressor_transform, 'tolist') else res_StackingRegressor_transform`\n  }\n\n  /**\n    The elements of the `estimators` parameter, having been fitted on the training data. If an estimator has been set to `'drop'`, it will not appear in `estimators\\_`. When `cv=\"prefit\"`, `estimators\\_` is set to `estimators` and is not fitted again.\n   */\n  get estimators_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'StackingRegressor must call init() before accessing estimators_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_StackingRegressor_estimators_ = bridgeStackingRegressor[${this.id}].estimators_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_StackingRegressor_estimators_.tolist() if hasattr(attr_StackingRegressor_estimators_, 'tolist') else attr_StackingRegressor_estimators_`\n    })()\n  }\n\n  /**\n    Attribute to access any fitted sub-estimators by name.\n   */\n  get named_estimators_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'StackingRegressor must call init() before accessing named_estimators_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_StackingRegressor_named_estimators_ = bridgeStackingRegressor[${this.id}].named_estimators_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_StackingRegressor_named_estimators_.tolist() if hasattr(attr_StackingRegressor_named_estimators_, 'tolist') else attr_StackingRegressor_named_estimators_`\n    })()\n  }\n\n  /**\n    Names of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying estimators expose such an attribute when fit.\n   */\n  get feature_names_in_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'StackingRegressor must call init() before accessing feature_names_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_StackingRegressor_feature_names_in_ = bridgeStackingRegressor[${this.id}].feature_names_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_StackingRegressor_feature_names_in_.tolist() if hasattr(attr_StackingRegressor_feature_names_in_, 'tolist') else attr_StackingRegressor_feature_names_in_`\n    })()\n  }\n\n  /**\n    The regressor to stacked the base estimators fitted.\n   */\n  get final_estimator_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'StackingRegressor must call init() before accessing final_estimator_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_StackingRegressor_final_estimator_ = bridgeStackingRegressor[${this.id}].final_estimator_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_StackingRegressor_final_estimator_.tolist() if hasattr(attr_StackingRegressor_final_estimator_, 'tolist') else attr_StackingRegressor_final_estimator_`\n    })()\n  }\n\n  /**\n    The method used by each base estimator.\n   */\n  get stack_method_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This StackingRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'StackingRegressor must call init() before accessing stack_method_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_StackingRegressor_stack_method_ = bridgeStackingRegressor[${this.id}].stack_method_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_StackingRegressor_stack_method_.tolist() if hasattr(attr_StackingRegressor_stack_method_, 'tolist') else attr_StackingRegressor_stack_method_`\n    })()\n  }\n}\n"],"mappings":";AAGA,OAAO,YAAY;AAeZ,IAAM,oBAAN,MAAwB;AAAA,EAQ7B,YAAY,MAkCT;AArCH,0BAA0B;AAC1B,uBAAuB;AAqCrB,SAAK,KAAK,oBAAoB,OAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC9D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,yDAAyD;AAAA,IAC3E;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,6CACb,KAAK,KAAK,YAAY,KAAK,8BACL,KAAK,KAAK,iBAAiB,KAAK,iBACtD,KAAK,KAAK,IAAI,KAAK,qBACN,KAAK,KAAK,QAAQ,KAAK,0BACpC,KAAK,KAAK,aAAa,KAAK,sBACd,KAAK,KAAK,SAAS,KAAK;AAAA;AAAA;AAIxC,UAAM,KAAK,IACR,6BAA6B,KAAK;AAErC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,iCAAiC,KAAK;AAErD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,IAAI,MAeO;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACnE;AAGA,UAAM,KAAK,IAAI,gDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,yDAAyD,KAAK;AAGjE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAeG;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IAAI,0DACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,mEAAmE,KAAK;AAG3E,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,sBAAsB,MAKX;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,sEACD,KAAK,gBAAgB,KAAK;AAAA;AAAA;AAM5B,UAAM,KAAK,IACR,2EAA2E,KAAK;AAGnF,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,qBAAqB,MAKV;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,8DACD,KAAK,SAAS,KAAK;AAAA;AAAA;AAMrB,UAAM,KAAK,IACR,0EAA0E,KAAK;AAGlF,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAQ,MAUO;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAGA,UAAM,KAAK,IAAI,oDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,uCACpB,KAAK,gBAAgB,KAAK;AAAA;AAAA;AAM5B,UAAM,KAAK,IACR,6DAA6D,KAAK;AAGrE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,MAAM,MAeQ;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAGA,UAAM,KAAK,IAAI,kDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,2DAA2D,KAAK;AAGnE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,gBAAgB,MAKL;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,+DACD,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,qEAAqE,KAAK;AAG7E,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,WAAW,MAKA;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAGA,UAAM,KAAK,IAAI,sDACb,KAAK,WAAW,KAAK;AAAA;AAAA;AAMvB,UAAM,KAAK,IACR,gEAAgE,KAAK;AAGxE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,kBAAkB,MAKP;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,iEACD,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,uEAAuE,KAAK;AAG/E,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,UAAU,MAKO;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,uDAAuD;AAAA,IACzE;AAGA,UAAM,KAAK,IAAI,sDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,+DAA+D,KAAK;AAGvE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,cAA4B;AAC9B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,kEAAkE,KAAK;AAG1E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAkC;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,wEAAwE,KAAK;AAGhF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAsC;AACxC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,wEAAwE,KAAK;AAGhF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,mBAAiC;AACnC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,uEAAuE,KAAK;AAG/E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,gBAA8B;AAChC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,oEAAoE,KAAK;AAG5E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;","names":[]}