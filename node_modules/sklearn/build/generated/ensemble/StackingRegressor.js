// src/generated/ensemble/StackingRegressor.ts
import crypto from "node:crypto";
var StackingRegressor = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `StackingRegressor${crypto.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("StackingRegressor.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import StackingRegressor
try: bridgeStackingRegressor
except NameError: bridgeStackingRegressor = {}
`;
    await this._py.ex`ctor_StackingRegressor = {'estimators': ${this.opts["estimators"] ?? void 0}, 'final_estimator': ${this.opts["final_estimator"] ?? void 0}, 'cv': ${this.opts["cv"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'passthrough': ${this.opts["passthrough"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}}

ctor_StackingRegressor = {k: v for k, v in ctor_StackingRegressor.items() if v is not None}`;
    await this._py.ex`bridgeStackingRegressor[${this.id}] = StackingRegressor(**ctor_StackingRegressor)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeStackingRegressor[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Fit the estimators.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingRegressor must call init() before fit()");
    }
    await this._py.ex`pms_StackingRegressor_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_StackingRegressor_fit = {k: v for k, v in pms_StackingRegressor_fit.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_fit = bridgeStackingRegressor[${this.id}].fit(**pms_StackingRegressor_fit)`;
    return this._py`res_StackingRegressor_fit.tolist() if hasattr(res_StackingRegressor_fit, 'tolist') else res_StackingRegressor_fit`;
  }
  /**
    Fit the estimators and return the predictions for X for each estimator.
   */
  async fit_transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before fit_transform()"
      );
    }
    await this._py.ex`pms_StackingRegressor_fit_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_StackingRegressor_fit_transform = {k: v for k, v in pms_StackingRegressor_fit_transform.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_fit_transform = bridgeStackingRegressor[${this.id}].fit_transform(**pms_StackingRegressor_fit_transform)`;
    return this._py`res_StackingRegressor_fit_transform.tolist() if hasattr(res_StackingRegressor_fit_transform, 'tolist') else res_StackingRegressor_fit_transform`;
  }
  /**
    Get output feature names for transformation.
   */
  async get_feature_names_out(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before get_feature_names_out()"
      );
    }
    await this._py.ex`pms_StackingRegressor_get_feature_names_out = {'input_features': ${opts["input_features"] ?? void 0}}

pms_StackingRegressor_get_feature_names_out = {k: v for k, v in pms_StackingRegressor_get_feature_names_out.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_get_feature_names_out = bridgeStackingRegressor[${this.id}].get_feature_names_out(**pms_StackingRegressor_get_feature_names_out)`;
    return this._py`res_StackingRegressor_get_feature_names_out.tolist() if hasattr(res_StackingRegressor_get_feature_names_out, 'tolist') else res_StackingRegressor_get_feature_names_out`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_StackingRegressor_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_StackingRegressor_get_metadata_routing = {k: v for k, v in pms_StackingRegressor_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_get_metadata_routing = bridgeStackingRegressor[${this.id}].get_metadata_routing(**pms_StackingRegressor_get_metadata_routing)`;
    return this._py`res_StackingRegressor_get_metadata_routing.tolist() if hasattr(res_StackingRegressor_get_metadata_routing, 'tolist') else res_StackingRegressor_get_metadata_routing`;
  }
  /**
    Predict target for X.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingRegressor must call init() before predict()");
    }
    await this._py.ex`pms_StackingRegressor_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'predict_params': ${opts["predict_params"] ?? void 0}}

pms_StackingRegressor_predict = {k: v for k, v in pms_StackingRegressor_predict.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_predict = bridgeStackingRegressor[${this.id}].predict(**pms_StackingRegressor_predict)`;
    return this._py`res_StackingRegressor_predict.tolist() if hasattr(res_StackingRegressor_predict, 'tolist') else res_StackingRegressor_predict`;
  }
  /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingRegressor must call init() before score()");
    }
    await this._py.ex`pms_StackingRegressor_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_StackingRegressor_score = {k: v for k, v in pms_StackingRegressor_score.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_score = bridgeStackingRegressor[${this.id}].score(**pms_StackingRegressor_score)`;
    return this._py`res_StackingRegressor_score.tolist() if hasattr(res_StackingRegressor_score, 'tolist') else res_StackingRegressor_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_StackingRegressor_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_StackingRegressor_set_fit_request = {k: v for k, v in pms_StackingRegressor_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_set_fit_request = bridgeStackingRegressor[${this.id}].set_fit_request(**pms_StackingRegressor_set_fit_request)`;
    return this._py`res_StackingRegressor_set_fit_request.tolist() if hasattr(res_StackingRegressor_set_fit_request, 'tolist') else res_StackingRegressor_set_fit_request`;
  }
  /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
  async set_output(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingRegressor must call init() before set_output()");
    }
    await this._py.ex`pms_StackingRegressor_set_output = {'transform': ${opts["transform"] ?? void 0}}

pms_StackingRegressor_set_output = {k: v for k, v in pms_StackingRegressor_set_output.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_set_output = bridgeStackingRegressor[${this.id}].set_output(**pms_StackingRegressor_set_output)`;
    return this._py`res_StackingRegressor_set_output.tolist() if hasattr(res_StackingRegressor_set_output, 'tolist') else res_StackingRegressor_set_output`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_StackingRegressor_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_StackingRegressor_set_score_request = {k: v for k, v in pms_StackingRegressor_set_score_request.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_set_score_request = bridgeStackingRegressor[${this.id}].set_score_request(**pms_StackingRegressor_set_score_request)`;
    return this._py`res_StackingRegressor_set_score_request.tolist() if hasattr(res_StackingRegressor_set_score_request, 'tolist') else res_StackingRegressor_set_score_request`;
  }
  /**
    Return the predictions for X for each estimator.
   */
  async transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingRegressor must call init() before transform()");
    }
    await this._py.ex`pms_StackingRegressor_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_StackingRegressor_transform = {k: v for k, v in pms_StackingRegressor_transform.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_transform = bridgeStackingRegressor[${this.id}].transform(**pms_StackingRegressor_transform)`;
    return this._py`res_StackingRegressor_transform.tolist() if hasattr(res_StackingRegressor_transform, 'tolist') else res_StackingRegressor_transform`;
  }
  /**
    The elements of the `estimators` parameter, having been fitted on the training data. If an estimator has been set to `'drop'`, it will not appear in `estimators\_`. When `cv="prefit"`, `estimators\_` is set to `estimators` and is not fitted again.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingRegressor_estimators_ = bridgeStackingRegressor[${this.id}].estimators_`;
      return this._py`attr_StackingRegressor_estimators_.tolist() if hasattr(attr_StackingRegressor_estimators_, 'tolist') else attr_StackingRegressor_estimators_`;
    })();
  }
  /**
    Attribute to access any fitted sub-estimators by name.
   */
  get named_estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before accessing named_estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingRegressor_named_estimators_ = bridgeStackingRegressor[${this.id}].named_estimators_`;
      return this._py`attr_StackingRegressor_named_estimators_.tolist() if hasattr(attr_StackingRegressor_named_estimators_, 'tolist') else attr_StackingRegressor_named_estimators_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying estimators expose such an attribute when fit.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingRegressor_feature_names_in_ = bridgeStackingRegressor[${this.id}].feature_names_in_`;
      return this._py`attr_StackingRegressor_feature_names_in_.tolist() if hasattr(attr_StackingRegressor_feature_names_in_, 'tolist') else attr_StackingRegressor_feature_names_in_`;
    })();
  }
  /**
    The regressor to stacked the base estimators fitted.
   */
  get final_estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before accessing final_estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingRegressor_final_estimator_ = bridgeStackingRegressor[${this.id}].final_estimator_`;
      return this._py`attr_StackingRegressor_final_estimator_.tolist() if hasattr(attr_StackingRegressor_final_estimator_, 'tolist') else attr_StackingRegressor_final_estimator_`;
    })();
  }
  /**
    The method used by each base estimator.
   */
  get stack_method_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before accessing stack_method_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingRegressor_stack_method_ = bridgeStackingRegressor[${this.id}].stack_method_`;
      return this._py`attr_StackingRegressor_stack_method_.tolist() if hasattr(attr_StackingRegressor_stack_method_, 'tolist') else attr_StackingRegressor_stack_method_`;
    })();
  }
};
export {
  StackingRegressor
};
//# sourceMappingURL=StackingRegressor.js.map