// src/generated/ensemble/AdaBoostClassifier.ts
import crypto from "node:crypto";
var AdaBoostClassifier = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `AdaBoostClassifier${crypto.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "AdaBoostClassifier.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import AdaBoostClassifier
try: bridgeAdaBoostClassifier
except NameError: bridgeAdaBoostClassifier = {}
`;
    await this._py.ex`ctor_AdaBoostClassifier = {'estimator': ${this.opts["estimator"] ?? void 0}, 'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'learning_rate': ${this.opts["learning_rate"] ?? void 0}, 'algorithm': ${this.opts["algorithm"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'base_estimator': ${this.opts["base_estimator"] ?? void 0}}

ctor_AdaBoostClassifier = {k: v for k, v in ctor_AdaBoostClassifier.items() if v is not None}`;
    await this._py.ex`bridgeAdaBoostClassifier[${this.id}] = AdaBoostClassifier(**ctor_AdaBoostClassifier)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeAdaBoostClassifier[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Compute the decision function of `X`.
   */
  async decision_function(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before decision_function()"
      );
    }
    await this._py.ex`pms_AdaBoostClassifier_decision_function = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_AdaBoostClassifier_decision_function = {k: v for k, v in pms_AdaBoostClassifier_decision_function.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_decision_function = bridgeAdaBoostClassifier[${this.id}].decision_function(**pms_AdaBoostClassifier_decision_function)`;
    return this._py`res_AdaBoostClassifier_decision_function.tolist() if hasattr(res_AdaBoostClassifier_decision_function, 'tolist') else res_AdaBoostClassifier_decision_function`;
  }
  /**
    Build a boosted classifier/regressor from the training set (X, y).
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("AdaBoostClassifier must call init() before fit()");
    }
    await this._py.ex`pms_AdaBoostClassifier_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_AdaBoostClassifier_fit = {k: v for k, v in pms_AdaBoostClassifier_fit.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_fit = bridgeAdaBoostClassifier[${this.id}].fit(**pms_AdaBoostClassifier_fit)`;
    return this._py`res_AdaBoostClassifier_fit.tolist() if hasattr(res_AdaBoostClassifier_fit, 'tolist') else res_AdaBoostClassifier_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_AdaBoostClassifier_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_AdaBoostClassifier_get_metadata_routing = {k: v for k, v in pms_AdaBoostClassifier_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_get_metadata_routing = bridgeAdaBoostClassifier[${this.id}].get_metadata_routing(**pms_AdaBoostClassifier_get_metadata_routing)`;
    return this._py`res_AdaBoostClassifier_get_metadata_routing.tolist() if hasattr(res_AdaBoostClassifier_get_metadata_routing, 'tolist') else res_AdaBoostClassifier_get_metadata_routing`;
  }
  /**
      Predict classes for X.
  
      The predicted class of an input sample is computed as the weighted mean prediction of the classifiers in the ensemble.
     */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("AdaBoostClassifier must call init() before predict()");
    }
    await this._py.ex`pms_AdaBoostClassifier_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_AdaBoostClassifier_predict = {k: v for k, v in pms_AdaBoostClassifier_predict.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_predict = bridgeAdaBoostClassifier[${this.id}].predict(**pms_AdaBoostClassifier_predict)`;
    return this._py`res_AdaBoostClassifier_predict.tolist() if hasattr(res_AdaBoostClassifier_predict, 'tolist') else res_AdaBoostClassifier_predict`;
  }
  /**
      Predict class log-probabilities for X.
  
      The predicted class log-probabilities of an input sample is computed as the weighted mean predicted class log-probabilities of the classifiers in the ensemble.
     */
  async predict_log_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before predict_log_proba()"
      );
    }
    await this._py.ex`pms_AdaBoostClassifier_predict_log_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_AdaBoostClassifier_predict_log_proba = {k: v for k, v in pms_AdaBoostClassifier_predict_log_proba.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_predict_log_proba = bridgeAdaBoostClassifier[${this.id}].predict_log_proba(**pms_AdaBoostClassifier_predict_log_proba)`;
    return this._py`res_AdaBoostClassifier_predict_log_proba.tolist() if hasattr(res_AdaBoostClassifier_predict_log_proba, 'tolist') else res_AdaBoostClassifier_predict_log_proba`;
  }
  /**
      Predict class probabilities for X.
  
      The predicted class probabilities of an input sample is computed as the weighted mean predicted class probabilities of the classifiers in the ensemble.
     */
  async predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before predict_proba()"
      );
    }
    await this._py.ex`pms_AdaBoostClassifier_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_AdaBoostClassifier_predict_proba = {k: v for k, v in pms_AdaBoostClassifier_predict_proba.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_predict_proba = bridgeAdaBoostClassifier[${this.id}].predict_proba(**pms_AdaBoostClassifier_predict_proba)`;
    return this._py`res_AdaBoostClassifier_predict_proba.tolist() if hasattr(res_AdaBoostClassifier_predict_proba, 'tolist') else res_AdaBoostClassifier_predict_proba`;
  }
  /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("AdaBoostClassifier must call init() before score()");
    }
    await this._py.ex`pms_AdaBoostClassifier_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_AdaBoostClassifier_score = {k: v for k, v in pms_AdaBoostClassifier_score.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_score = bridgeAdaBoostClassifier[${this.id}].score(**pms_AdaBoostClassifier_score)`;
    return this._py`res_AdaBoostClassifier_score.tolist() if hasattr(res_AdaBoostClassifier_score, 'tolist') else res_AdaBoostClassifier_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_AdaBoostClassifier_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_AdaBoostClassifier_set_fit_request = {k: v for k, v in pms_AdaBoostClassifier_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_set_fit_request = bridgeAdaBoostClassifier[${this.id}].set_fit_request(**pms_AdaBoostClassifier_set_fit_request)`;
    return this._py`res_AdaBoostClassifier_set_fit_request.tolist() if hasattr(res_AdaBoostClassifier_set_fit_request, 'tolist') else res_AdaBoostClassifier_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_AdaBoostClassifier_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_AdaBoostClassifier_set_score_request = {k: v for k, v in pms_AdaBoostClassifier_set_score_request.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_set_score_request = bridgeAdaBoostClassifier[${this.id}].set_score_request(**pms_AdaBoostClassifier_set_score_request)`;
    return this._py`res_AdaBoostClassifier_set_score_request.tolist() if hasattr(res_AdaBoostClassifier_set_score_request, 'tolist') else res_AdaBoostClassifier_set_score_request`;
  }
  /**
      Compute decision function of `X` for each boosting iteration.
  
      This method allows monitoring (i.e. determine error on testing set) after each boosting iteration.
     */
  async staged_decision_function(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before staged_decision_function()"
      );
    }
    await this._py.ex`pms_AdaBoostClassifier_staged_decision_function = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_AdaBoostClassifier_staged_decision_function = {k: v for k, v in pms_AdaBoostClassifier_staged_decision_function.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_staged_decision_function = bridgeAdaBoostClassifier[${this.id}].staged_decision_function(**pms_AdaBoostClassifier_staged_decision_function)`;
    return this._py`res_AdaBoostClassifier_staged_decision_function.tolist() if hasattr(res_AdaBoostClassifier_staged_decision_function, 'tolist') else res_AdaBoostClassifier_staged_decision_function`;
  }
  /**
      Return staged predictions for X.
  
      The predicted class of an input sample is computed as the weighted mean prediction of the classifiers in the ensemble.
  
      This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.
     */
  async staged_predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before staged_predict()"
      );
    }
    await this._py.ex`pms_AdaBoostClassifier_staged_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_AdaBoostClassifier_staged_predict = {k: v for k, v in pms_AdaBoostClassifier_staged_predict.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_staged_predict = bridgeAdaBoostClassifier[${this.id}].staged_predict(**pms_AdaBoostClassifier_staged_predict)`;
    return this._py`res_AdaBoostClassifier_staged_predict.tolist() if hasattr(res_AdaBoostClassifier_staged_predict, 'tolist') else res_AdaBoostClassifier_staged_predict`;
  }
  /**
      Predict class probabilities for X.
  
      The predicted class probabilities of an input sample is computed as the weighted mean predicted class probabilities of the classifiers in the ensemble.
  
      This generator method yields the ensemble predicted class probabilities after each iteration of boosting and therefore allows monitoring, such as to determine the predicted class probabilities on a test set after each boost.
     */
  async staged_predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before staged_predict_proba()"
      );
    }
    await this._py.ex`pms_AdaBoostClassifier_staged_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_AdaBoostClassifier_staged_predict_proba = {k: v for k, v in pms_AdaBoostClassifier_staged_predict_proba.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_staged_predict_proba = bridgeAdaBoostClassifier[${this.id}].staged_predict_proba(**pms_AdaBoostClassifier_staged_predict_proba)`;
    return this._py`res_AdaBoostClassifier_staged_predict_proba.tolist() if hasattr(res_AdaBoostClassifier_staged_predict_proba, 'tolist') else res_AdaBoostClassifier_staged_predict_proba`;
  }
  /**
      Return staged scores for X, y.
  
      This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.
     */
  async staged_score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before staged_score()"
      );
    }
    await this._py.ex`pms_AdaBoostClassifier_staged_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_AdaBoostClassifier_staged_score = {k: v for k, v in pms_AdaBoostClassifier_staged_score.items() if v is not None}`;
    await this._py.ex`res_AdaBoostClassifier_staged_score = bridgeAdaBoostClassifier[${this.id}].staged_score(**pms_AdaBoostClassifier_staged_score)`;
    return this._py`res_AdaBoostClassifier_staged_score.tolist() if hasattr(res_AdaBoostClassifier_staged_score, 'tolist') else res_AdaBoostClassifier_staged_score`;
  }
  /**
    The base estimator from which the ensemble is grown.
   */
  get estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before accessing estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostClassifier_estimator_ = bridgeAdaBoostClassifier[${this.id}].estimator_`;
      return this._py`attr_AdaBoostClassifier_estimator_.tolist() if hasattr(attr_AdaBoostClassifier_estimator_, 'tolist') else attr_AdaBoostClassifier_estimator_`;
    })();
  }
  /**
    The collection of fitted sub-estimators.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostClassifier_estimators_ = bridgeAdaBoostClassifier[${this.id}].estimators_`;
      return this._py`attr_AdaBoostClassifier_estimators_.tolist() if hasattr(attr_AdaBoostClassifier_estimators_, 'tolist') else attr_AdaBoostClassifier_estimators_`;
    })();
  }
  /**
    The classes labels.
   */
  get classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before accessing classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostClassifier_classes_ = bridgeAdaBoostClassifier[${this.id}].classes_`;
      return this._py`attr_AdaBoostClassifier_classes_.tolist() if hasattr(attr_AdaBoostClassifier_classes_, 'tolist') else attr_AdaBoostClassifier_classes_`;
    })();
  }
  /**
    The number of classes.
   */
  get n_classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before accessing n_classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostClassifier_n_classes_ = bridgeAdaBoostClassifier[${this.id}].n_classes_`;
      return this._py`attr_AdaBoostClassifier_n_classes_.tolist() if hasattr(attr_AdaBoostClassifier_n_classes_, 'tolist') else attr_AdaBoostClassifier_n_classes_`;
    })();
  }
  /**
    Weights for each estimator in the boosted ensemble.
   */
  get estimator_weights_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before accessing estimator_weights_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostClassifier_estimator_weights_ = bridgeAdaBoostClassifier[${this.id}].estimator_weights_`;
      return this._py`attr_AdaBoostClassifier_estimator_weights_.tolist() if hasattr(attr_AdaBoostClassifier_estimator_weights_, 'tolist') else attr_AdaBoostClassifier_estimator_weights_`;
    })();
  }
  /**
    Classification error for each estimator in the boosted ensemble.
   */
  get estimator_errors_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before accessing estimator_errors_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostClassifier_estimator_errors_ = bridgeAdaBoostClassifier[${this.id}].estimator_errors_`;
      return this._py`attr_AdaBoostClassifier_estimator_errors_.tolist() if hasattr(attr_AdaBoostClassifier_estimator_errors_, 'tolist') else attr_AdaBoostClassifier_estimator_errors_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostClassifier_n_features_in_ = bridgeAdaBoostClassifier[${this.id}].n_features_in_`;
      return this._py`attr_AdaBoostClassifier_n_features_in_.tolist() if hasattr(attr_AdaBoostClassifier_n_features_in_, 'tolist') else attr_AdaBoostClassifier_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostClassifier must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostClassifier_feature_names_in_ = bridgeAdaBoostClassifier[${this.id}].feature_names_in_`;
      return this._py`attr_AdaBoostClassifier_feature_names_in_.tolist() if hasattr(attr_AdaBoostClassifier_feature_names_in_, 'tolist') else attr_AdaBoostClassifier_feature_names_in_`;
    })();
  }
};

// src/generated/ensemble/AdaBoostRegressor.ts
import crypto2 from "node:crypto";
var AdaBoostRegressor = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `AdaBoostRegressor${crypto2.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("AdaBoostRegressor.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import AdaBoostRegressor
try: bridgeAdaBoostRegressor
except NameError: bridgeAdaBoostRegressor = {}
`;
    await this._py.ex`ctor_AdaBoostRegressor = {'estimator': ${this.opts["estimator"] ?? void 0}, 'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'learning_rate': ${this.opts["learning_rate"] ?? void 0}, 'loss': ${this.opts["loss"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'base_estimator': ${this.opts["base_estimator"] ?? void 0}}

ctor_AdaBoostRegressor = {k: v for k, v in ctor_AdaBoostRegressor.items() if v is not None}`;
    await this._py.ex`bridgeAdaBoostRegressor[${this.id}] = AdaBoostRegressor(**ctor_AdaBoostRegressor)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeAdaBoostRegressor[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Build a boosted classifier/regressor from the training set (X, y).
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("AdaBoostRegressor must call init() before fit()");
    }
    await this._py.ex`pms_AdaBoostRegressor_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_AdaBoostRegressor_fit = {k: v for k, v in pms_AdaBoostRegressor_fit.items() if v is not None}`;
    await this._py.ex`res_AdaBoostRegressor_fit = bridgeAdaBoostRegressor[${this.id}].fit(**pms_AdaBoostRegressor_fit)`;
    return this._py`res_AdaBoostRegressor_fit.tolist() if hasattr(res_AdaBoostRegressor_fit, 'tolist') else res_AdaBoostRegressor_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostRegressor must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_AdaBoostRegressor_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_AdaBoostRegressor_get_metadata_routing = {k: v for k, v in pms_AdaBoostRegressor_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_AdaBoostRegressor_get_metadata_routing = bridgeAdaBoostRegressor[${this.id}].get_metadata_routing(**pms_AdaBoostRegressor_get_metadata_routing)`;
    return this._py`res_AdaBoostRegressor_get_metadata_routing.tolist() if hasattr(res_AdaBoostRegressor_get_metadata_routing, 'tolist') else res_AdaBoostRegressor_get_metadata_routing`;
  }
  /**
      Predict regression value for X.
  
      The predicted regression value of an input sample is computed as the weighted median prediction of the regressors in the ensemble.
     */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("AdaBoostRegressor must call init() before predict()");
    }
    await this._py.ex`pms_AdaBoostRegressor_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_AdaBoostRegressor_predict = {k: v for k, v in pms_AdaBoostRegressor_predict.items() if v is not None}`;
    await this._py.ex`res_AdaBoostRegressor_predict = bridgeAdaBoostRegressor[${this.id}].predict(**pms_AdaBoostRegressor_predict)`;
    return this._py`res_AdaBoostRegressor_predict.tolist() if hasattr(res_AdaBoostRegressor_predict, 'tolist') else res_AdaBoostRegressor_predict`;
  }
  /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("AdaBoostRegressor must call init() before score()");
    }
    await this._py.ex`pms_AdaBoostRegressor_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_AdaBoostRegressor_score = {k: v for k, v in pms_AdaBoostRegressor_score.items() if v is not None}`;
    await this._py.ex`res_AdaBoostRegressor_score = bridgeAdaBoostRegressor[${this.id}].score(**pms_AdaBoostRegressor_score)`;
    return this._py`res_AdaBoostRegressor_score.tolist() if hasattr(res_AdaBoostRegressor_score, 'tolist') else res_AdaBoostRegressor_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostRegressor must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_AdaBoostRegressor_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_AdaBoostRegressor_set_fit_request = {k: v for k, v in pms_AdaBoostRegressor_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_AdaBoostRegressor_set_fit_request = bridgeAdaBoostRegressor[${this.id}].set_fit_request(**pms_AdaBoostRegressor_set_fit_request)`;
    return this._py`res_AdaBoostRegressor_set_fit_request.tolist() if hasattr(res_AdaBoostRegressor_set_fit_request, 'tolist') else res_AdaBoostRegressor_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostRegressor must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_AdaBoostRegressor_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_AdaBoostRegressor_set_score_request = {k: v for k, v in pms_AdaBoostRegressor_set_score_request.items() if v is not None}`;
    await this._py.ex`res_AdaBoostRegressor_set_score_request = bridgeAdaBoostRegressor[${this.id}].set_score_request(**pms_AdaBoostRegressor_set_score_request)`;
    return this._py`res_AdaBoostRegressor_set_score_request.tolist() if hasattr(res_AdaBoostRegressor_set_score_request, 'tolist') else res_AdaBoostRegressor_set_score_request`;
  }
  /**
      Return staged predictions for X.
  
      The predicted regression value of an input sample is computed as the weighted median prediction of the regressors in the ensemble.
  
      This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.
     */
  async staged_predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostRegressor must call init() before staged_predict()"
      );
    }
    await this._py.ex`pms_AdaBoostRegressor_staged_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_AdaBoostRegressor_staged_predict = {k: v for k, v in pms_AdaBoostRegressor_staged_predict.items() if v is not None}`;
    await this._py.ex`res_AdaBoostRegressor_staged_predict = bridgeAdaBoostRegressor[${this.id}].staged_predict(**pms_AdaBoostRegressor_staged_predict)`;
    return this._py`res_AdaBoostRegressor_staged_predict.tolist() if hasattr(res_AdaBoostRegressor_staged_predict, 'tolist') else res_AdaBoostRegressor_staged_predict`;
  }
  /**
      Return staged scores for X, y.
  
      This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.
     */
  async staged_score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostRegressor must call init() before staged_score()"
      );
    }
    await this._py.ex`pms_AdaBoostRegressor_staged_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_AdaBoostRegressor_staged_score = {k: v for k, v in pms_AdaBoostRegressor_staged_score.items() if v is not None}`;
    await this._py.ex`res_AdaBoostRegressor_staged_score = bridgeAdaBoostRegressor[${this.id}].staged_score(**pms_AdaBoostRegressor_staged_score)`;
    return this._py`res_AdaBoostRegressor_staged_score.tolist() if hasattr(res_AdaBoostRegressor_staged_score, 'tolist') else res_AdaBoostRegressor_staged_score`;
  }
  /**
    The base estimator from which the ensemble is grown.
   */
  get estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostRegressor must call init() before accessing estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostRegressor_estimator_ = bridgeAdaBoostRegressor[${this.id}].estimator_`;
      return this._py`attr_AdaBoostRegressor_estimator_.tolist() if hasattr(attr_AdaBoostRegressor_estimator_, 'tolist') else attr_AdaBoostRegressor_estimator_`;
    })();
  }
  /**
    The collection of fitted sub-estimators.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostRegressor must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostRegressor_estimators_ = bridgeAdaBoostRegressor[${this.id}].estimators_`;
      return this._py`attr_AdaBoostRegressor_estimators_.tolist() if hasattr(attr_AdaBoostRegressor_estimators_, 'tolist') else attr_AdaBoostRegressor_estimators_`;
    })();
  }
  /**
    Weights for each estimator in the boosted ensemble.
   */
  get estimator_weights_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostRegressor must call init() before accessing estimator_weights_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostRegressor_estimator_weights_ = bridgeAdaBoostRegressor[${this.id}].estimator_weights_`;
      return this._py`attr_AdaBoostRegressor_estimator_weights_.tolist() if hasattr(attr_AdaBoostRegressor_estimator_weights_, 'tolist') else attr_AdaBoostRegressor_estimator_weights_`;
    })();
  }
  /**
    Regression error for each estimator in the boosted ensemble.
   */
  get estimator_errors_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostRegressor must call init() before accessing estimator_errors_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostRegressor_estimator_errors_ = bridgeAdaBoostRegressor[${this.id}].estimator_errors_`;
      return this._py`attr_AdaBoostRegressor_estimator_errors_.tolist() if hasattr(attr_AdaBoostRegressor_estimator_errors_, 'tolist') else attr_AdaBoostRegressor_estimator_errors_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostRegressor must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostRegressor_n_features_in_ = bridgeAdaBoostRegressor[${this.id}].n_features_in_`;
      return this._py`attr_AdaBoostRegressor_n_features_in_.tolist() if hasattr(attr_AdaBoostRegressor_n_features_in_, 'tolist') else attr_AdaBoostRegressor_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This AdaBoostRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "AdaBoostRegressor must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_AdaBoostRegressor_feature_names_in_ = bridgeAdaBoostRegressor[${this.id}].feature_names_in_`;
      return this._py`attr_AdaBoostRegressor_feature_names_in_.tolist() if hasattr(attr_AdaBoostRegressor_feature_names_in_, 'tolist') else attr_AdaBoostRegressor_feature_names_in_`;
    })();
  }
};

// src/generated/ensemble/BaggingClassifier.ts
import crypto3 from "node:crypto";
var BaggingClassifier = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `BaggingClassifier${crypto3.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("BaggingClassifier.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import BaggingClassifier
try: bridgeBaggingClassifier
except NameError: bridgeBaggingClassifier = {}
`;
    await this._py.ex`ctor_BaggingClassifier = {'estimator': ${this.opts["estimator"] ?? void 0}, 'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'max_samples': ${this.opts["max_samples"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'bootstrap': ${this.opts["bootstrap"] ?? void 0}, 'bootstrap_features': ${this.opts["bootstrap_features"] ?? void 0}, 'oob_score': ${this.opts["oob_score"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'base_estimator': ${this.opts["base_estimator"] ?? void 0}}

ctor_BaggingClassifier = {k: v for k, v in ctor_BaggingClassifier.items() if v is not None}`;
    await this._py.ex`bridgeBaggingClassifier[${this.id}] = BaggingClassifier(**ctor_BaggingClassifier)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeBaggingClassifier[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Average of the decision functions of the base classifiers.
   */
  async decision_function(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before decision_function()"
      );
    }
    await this._py.ex`pms_BaggingClassifier_decision_function = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_BaggingClassifier_decision_function = {k: v for k, v in pms_BaggingClassifier_decision_function.items() if v is not None}`;
    await this._py.ex`res_BaggingClassifier_decision_function = bridgeBaggingClassifier[${this.id}].decision_function(**pms_BaggingClassifier_decision_function)`;
    return this._py`res_BaggingClassifier_decision_function.tolist() if hasattr(res_BaggingClassifier_decision_function, 'tolist') else res_BaggingClassifier_decision_function`;
  }
  /**
    Build a Bagging ensemble of estimators from the training set (X, y).
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("BaggingClassifier must call init() before fit()");
    }
    await this._py.ex`pms_BaggingClassifier_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_BaggingClassifier_fit = {k: v for k, v in pms_BaggingClassifier_fit.items() if v is not None}`;
    await this._py.ex`res_BaggingClassifier_fit = bridgeBaggingClassifier[${this.id}].fit(**pms_BaggingClassifier_fit)`;
    return this._py`res_BaggingClassifier_fit.tolist() if hasattr(res_BaggingClassifier_fit, 'tolist') else res_BaggingClassifier_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_BaggingClassifier_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_BaggingClassifier_get_metadata_routing = {k: v for k, v in pms_BaggingClassifier_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_BaggingClassifier_get_metadata_routing = bridgeBaggingClassifier[${this.id}].get_metadata_routing(**pms_BaggingClassifier_get_metadata_routing)`;
    return this._py`res_BaggingClassifier_get_metadata_routing.tolist() if hasattr(res_BaggingClassifier_get_metadata_routing, 'tolist') else res_BaggingClassifier_get_metadata_routing`;
  }
  /**
      Predict class for X.
  
      The predicted class of an input sample is computed as the class with the highest mean predicted probability. If base estimators do not implement a `predict\_proba` method, then it resorts to voting.
     */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("BaggingClassifier must call init() before predict()");
    }
    await this._py.ex`pms_BaggingClassifier_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_BaggingClassifier_predict = {k: v for k, v in pms_BaggingClassifier_predict.items() if v is not None}`;
    await this._py.ex`res_BaggingClassifier_predict = bridgeBaggingClassifier[${this.id}].predict(**pms_BaggingClassifier_predict)`;
    return this._py`res_BaggingClassifier_predict.tolist() if hasattr(res_BaggingClassifier_predict, 'tolist') else res_BaggingClassifier_predict`;
  }
  /**
      Predict class log-probabilities for X.
  
      The predicted class log-probabilities of an input sample is computed as the log of the mean predicted class probabilities of the base estimators in the ensemble.
     */
  async predict_log_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before predict_log_proba()"
      );
    }
    await this._py.ex`pms_BaggingClassifier_predict_log_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_BaggingClassifier_predict_log_proba = {k: v for k, v in pms_BaggingClassifier_predict_log_proba.items() if v is not None}`;
    await this._py.ex`res_BaggingClassifier_predict_log_proba = bridgeBaggingClassifier[${this.id}].predict_log_proba(**pms_BaggingClassifier_predict_log_proba)`;
    return this._py`res_BaggingClassifier_predict_log_proba.tolist() if hasattr(res_BaggingClassifier_predict_log_proba, 'tolist') else res_BaggingClassifier_predict_log_proba`;
  }
  /**
      Predict class probabilities for X.
  
      The predicted class probabilities of an input sample is computed as the mean predicted class probabilities of the base estimators in the ensemble. If base estimators do not implement a `predict\_proba` method, then it resorts to voting and the predicted class probabilities of an input sample represents the proportion of estimators predicting each class.
     */
  async predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before predict_proba()"
      );
    }
    await this._py.ex`pms_BaggingClassifier_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_BaggingClassifier_predict_proba = {k: v for k, v in pms_BaggingClassifier_predict_proba.items() if v is not None}`;
    await this._py.ex`res_BaggingClassifier_predict_proba = bridgeBaggingClassifier[${this.id}].predict_proba(**pms_BaggingClassifier_predict_proba)`;
    return this._py`res_BaggingClassifier_predict_proba.tolist() if hasattr(res_BaggingClassifier_predict_proba, 'tolist') else res_BaggingClassifier_predict_proba`;
  }
  /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("BaggingClassifier must call init() before score()");
    }
    await this._py.ex`pms_BaggingClassifier_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_BaggingClassifier_score = {k: v for k, v in pms_BaggingClassifier_score.items() if v is not None}`;
    await this._py.ex`res_BaggingClassifier_score = bridgeBaggingClassifier[${this.id}].score(**pms_BaggingClassifier_score)`;
    return this._py`res_BaggingClassifier_score.tolist() if hasattr(res_BaggingClassifier_score, 'tolist') else res_BaggingClassifier_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_BaggingClassifier_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_BaggingClassifier_set_fit_request = {k: v for k, v in pms_BaggingClassifier_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_BaggingClassifier_set_fit_request = bridgeBaggingClassifier[${this.id}].set_fit_request(**pms_BaggingClassifier_set_fit_request)`;
    return this._py`res_BaggingClassifier_set_fit_request.tolist() if hasattr(res_BaggingClassifier_set_fit_request, 'tolist') else res_BaggingClassifier_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_BaggingClassifier_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_BaggingClassifier_set_score_request = {k: v for k, v in pms_BaggingClassifier_set_score_request.items() if v is not None}`;
    await this._py.ex`res_BaggingClassifier_set_score_request = bridgeBaggingClassifier[${this.id}].set_score_request(**pms_BaggingClassifier_set_score_request)`;
    return this._py`res_BaggingClassifier_set_score_request.tolist() if hasattr(res_BaggingClassifier_set_score_request, 'tolist') else res_BaggingClassifier_set_score_request`;
  }
  /**
    The base estimator from which the ensemble is grown.
   */
  get estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before accessing estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingClassifier_estimator_ = bridgeBaggingClassifier[${this.id}].estimator_`;
      return this._py`attr_BaggingClassifier_estimator_.tolist() if hasattr(attr_BaggingClassifier_estimator_, 'tolist') else attr_BaggingClassifier_estimator_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingClassifier_n_features_in_ = bridgeBaggingClassifier[${this.id}].n_features_in_`;
      return this._py`attr_BaggingClassifier_n_features_in_.tolist() if hasattr(attr_BaggingClassifier_n_features_in_, 'tolist') else attr_BaggingClassifier_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingClassifier_feature_names_in_ = bridgeBaggingClassifier[${this.id}].feature_names_in_`;
      return this._py`attr_BaggingClassifier_feature_names_in_.tolist() if hasattr(attr_BaggingClassifier_feature_names_in_, 'tolist') else attr_BaggingClassifier_feature_names_in_`;
    })();
  }
  /**
    The collection of fitted base estimators.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingClassifier_estimators_ = bridgeBaggingClassifier[${this.id}].estimators_`;
      return this._py`attr_BaggingClassifier_estimators_.tolist() if hasattr(attr_BaggingClassifier_estimators_, 'tolist') else attr_BaggingClassifier_estimators_`;
    })();
  }
  /**
    The subset of drawn features for each base estimator.
   */
  get estimators_features_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before accessing estimators_features_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingClassifier_estimators_features_ = bridgeBaggingClassifier[${this.id}].estimators_features_`;
      return this._py`attr_BaggingClassifier_estimators_features_.tolist() if hasattr(attr_BaggingClassifier_estimators_features_, 'tolist') else attr_BaggingClassifier_estimators_features_`;
    })();
  }
  /**
    The classes labels.
   */
  get classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before accessing classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingClassifier_classes_ = bridgeBaggingClassifier[${this.id}].classes_`;
      return this._py`attr_BaggingClassifier_classes_.tolist() if hasattr(attr_BaggingClassifier_classes_, 'tolist') else attr_BaggingClassifier_classes_`;
    })();
  }
  /**
    The number of classes.
   */
  get n_classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before accessing n_classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingClassifier_n_classes_ = bridgeBaggingClassifier[${this.id}].n_classes_`;
      return this._py`attr_BaggingClassifier_n_classes_.tolist() if hasattr(attr_BaggingClassifier_n_classes_, 'tolist') else attr_BaggingClassifier_n_classes_`;
    })();
  }
  /**
    Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before accessing oob_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingClassifier_oob_score_ = bridgeBaggingClassifier[${this.id}].oob_score_`;
      return this._py`attr_BaggingClassifier_oob_score_.tolist() if hasattr(attr_BaggingClassifier_oob_score_, 'tolist') else attr_BaggingClassifier_oob_score_`;
    })();
  }
  /**
    Decision function computed with out-of-bag estimate on the training set. If n\_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, `oob\_decision\_function\_` might contain NaN. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_decision_function_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingClassifier must call init() before accessing oob_decision_function_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingClassifier_oob_decision_function_ = bridgeBaggingClassifier[${this.id}].oob_decision_function_`;
      return this._py`attr_BaggingClassifier_oob_decision_function_.tolist() if hasattr(attr_BaggingClassifier_oob_decision_function_, 'tolist') else attr_BaggingClassifier_oob_decision_function_`;
    })();
  }
};

// src/generated/ensemble/BaggingRegressor.ts
import crypto4 from "node:crypto";
var BaggingRegressor = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `BaggingRegressor${crypto4.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("BaggingRegressor.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import BaggingRegressor
try: bridgeBaggingRegressor
except NameError: bridgeBaggingRegressor = {}
`;
    await this._py.ex`ctor_BaggingRegressor = {'estimator': ${this.opts["estimator"] ?? void 0}, 'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'max_samples': ${this.opts["max_samples"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'bootstrap': ${this.opts["bootstrap"] ?? void 0}, 'bootstrap_features': ${this.opts["bootstrap_features"] ?? void 0}, 'oob_score': ${this.opts["oob_score"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'base_estimator': ${this.opts["base_estimator"] ?? void 0}}

ctor_BaggingRegressor = {k: v for k, v in ctor_BaggingRegressor.items() if v is not None}`;
    await this._py.ex`bridgeBaggingRegressor[${this.id}] = BaggingRegressor(**ctor_BaggingRegressor)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeBaggingRegressor[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Build a Bagging ensemble of estimators from the training set (X, y).
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("BaggingRegressor must call init() before fit()");
    }
    await this._py.ex`pms_BaggingRegressor_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_BaggingRegressor_fit = {k: v for k, v in pms_BaggingRegressor_fit.items() if v is not None}`;
    await this._py.ex`res_BaggingRegressor_fit = bridgeBaggingRegressor[${this.id}].fit(**pms_BaggingRegressor_fit)`;
    return this._py`res_BaggingRegressor_fit.tolist() if hasattr(res_BaggingRegressor_fit, 'tolist') else res_BaggingRegressor_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingRegressor must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_BaggingRegressor_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_BaggingRegressor_get_metadata_routing = {k: v for k, v in pms_BaggingRegressor_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_BaggingRegressor_get_metadata_routing = bridgeBaggingRegressor[${this.id}].get_metadata_routing(**pms_BaggingRegressor_get_metadata_routing)`;
    return this._py`res_BaggingRegressor_get_metadata_routing.tolist() if hasattr(res_BaggingRegressor_get_metadata_routing, 'tolist') else res_BaggingRegressor_get_metadata_routing`;
  }
  /**
      Predict regression target for X.
  
      The predicted regression target of an input sample is computed as the mean predicted regression targets of the estimators in the ensemble.
     */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("BaggingRegressor must call init() before predict()");
    }
    await this._py.ex`pms_BaggingRegressor_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_BaggingRegressor_predict = {k: v for k, v in pms_BaggingRegressor_predict.items() if v is not None}`;
    await this._py.ex`res_BaggingRegressor_predict = bridgeBaggingRegressor[${this.id}].predict(**pms_BaggingRegressor_predict)`;
    return this._py`res_BaggingRegressor_predict.tolist() if hasattr(res_BaggingRegressor_predict, 'tolist') else res_BaggingRegressor_predict`;
  }
  /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("BaggingRegressor must call init() before score()");
    }
    await this._py.ex`pms_BaggingRegressor_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_BaggingRegressor_score = {k: v for k, v in pms_BaggingRegressor_score.items() if v is not None}`;
    await this._py.ex`res_BaggingRegressor_score = bridgeBaggingRegressor[${this.id}].score(**pms_BaggingRegressor_score)`;
    return this._py`res_BaggingRegressor_score.tolist() if hasattr(res_BaggingRegressor_score, 'tolist') else res_BaggingRegressor_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingRegressor must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_BaggingRegressor_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_BaggingRegressor_set_fit_request = {k: v for k, v in pms_BaggingRegressor_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_BaggingRegressor_set_fit_request = bridgeBaggingRegressor[${this.id}].set_fit_request(**pms_BaggingRegressor_set_fit_request)`;
    return this._py`res_BaggingRegressor_set_fit_request.tolist() if hasattr(res_BaggingRegressor_set_fit_request, 'tolist') else res_BaggingRegressor_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingRegressor must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_BaggingRegressor_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_BaggingRegressor_set_score_request = {k: v for k, v in pms_BaggingRegressor_set_score_request.items() if v is not None}`;
    await this._py.ex`res_BaggingRegressor_set_score_request = bridgeBaggingRegressor[${this.id}].set_score_request(**pms_BaggingRegressor_set_score_request)`;
    return this._py`res_BaggingRegressor_set_score_request.tolist() if hasattr(res_BaggingRegressor_set_score_request, 'tolist') else res_BaggingRegressor_set_score_request`;
  }
  /**
    The base estimator from which the ensemble is grown.
   */
  get estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingRegressor must call init() before accessing estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingRegressor_estimator_ = bridgeBaggingRegressor[${this.id}].estimator_`;
      return this._py`attr_BaggingRegressor_estimator_.tolist() if hasattr(attr_BaggingRegressor_estimator_, 'tolist') else attr_BaggingRegressor_estimator_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingRegressor must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingRegressor_n_features_in_ = bridgeBaggingRegressor[${this.id}].n_features_in_`;
      return this._py`attr_BaggingRegressor_n_features_in_.tolist() if hasattr(attr_BaggingRegressor_n_features_in_, 'tolist') else attr_BaggingRegressor_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingRegressor must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingRegressor_feature_names_in_ = bridgeBaggingRegressor[${this.id}].feature_names_in_`;
      return this._py`attr_BaggingRegressor_feature_names_in_.tolist() if hasattr(attr_BaggingRegressor_feature_names_in_, 'tolist') else attr_BaggingRegressor_feature_names_in_`;
    })();
  }
  /**
    The collection of fitted sub-estimators.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingRegressor must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingRegressor_estimators_ = bridgeBaggingRegressor[${this.id}].estimators_`;
      return this._py`attr_BaggingRegressor_estimators_.tolist() if hasattr(attr_BaggingRegressor_estimators_, 'tolist') else attr_BaggingRegressor_estimators_`;
    })();
  }
  /**
    The subset of drawn features for each base estimator.
   */
  get estimators_features_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingRegressor must call init() before accessing estimators_features_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingRegressor_estimators_features_ = bridgeBaggingRegressor[${this.id}].estimators_features_`;
      return this._py`attr_BaggingRegressor_estimators_features_.tolist() if hasattr(attr_BaggingRegressor_estimators_features_, 'tolist') else attr_BaggingRegressor_estimators_features_`;
    })();
  }
  /**
    Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingRegressor must call init() before accessing oob_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingRegressor_oob_score_ = bridgeBaggingRegressor[${this.id}].oob_score_`;
      return this._py`attr_BaggingRegressor_oob_score_.tolist() if hasattr(attr_BaggingRegressor_oob_score_, 'tolist') else attr_BaggingRegressor_oob_score_`;
    })();
  }
  /**
    Prediction computed with out-of-bag estimate on the training set. If n\_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, `oob\_prediction\_` might contain NaN. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_prediction_() {
    if (this._isDisposed) {
      throw new Error(
        "This BaggingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "BaggingRegressor must call init() before accessing oob_prediction_"
      );
    }
    return (async () => {
      await this._py.ex`attr_BaggingRegressor_oob_prediction_ = bridgeBaggingRegressor[${this.id}].oob_prediction_`;
      return this._py`attr_BaggingRegressor_oob_prediction_.tolist() if hasattr(attr_BaggingRegressor_oob_prediction_, 'tolist') else attr_BaggingRegressor_oob_prediction_`;
    })();
  }
};

// src/generated/ensemble/ExtraTreesClassifier.ts
import crypto5 from "node:crypto";
var ExtraTreesClassifier = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `ExtraTreesClassifier${crypto5.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "ExtraTreesClassifier.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import ExtraTreesClassifier
try: bridgeExtraTreesClassifier
except NameError: bridgeExtraTreesClassifier = {}
`;
    await this._py.ex`ctor_ExtraTreesClassifier = {'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'criterion': ${this.opts["criterion"] ?? void 0}, 'max_depth': ${this.opts["max_depth"] ?? void 0}, 'min_samples_split': ${this.opts["min_samples_split"] ?? void 0}, 'min_samples_leaf': ${this.opts["min_samples_leaf"] ?? void 0}, 'min_weight_fraction_leaf': ${this.opts["min_weight_fraction_leaf"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'max_leaf_nodes': ${this.opts["max_leaf_nodes"] ?? void 0}, 'min_impurity_decrease': ${this.opts["min_impurity_decrease"] ?? void 0}, 'bootstrap': ${this.opts["bootstrap"] ?? void 0}, 'oob_score': ${this.opts["oob_score"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'class_weight': ${this.opts["class_weight"] ?? void 0}, 'ccp_alpha': ${this.opts["ccp_alpha"] ?? void 0}, 'max_samples': ${this.opts["max_samples"] ?? void 0}}

ctor_ExtraTreesClassifier = {k: v for k, v in ctor_ExtraTreesClassifier.items() if v is not None}`;
    await this._py.ex`bridgeExtraTreesClassifier[${this.id}] = ExtraTreesClassifier(**ctor_ExtraTreesClassifier)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeExtraTreesClassifier[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Apply trees in the forest to X, return leaf indices.
   */
  async apply(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("ExtraTreesClassifier must call init() before apply()");
    }
    await this._py.ex`pms_ExtraTreesClassifier_apply = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_ExtraTreesClassifier_apply = {k: v for k, v in pms_ExtraTreesClassifier_apply.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesClassifier_apply = bridgeExtraTreesClassifier[${this.id}].apply(**pms_ExtraTreesClassifier_apply)`;
    return this._py`res_ExtraTreesClassifier_apply.tolist() if hasattr(res_ExtraTreesClassifier_apply, 'tolist') else res_ExtraTreesClassifier_apply`;
  }
  /**
    Return the decision path in the forest.
   */
  async decision_path(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before decision_path()"
      );
    }
    await this._py.ex`pms_ExtraTreesClassifier_decision_path = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_ExtraTreesClassifier_decision_path = {k: v for k, v in pms_ExtraTreesClassifier_decision_path.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesClassifier_decision_path = bridgeExtraTreesClassifier[${this.id}].decision_path(**pms_ExtraTreesClassifier_decision_path)`;
    return this._py`res_ExtraTreesClassifier_decision_path.tolist() if hasattr(res_ExtraTreesClassifier_decision_path, 'tolist') else res_ExtraTreesClassifier_decision_path`;
  }
  /**
    Build a forest of trees from the training set (X, y).
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("ExtraTreesClassifier must call init() before fit()");
    }
    await this._py.ex`pms_ExtraTreesClassifier_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_ExtraTreesClassifier_fit = {k: v for k, v in pms_ExtraTreesClassifier_fit.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesClassifier_fit = bridgeExtraTreesClassifier[${this.id}].fit(**pms_ExtraTreesClassifier_fit)`;
    return this._py`res_ExtraTreesClassifier_fit.tolist() if hasattr(res_ExtraTreesClassifier_fit, 'tolist') else res_ExtraTreesClassifier_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_ExtraTreesClassifier_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_ExtraTreesClassifier_get_metadata_routing = {k: v for k, v in pms_ExtraTreesClassifier_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesClassifier_get_metadata_routing = bridgeExtraTreesClassifier[${this.id}].get_metadata_routing(**pms_ExtraTreesClassifier_get_metadata_routing)`;
    return this._py`res_ExtraTreesClassifier_get_metadata_routing.tolist() if hasattr(res_ExtraTreesClassifier_get_metadata_routing, 'tolist') else res_ExtraTreesClassifier_get_metadata_routing`;
  }
  /**
      Predict class for X.
  
      The predicted class of an input sample is a vote by the trees in the forest, weighted by their probability estimates. That is, the predicted class is the one with highest mean probability estimate across the trees.
     */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("ExtraTreesClassifier must call init() before predict()");
    }
    await this._py.ex`pms_ExtraTreesClassifier_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_ExtraTreesClassifier_predict = {k: v for k, v in pms_ExtraTreesClassifier_predict.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesClassifier_predict = bridgeExtraTreesClassifier[${this.id}].predict(**pms_ExtraTreesClassifier_predict)`;
    return this._py`res_ExtraTreesClassifier_predict.tolist() if hasattr(res_ExtraTreesClassifier_predict, 'tolist') else res_ExtraTreesClassifier_predict`;
  }
  /**
      Predict class log-probabilities for X.
  
      The predicted class log-probabilities of an input sample is computed as the log of the mean predicted class probabilities of the trees in the forest.
     */
  async predict_log_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before predict_log_proba()"
      );
    }
    await this._py.ex`pms_ExtraTreesClassifier_predict_log_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_ExtraTreesClassifier_predict_log_proba = {k: v for k, v in pms_ExtraTreesClassifier_predict_log_proba.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesClassifier_predict_log_proba = bridgeExtraTreesClassifier[${this.id}].predict_log_proba(**pms_ExtraTreesClassifier_predict_log_proba)`;
    return this._py`res_ExtraTreesClassifier_predict_log_proba.tolist() if hasattr(res_ExtraTreesClassifier_predict_log_proba, 'tolist') else res_ExtraTreesClassifier_predict_log_proba`;
  }
  /**
      Predict class probabilities for X.
  
      The predicted class probabilities of an input sample are computed as the mean predicted class probabilities of the trees in the forest. The class probability of a single tree is the fraction of samples of the same class in a leaf.
     */
  async predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before predict_proba()"
      );
    }
    await this._py.ex`pms_ExtraTreesClassifier_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_ExtraTreesClassifier_predict_proba = {k: v for k, v in pms_ExtraTreesClassifier_predict_proba.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesClassifier_predict_proba = bridgeExtraTreesClassifier[${this.id}].predict_proba(**pms_ExtraTreesClassifier_predict_proba)`;
    return this._py`res_ExtraTreesClassifier_predict_proba.tolist() if hasattr(res_ExtraTreesClassifier_predict_proba, 'tolist') else res_ExtraTreesClassifier_predict_proba`;
  }
  /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("ExtraTreesClassifier must call init() before score()");
    }
    await this._py.ex`pms_ExtraTreesClassifier_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_ExtraTreesClassifier_score = {k: v for k, v in pms_ExtraTreesClassifier_score.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesClassifier_score = bridgeExtraTreesClassifier[${this.id}].score(**pms_ExtraTreesClassifier_score)`;
    return this._py`res_ExtraTreesClassifier_score.tolist() if hasattr(res_ExtraTreesClassifier_score, 'tolist') else res_ExtraTreesClassifier_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_ExtraTreesClassifier_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_ExtraTreesClassifier_set_fit_request = {k: v for k, v in pms_ExtraTreesClassifier_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesClassifier_set_fit_request = bridgeExtraTreesClassifier[${this.id}].set_fit_request(**pms_ExtraTreesClassifier_set_fit_request)`;
    return this._py`res_ExtraTreesClassifier_set_fit_request.tolist() if hasattr(res_ExtraTreesClassifier_set_fit_request, 'tolist') else res_ExtraTreesClassifier_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_ExtraTreesClassifier_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_ExtraTreesClassifier_set_score_request = {k: v for k, v in pms_ExtraTreesClassifier_set_score_request.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesClassifier_set_score_request = bridgeExtraTreesClassifier[${this.id}].set_score_request(**pms_ExtraTreesClassifier_set_score_request)`;
    return this._py`res_ExtraTreesClassifier_set_score_request.tolist() if hasattr(res_ExtraTreesClassifier_set_score_request, 'tolist') else res_ExtraTreesClassifier_set_score_request`;
  }
  /**
    The child estimator template used to create the collection of fitted sub-estimators.
   */
  get estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before accessing estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesClassifier_estimator_ = bridgeExtraTreesClassifier[${this.id}].estimator_`;
      return this._py`attr_ExtraTreesClassifier_estimator_.tolist() if hasattr(attr_ExtraTreesClassifier_estimator_, 'tolist') else attr_ExtraTreesClassifier_estimator_`;
    })();
  }
  /**
    The collection of fitted sub-estimators.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesClassifier_estimators_ = bridgeExtraTreesClassifier[${this.id}].estimators_`;
      return this._py`attr_ExtraTreesClassifier_estimators_.tolist() if hasattr(attr_ExtraTreesClassifier_estimators_, 'tolist') else attr_ExtraTreesClassifier_estimators_`;
    })();
  }
  /**
    The classes labels (single output problem), or a list of arrays of class labels (multi-output problem).
   */
  get classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before accessing classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesClassifier_classes_ = bridgeExtraTreesClassifier[${this.id}].classes_`;
      return this._py`attr_ExtraTreesClassifier_classes_.tolist() if hasattr(attr_ExtraTreesClassifier_classes_, 'tolist') else attr_ExtraTreesClassifier_classes_`;
    })();
  }
  /**
    The number of classes (single output problem), or a list containing the number of classes for each output (multi-output problem).
   */
  get n_classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before accessing n_classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesClassifier_n_classes_ = bridgeExtraTreesClassifier[${this.id}].n_classes_`;
      return this._py`attr_ExtraTreesClassifier_n_classes_.tolist() if hasattr(attr_ExtraTreesClassifier_n_classes_, 'tolist') else attr_ExtraTreesClassifier_n_classes_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesClassifier_n_features_in_ = bridgeExtraTreesClassifier[${this.id}].n_features_in_`;
      return this._py`attr_ExtraTreesClassifier_n_features_in_.tolist() if hasattr(attr_ExtraTreesClassifier_n_features_in_, 'tolist') else attr_ExtraTreesClassifier_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesClassifier_feature_names_in_ = bridgeExtraTreesClassifier[${this.id}].feature_names_in_`;
      return this._py`attr_ExtraTreesClassifier_feature_names_in_.tolist() if hasattr(attr_ExtraTreesClassifier_feature_names_in_, 'tolist') else attr_ExtraTreesClassifier_feature_names_in_`;
    })();
  }
  /**
    The number of outputs when `fit` is performed.
   */
  get n_outputs_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before accessing n_outputs_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesClassifier_n_outputs_ = bridgeExtraTreesClassifier[${this.id}].n_outputs_`;
      return this._py`attr_ExtraTreesClassifier_n_outputs_.tolist() if hasattr(attr_ExtraTreesClassifier_n_outputs_, 'tolist') else attr_ExtraTreesClassifier_n_outputs_`;
    })();
  }
  /**
    Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before accessing oob_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesClassifier_oob_score_ = bridgeExtraTreesClassifier[${this.id}].oob_score_`;
      return this._py`attr_ExtraTreesClassifier_oob_score_.tolist() if hasattr(attr_ExtraTreesClassifier_oob_score_, 'tolist') else attr_ExtraTreesClassifier_oob_score_`;
    })();
  }
  /**
    Decision function computed with out-of-bag estimate on the training set. If n\_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, `oob\_decision\_function\_` might contain NaN. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_decision_function_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesClassifier must call init() before accessing oob_decision_function_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesClassifier_oob_decision_function_ = bridgeExtraTreesClassifier[${this.id}].oob_decision_function_`;
      return this._py`attr_ExtraTreesClassifier_oob_decision_function_.tolist() if hasattr(attr_ExtraTreesClassifier_oob_decision_function_, 'tolist') else attr_ExtraTreesClassifier_oob_decision_function_`;
    })();
  }
};

// src/generated/ensemble/ExtraTreesRegressor.ts
import crypto6 from "node:crypto";
var ExtraTreesRegressor = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `ExtraTreesRegressor${crypto6.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "ExtraTreesRegressor.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import ExtraTreesRegressor
try: bridgeExtraTreesRegressor
except NameError: bridgeExtraTreesRegressor = {}
`;
    await this._py.ex`ctor_ExtraTreesRegressor = {'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'criterion': ${this.opts["criterion"] ?? void 0}, 'max_depth': ${this.opts["max_depth"] ?? void 0}, 'min_samples_split': ${this.opts["min_samples_split"] ?? void 0}, 'min_samples_leaf': ${this.opts["min_samples_leaf"] ?? void 0}, 'min_weight_fraction_leaf': ${this.opts["min_weight_fraction_leaf"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'max_leaf_nodes': ${this.opts["max_leaf_nodes"] ?? void 0}, 'min_impurity_decrease': ${this.opts["min_impurity_decrease"] ?? void 0}, 'bootstrap': ${this.opts["bootstrap"] ?? void 0}, 'oob_score': ${this.opts["oob_score"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'ccp_alpha': ${this.opts["ccp_alpha"] ?? void 0}, 'max_samples': ${this.opts["max_samples"] ?? void 0}}

ctor_ExtraTreesRegressor = {k: v for k, v in ctor_ExtraTreesRegressor.items() if v is not None}`;
    await this._py.ex`bridgeExtraTreesRegressor[${this.id}] = ExtraTreesRegressor(**ctor_ExtraTreesRegressor)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeExtraTreesRegressor[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Apply trees in the forest to X, return leaf indices.
   */
  async apply(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("ExtraTreesRegressor must call init() before apply()");
    }
    await this._py.ex`pms_ExtraTreesRegressor_apply = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_ExtraTreesRegressor_apply = {k: v for k, v in pms_ExtraTreesRegressor_apply.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesRegressor_apply = bridgeExtraTreesRegressor[${this.id}].apply(**pms_ExtraTreesRegressor_apply)`;
    return this._py`res_ExtraTreesRegressor_apply.tolist() if hasattr(res_ExtraTreesRegressor_apply, 'tolist') else res_ExtraTreesRegressor_apply`;
  }
  /**
    Return the decision path in the forest.
   */
  async decision_path(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesRegressor must call init() before decision_path()"
      );
    }
    await this._py.ex`pms_ExtraTreesRegressor_decision_path = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_ExtraTreesRegressor_decision_path = {k: v for k, v in pms_ExtraTreesRegressor_decision_path.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesRegressor_decision_path = bridgeExtraTreesRegressor[${this.id}].decision_path(**pms_ExtraTreesRegressor_decision_path)`;
    return this._py`res_ExtraTreesRegressor_decision_path.tolist() if hasattr(res_ExtraTreesRegressor_decision_path, 'tolist') else res_ExtraTreesRegressor_decision_path`;
  }
  /**
    Build a forest of trees from the training set (X, y).
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("ExtraTreesRegressor must call init() before fit()");
    }
    await this._py.ex`pms_ExtraTreesRegressor_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_ExtraTreesRegressor_fit = {k: v for k, v in pms_ExtraTreesRegressor_fit.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesRegressor_fit = bridgeExtraTreesRegressor[${this.id}].fit(**pms_ExtraTreesRegressor_fit)`;
    return this._py`res_ExtraTreesRegressor_fit.tolist() if hasattr(res_ExtraTreesRegressor_fit, 'tolist') else res_ExtraTreesRegressor_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesRegressor must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_ExtraTreesRegressor_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_ExtraTreesRegressor_get_metadata_routing = {k: v for k, v in pms_ExtraTreesRegressor_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesRegressor_get_metadata_routing = bridgeExtraTreesRegressor[${this.id}].get_metadata_routing(**pms_ExtraTreesRegressor_get_metadata_routing)`;
    return this._py`res_ExtraTreesRegressor_get_metadata_routing.tolist() if hasattr(res_ExtraTreesRegressor_get_metadata_routing, 'tolist') else res_ExtraTreesRegressor_get_metadata_routing`;
  }
  /**
      Predict regression target for X.
  
      The predicted regression target of an input sample is computed as the mean predicted regression targets of the trees in the forest.
     */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("ExtraTreesRegressor must call init() before predict()");
    }
    await this._py.ex`pms_ExtraTreesRegressor_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_ExtraTreesRegressor_predict = {k: v for k, v in pms_ExtraTreesRegressor_predict.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesRegressor_predict = bridgeExtraTreesRegressor[${this.id}].predict(**pms_ExtraTreesRegressor_predict)`;
    return this._py`res_ExtraTreesRegressor_predict.tolist() if hasattr(res_ExtraTreesRegressor_predict, 'tolist') else res_ExtraTreesRegressor_predict`;
  }
  /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("ExtraTreesRegressor must call init() before score()");
    }
    await this._py.ex`pms_ExtraTreesRegressor_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_ExtraTreesRegressor_score = {k: v for k, v in pms_ExtraTreesRegressor_score.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesRegressor_score = bridgeExtraTreesRegressor[${this.id}].score(**pms_ExtraTreesRegressor_score)`;
    return this._py`res_ExtraTreesRegressor_score.tolist() if hasattr(res_ExtraTreesRegressor_score, 'tolist') else res_ExtraTreesRegressor_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesRegressor must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_ExtraTreesRegressor_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_ExtraTreesRegressor_set_fit_request = {k: v for k, v in pms_ExtraTreesRegressor_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesRegressor_set_fit_request = bridgeExtraTreesRegressor[${this.id}].set_fit_request(**pms_ExtraTreesRegressor_set_fit_request)`;
    return this._py`res_ExtraTreesRegressor_set_fit_request.tolist() if hasattr(res_ExtraTreesRegressor_set_fit_request, 'tolist') else res_ExtraTreesRegressor_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesRegressor must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_ExtraTreesRegressor_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_ExtraTreesRegressor_set_score_request = {k: v for k, v in pms_ExtraTreesRegressor_set_score_request.items() if v is not None}`;
    await this._py.ex`res_ExtraTreesRegressor_set_score_request = bridgeExtraTreesRegressor[${this.id}].set_score_request(**pms_ExtraTreesRegressor_set_score_request)`;
    return this._py`res_ExtraTreesRegressor_set_score_request.tolist() if hasattr(res_ExtraTreesRegressor_set_score_request, 'tolist') else res_ExtraTreesRegressor_set_score_request`;
  }
  /**
    The child estimator template used to create the collection of fitted sub-estimators.
   */
  get estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesRegressor must call init() before accessing estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesRegressor_estimator_ = bridgeExtraTreesRegressor[${this.id}].estimator_`;
      return this._py`attr_ExtraTreesRegressor_estimator_.tolist() if hasattr(attr_ExtraTreesRegressor_estimator_, 'tolist') else attr_ExtraTreesRegressor_estimator_`;
    })();
  }
  /**
    The collection of fitted sub-estimators.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesRegressor must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesRegressor_estimators_ = bridgeExtraTreesRegressor[${this.id}].estimators_`;
      return this._py`attr_ExtraTreesRegressor_estimators_.tolist() if hasattr(attr_ExtraTreesRegressor_estimators_, 'tolist') else attr_ExtraTreesRegressor_estimators_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesRegressor must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesRegressor_n_features_in_ = bridgeExtraTreesRegressor[${this.id}].n_features_in_`;
      return this._py`attr_ExtraTreesRegressor_n_features_in_.tolist() if hasattr(attr_ExtraTreesRegressor_n_features_in_, 'tolist') else attr_ExtraTreesRegressor_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesRegressor must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesRegressor_feature_names_in_ = bridgeExtraTreesRegressor[${this.id}].feature_names_in_`;
      return this._py`attr_ExtraTreesRegressor_feature_names_in_.tolist() if hasattr(attr_ExtraTreesRegressor_feature_names_in_, 'tolist') else attr_ExtraTreesRegressor_feature_names_in_`;
    })();
  }
  /**
    The number of outputs.
   */
  get n_outputs_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesRegressor must call init() before accessing n_outputs_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesRegressor_n_outputs_ = bridgeExtraTreesRegressor[${this.id}].n_outputs_`;
      return this._py`attr_ExtraTreesRegressor_n_outputs_.tolist() if hasattr(attr_ExtraTreesRegressor_n_outputs_, 'tolist') else attr_ExtraTreesRegressor_n_outputs_`;
    })();
  }
  /**
    Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesRegressor must call init() before accessing oob_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesRegressor_oob_score_ = bridgeExtraTreesRegressor[${this.id}].oob_score_`;
      return this._py`attr_ExtraTreesRegressor_oob_score_.tolist() if hasattr(attr_ExtraTreesRegressor_oob_score_, 'tolist') else attr_ExtraTreesRegressor_oob_score_`;
    })();
  }
  /**
    Prediction computed with out-of-bag estimate on the training set. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_prediction_() {
    if (this._isDisposed) {
      throw new Error(
        "This ExtraTreesRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "ExtraTreesRegressor must call init() before accessing oob_prediction_"
      );
    }
    return (async () => {
      await this._py.ex`attr_ExtraTreesRegressor_oob_prediction_ = bridgeExtraTreesRegressor[${this.id}].oob_prediction_`;
      return this._py`attr_ExtraTreesRegressor_oob_prediction_.tolist() if hasattr(attr_ExtraTreesRegressor_oob_prediction_, 'tolist') else attr_ExtraTreesRegressor_oob_prediction_`;
    })();
  }
};

// src/generated/ensemble/GradientBoostingClassifier.ts
import crypto7 from "node:crypto";
var GradientBoostingClassifier = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `GradientBoostingClassifier${crypto7.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "GradientBoostingClassifier.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier
try: bridgeGradientBoostingClassifier
except NameError: bridgeGradientBoostingClassifier = {}
`;
    await this._py.ex`ctor_GradientBoostingClassifier = {'loss': ${this.opts["loss"] ?? void 0}, 'learning_rate': ${this.opts["learning_rate"] ?? void 0}, 'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'subsample': ${this.opts["subsample"] ?? void 0}, 'criterion': ${this.opts["criterion"] ?? void 0}, 'min_samples_split': ${this.opts["min_samples_split"] ?? void 0}, 'min_samples_leaf': ${this.opts["min_samples_leaf"] ?? void 0}, 'min_weight_fraction_leaf': ${this.opts["min_weight_fraction_leaf"] ?? void 0}, 'max_depth': ${this.opts["max_depth"] ?? void 0}, 'min_impurity_decrease': ${this.opts["min_impurity_decrease"] ?? void 0}, 'init': ${this.opts["init"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'max_leaf_nodes': ${this.opts["max_leaf_nodes"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'validation_fraction': ${this.opts["validation_fraction"] ?? void 0}, 'n_iter_no_change': ${this.opts["n_iter_no_change"] ?? void 0}, 'tol': ${this.opts["tol"] ?? void 0}, 'ccp_alpha': ${this.opts["ccp_alpha"] ?? void 0}}

ctor_GradientBoostingClassifier = {k: v for k, v in ctor_GradientBoostingClassifier.items() if v is not None}`;
    await this._py.ex`bridgeGradientBoostingClassifier[${this.id}] = GradientBoostingClassifier(**ctor_GradientBoostingClassifier)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeGradientBoostingClassifier[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Apply trees in the ensemble to X, return leaf indices.
   */
  async apply(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before apply()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_apply = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_apply = {k: v for k, v in pms_GradientBoostingClassifier_apply.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_apply = bridgeGradientBoostingClassifier[${this.id}].apply(**pms_GradientBoostingClassifier_apply)`;
    return this._py`res_GradientBoostingClassifier_apply.tolist() if hasattr(res_GradientBoostingClassifier_apply, 'tolist') else res_GradientBoostingClassifier_apply`;
  }
  /**
    Compute the decision function of `X`.
   */
  async decision_function(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before decision_function()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_decision_function = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_decision_function = {k: v for k, v in pms_GradientBoostingClassifier_decision_function.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_decision_function = bridgeGradientBoostingClassifier[${this.id}].decision_function(**pms_GradientBoostingClassifier_decision_function)`;
    return this._py`res_GradientBoostingClassifier_decision_function.tolist() if hasattr(res_GradientBoostingClassifier_decision_function, 'tolist') else res_GradientBoostingClassifier_decision_function`;
  }
  /**
    Fit the gradient boosting model.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before fit()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None, 'monitor': ${opts["monitor"] ?? void 0}}

pms_GradientBoostingClassifier_fit = {k: v for k, v in pms_GradientBoostingClassifier_fit.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_fit = bridgeGradientBoostingClassifier[${this.id}].fit(**pms_GradientBoostingClassifier_fit)`;
    return this._py`res_GradientBoostingClassifier_fit.tolist() if hasattr(res_GradientBoostingClassifier_fit, 'tolist') else res_GradientBoostingClassifier_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_GradientBoostingClassifier_get_metadata_routing = {k: v for k, v in pms_GradientBoostingClassifier_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_get_metadata_routing = bridgeGradientBoostingClassifier[${this.id}].get_metadata_routing(**pms_GradientBoostingClassifier_get_metadata_routing)`;
    return this._py`res_GradientBoostingClassifier_get_metadata_routing.tolist() if hasattr(res_GradientBoostingClassifier_get_metadata_routing, 'tolist') else res_GradientBoostingClassifier_get_metadata_routing`;
  }
  /**
    Predict class for X.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before predict()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_predict = {k: v for k, v in pms_GradientBoostingClassifier_predict.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_predict = bridgeGradientBoostingClassifier[${this.id}].predict(**pms_GradientBoostingClassifier_predict)`;
    return this._py`res_GradientBoostingClassifier_predict.tolist() if hasattr(res_GradientBoostingClassifier_predict, 'tolist') else res_GradientBoostingClassifier_predict`;
  }
  /**
    Predict class log-probabilities for X.
   */
  async predict_log_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before predict_log_proba()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_predict_log_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_predict_log_proba = {k: v for k, v in pms_GradientBoostingClassifier_predict_log_proba.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_predict_log_proba = bridgeGradientBoostingClassifier[${this.id}].predict_log_proba(**pms_GradientBoostingClassifier_predict_log_proba)`;
    return this._py`res_GradientBoostingClassifier_predict_log_proba.tolist() if hasattr(res_GradientBoostingClassifier_predict_log_proba, 'tolist') else res_GradientBoostingClassifier_predict_log_proba`;
  }
  /**
    Predict class probabilities for X.
   */
  async predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before predict_proba()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_predict_proba = {k: v for k, v in pms_GradientBoostingClassifier_predict_proba.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_predict_proba = bridgeGradientBoostingClassifier[${this.id}].predict_proba(**pms_GradientBoostingClassifier_predict_proba)`;
    return this._py`res_GradientBoostingClassifier_predict_proba.tolist() if hasattr(res_GradientBoostingClassifier_predict_proba, 'tolist') else res_GradientBoostingClassifier_predict_proba`;
  }
  /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before score()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_GradientBoostingClassifier_score = {k: v for k, v in pms_GradientBoostingClassifier_score.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_score = bridgeGradientBoostingClassifier[${this.id}].score(**pms_GradientBoostingClassifier_score)`;
    return this._py`res_GradientBoostingClassifier_score.tolist() if hasattr(res_GradientBoostingClassifier_score, 'tolist') else res_GradientBoostingClassifier_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_set_fit_request = {'monitor': ${opts["monitor"] ?? void 0}, 'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_GradientBoostingClassifier_set_fit_request = {k: v for k, v in pms_GradientBoostingClassifier_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_set_fit_request = bridgeGradientBoostingClassifier[${this.id}].set_fit_request(**pms_GradientBoostingClassifier_set_fit_request)`;
    return this._py`res_GradientBoostingClassifier_set_fit_request.tolist() if hasattr(res_GradientBoostingClassifier_set_fit_request, 'tolist') else res_GradientBoostingClassifier_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_GradientBoostingClassifier_set_score_request = {k: v for k, v in pms_GradientBoostingClassifier_set_score_request.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_set_score_request = bridgeGradientBoostingClassifier[${this.id}].set_score_request(**pms_GradientBoostingClassifier_set_score_request)`;
    return this._py`res_GradientBoostingClassifier_set_score_request.tolist() if hasattr(res_GradientBoostingClassifier_set_score_request, 'tolist') else res_GradientBoostingClassifier_set_score_request`;
  }
  /**
      Compute decision function of `X` for each iteration.
  
      This method allows monitoring (i.e. determine error on testing set) after each stage.
     */
  async staged_decision_function(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before staged_decision_function()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_staged_decision_function = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_staged_decision_function = {k: v for k, v in pms_GradientBoostingClassifier_staged_decision_function.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_staged_decision_function = bridgeGradientBoostingClassifier[${this.id}].staged_decision_function(**pms_GradientBoostingClassifier_staged_decision_function)`;
    return this._py`res_GradientBoostingClassifier_staged_decision_function.tolist() if hasattr(res_GradientBoostingClassifier_staged_decision_function, 'tolist') else res_GradientBoostingClassifier_staged_decision_function`;
  }
  /**
      Predict class at each stage for X.
  
      This method allows monitoring (i.e. determine error on testing set) after each stage.
     */
  async staged_predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before staged_predict()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_staged_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_staged_predict = {k: v for k, v in pms_GradientBoostingClassifier_staged_predict.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_staged_predict = bridgeGradientBoostingClassifier[${this.id}].staged_predict(**pms_GradientBoostingClassifier_staged_predict)`;
    return this._py`res_GradientBoostingClassifier_staged_predict.tolist() if hasattr(res_GradientBoostingClassifier_staged_predict, 'tolist') else res_GradientBoostingClassifier_staged_predict`;
  }
  /**
      Predict class probabilities at each stage for X.
  
      This method allows monitoring (i.e. determine error on testing set) after each stage.
     */
  async staged_predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before staged_predict_proba()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_staged_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_staged_predict_proba = {k: v for k, v in pms_GradientBoostingClassifier_staged_predict_proba.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_staged_predict_proba = bridgeGradientBoostingClassifier[${this.id}].staged_predict_proba(**pms_GradientBoostingClassifier_staged_predict_proba)`;
    return this._py`res_GradientBoostingClassifier_staged_predict_proba.tolist() if hasattr(res_GradientBoostingClassifier_staged_predict_proba, 'tolist') else res_GradientBoostingClassifier_staged_predict_proba`;
  }
  /**
    The number of estimators as selected by early stopping (if `n\_iter\_no\_change` is specified). Otherwise it is set to `n\_estimators`.
   */
  get n_estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing n_estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_n_estimators_ = bridgeGradientBoostingClassifier[${this.id}].n_estimators_`;
      return this._py`attr_GradientBoostingClassifier_n_estimators_.tolist() if hasattr(attr_GradientBoostingClassifier_n_estimators_, 'tolist') else attr_GradientBoostingClassifier_n_estimators_`;
    })();
  }
  /**
    The improvement in loss on the out-of-bag samples relative to the previous iteration. `oob\_improvement\_\[0\]` is the improvement in loss of the first stage over the `init` estimator. Only available if `subsample < 1.0`.
   */
  get oob_improvement_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing oob_improvement_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_oob_improvement_ = bridgeGradientBoostingClassifier[${this.id}].oob_improvement_`;
      return this._py`attr_GradientBoostingClassifier_oob_improvement_.tolist() if hasattr(attr_GradientBoostingClassifier_oob_improvement_, 'tolist') else attr_GradientBoostingClassifier_oob_improvement_`;
    })();
  }
  /**
    The full history of the loss values on the out-of-bag samples. Only available if `subsample < 1.0`.
   */
  get oob_scores_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing oob_scores_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_oob_scores_ = bridgeGradientBoostingClassifier[${this.id}].oob_scores_`;
      return this._py`attr_GradientBoostingClassifier_oob_scores_.tolist() if hasattr(attr_GradientBoostingClassifier_oob_scores_, 'tolist') else attr_GradientBoostingClassifier_oob_scores_`;
    })();
  }
  /**
    The last value of the loss on the out-of-bag samples. It is the same as `oob\_scores\_\[-1\]`. Only available if `subsample < 1.0`.
   */
  get oob_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing oob_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_oob_score_ = bridgeGradientBoostingClassifier[${this.id}].oob_score_`;
      return this._py`attr_GradientBoostingClassifier_oob_score_.tolist() if hasattr(attr_GradientBoostingClassifier_oob_score_, 'tolist') else attr_GradientBoostingClassifier_oob_score_`;
    })();
  }
  /**
    The i-th score `train\_score\_\[i\]` is the loss of the model at iteration `i` on the in-bag sample. If `subsample \== 1` this is the loss on the training data.
   */
  get train_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing train_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_train_score_ = bridgeGradientBoostingClassifier[${this.id}].train_score_`;
      return this._py`attr_GradientBoostingClassifier_train_score_.tolist() if hasattr(attr_GradientBoostingClassifier_train_score_, 'tolist') else attr_GradientBoostingClassifier_train_score_`;
    })();
  }
  /**
    The estimator that provides the initial predictions. Set via the `init` argument or `loss.init\_estimator`.
   */
  get init_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing init_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_init_ = bridgeGradientBoostingClassifier[${this.id}].init_`;
      return this._py`attr_GradientBoostingClassifier_init_.tolist() if hasattr(attr_GradientBoostingClassifier_init_, 'tolist') else attr_GradientBoostingClassifier_init_`;
    })();
  }
  /**
    The collection of fitted sub-estimators. `loss\_.K` is 1 for binary classification, otherwise n\_classes.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_estimators_ = bridgeGradientBoostingClassifier[${this.id}].estimators_`;
      return this._py`attr_GradientBoostingClassifier_estimators_.tolist() if hasattr(attr_GradientBoostingClassifier_estimators_, 'tolist') else attr_GradientBoostingClassifier_estimators_`;
    })();
  }
  /**
    The classes labels.
   */
  get classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_classes_ = bridgeGradientBoostingClassifier[${this.id}].classes_`;
      return this._py`attr_GradientBoostingClassifier_classes_.tolist() if hasattr(attr_GradientBoostingClassifier_classes_, 'tolist') else attr_GradientBoostingClassifier_classes_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_n_features_in_ = bridgeGradientBoostingClassifier[${this.id}].n_features_in_`;
      return this._py`attr_GradientBoostingClassifier_n_features_in_.tolist() if hasattr(attr_GradientBoostingClassifier_n_features_in_, 'tolist') else attr_GradientBoostingClassifier_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_feature_names_in_ = bridgeGradientBoostingClassifier[${this.id}].feature_names_in_`;
      return this._py`attr_GradientBoostingClassifier_feature_names_in_.tolist() if hasattr(attr_GradientBoostingClassifier_feature_names_in_, 'tolist') else attr_GradientBoostingClassifier_feature_names_in_`;
    })();
  }
  /**
    The number of classes.
   */
  get n_classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing n_classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_n_classes_ = bridgeGradientBoostingClassifier[${this.id}].n_classes_`;
      return this._py`attr_GradientBoostingClassifier_n_classes_.tolist() if hasattr(attr_GradientBoostingClassifier_n_classes_, 'tolist') else attr_GradientBoostingClassifier_n_classes_`;
    })();
  }
  /**
    The inferred value of max\_features.
   */
  get max_features_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing max_features_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_max_features_ = bridgeGradientBoostingClassifier[${this.id}].max_features_`;
      return this._py`attr_GradientBoostingClassifier_max_features_.tolist() if hasattr(attr_GradientBoostingClassifier_max_features_, 'tolist') else attr_GradientBoostingClassifier_max_features_`;
    })();
  }
};

// src/generated/ensemble/GradientBoostingRegressor.ts
import crypto8 from "node:crypto";
var GradientBoostingRegressor = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `GradientBoostingRegressor${crypto8.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "GradientBoostingRegressor.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
try: bridgeGradientBoostingRegressor
except NameError: bridgeGradientBoostingRegressor = {}
`;
    await this._py.ex`ctor_GradientBoostingRegressor = {'loss': ${this.opts["loss"] ?? void 0}, 'learning_rate': ${this.opts["learning_rate"] ?? void 0}, 'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'subsample': ${this.opts["subsample"] ?? void 0}, 'criterion': ${this.opts["criterion"] ?? void 0}, 'min_samples_split': ${this.opts["min_samples_split"] ?? void 0}, 'min_samples_leaf': ${this.opts["min_samples_leaf"] ?? void 0}, 'min_weight_fraction_leaf': ${this.opts["min_weight_fraction_leaf"] ?? void 0}, 'max_depth': ${this.opts["max_depth"] ?? void 0}, 'min_impurity_decrease': ${this.opts["min_impurity_decrease"] ?? void 0}, 'init': ${this.opts["init"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'alpha': ${this.opts["alpha"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'max_leaf_nodes': ${this.opts["max_leaf_nodes"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'validation_fraction': ${this.opts["validation_fraction"] ?? void 0}, 'n_iter_no_change': ${this.opts["n_iter_no_change"] ?? void 0}, 'tol': ${this.opts["tol"] ?? void 0}, 'ccp_alpha': ${this.opts["ccp_alpha"] ?? void 0}}

ctor_GradientBoostingRegressor = {k: v for k, v in ctor_GradientBoostingRegressor.items() if v is not None}`;
    await this._py.ex`bridgeGradientBoostingRegressor[${this.id}] = GradientBoostingRegressor(**ctor_GradientBoostingRegressor)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeGradientBoostingRegressor[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Apply trees in the ensemble to X, return leaf indices.
   */
  async apply(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before apply()"
      );
    }
    await this._py.ex`pms_GradientBoostingRegressor_apply = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingRegressor_apply = {k: v for k, v in pms_GradientBoostingRegressor_apply.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingRegressor_apply = bridgeGradientBoostingRegressor[${this.id}].apply(**pms_GradientBoostingRegressor_apply)`;
    return this._py`res_GradientBoostingRegressor_apply.tolist() if hasattr(res_GradientBoostingRegressor_apply, 'tolist') else res_GradientBoostingRegressor_apply`;
  }
  /**
    Fit the gradient boosting model.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("GradientBoostingRegressor must call init() before fit()");
    }
    await this._py.ex`pms_GradientBoostingRegressor_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None, 'monitor': ${opts["monitor"] ?? void 0}}

pms_GradientBoostingRegressor_fit = {k: v for k, v in pms_GradientBoostingRegressor_fit.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingRegressor_fit = bridgeGradientBoostingRegressor[${this.id}].fit(**pms_GradientBoostingRegressor_fit)`;
    return this._py`res_GradientBoostingRegressor_fit.tolist() if hasattr(res_GradientBoostingRegressor_fit, 'tolist') else res_GradientBoostingRegressor_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_GradientBoostingRegressor_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_GradientBoostingRegressor_get_metadata_routing = {k: v for k, v in pms_GradientBoostingRegressor_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingRegressor_get_metadata_routing = bridgeGradientBoostingRegressor[${this.id}].get_metadata_routing(**pms_GradientBoostingRegressor_get_metadata_routing)`;
    return this._py`res_GradientBoostingRegressor_get_metadata_routing.tolist() if hasattr(res_GradientBoostingRegressor_get_metadata_routing, 'tolist') else res_GradientBoostingRegressor_get_metadata_routing`;
  }
  /**
    Predict regression target for X.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before predict()"
      );
    }
    await this._py.ex`pms_GradientBoostingRegressor_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingRegressor_predict = {k: v for k, v in pms_GradientBoostingRegressor_predict.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingRegressor_predict = bridgeGradientBoostingRegressor[${this.id}].predict(**pms_GradientBoostingRegressor_predict)`;
    return this._py`res_GradientBoostingRegressor_predict.tolist() if hasattr(res_GradientBoostingRegressor_predict, 'tolist') else res_GradientBoostingRegressor_predict`;
  }
  /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before score()"
      );
    }
    await this._py.ex`pms_GradientBoostingRegressor_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_GradientBoostingRegressor_score = {k: v for k, v in pms_GradientBoostingRegressor_score.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingRegressor_score = bridgeGradientBoostingRegressor[${this.id}].score(**pms_GradientBoostingRegressor_score)`;
    return this._py`res_GradientBoostingRegressor_score.tolist() if hasattr(res_GradientBoostingRegressor_score, 'tolist') else res_GradientBoostingRegressor_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_GradientBoostingRegressor_set_fit_request = {'monitor': ${opts["monitor"] ?? void 0}, 'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_GradientBoostingRegressor_set_fit_request = {k: v for k, v in pms_GradientBoostingRegressor_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingRegressor_set_fit_request = bridgeGradientBoostingRegressor[${this.id}].set_fit_request(**pms_GradientBoostingRegressor_set_fit_request)`;
    return this._py`res_GradientBoostingRegressor_set_fit_request.tolist() if hasattr(res_GradientBoostingRegressor_set_fit_request, 'tolist') else res_GradientBoostingRegressor_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_GradientBoostingRegressor_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_GradientBoostingRegressor_set_score_request = {k: v for k, v in pms_GradientBoostingRegressor_set_score_request.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingRegressor_set_score_request = bridgeGradientBoostingRegressor[${this.id}].set_score_request(**pms_GradientBoostingRegressor_set_score_request)`;
    return this._py`res_GradientBoostingRegressor_set_score_request.tolist() if hasattr(res_GradientBoostingRegressor_set_score_request, 'tolist') else res_GradientBoostingRegressor_set_score_request`;
  }
  /**
      Predict regression target at each stage for X.
  
      This method allows monitoring (i.e. determine error on testing set) after each stage.
     */
  async staged_predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before staged_predict()"
      );
    }
    await this._py.ex`pms_GradientBoostingRegressor_staged_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingRegressor_staged_predict = {k: v for k, v in pms_GradientBoostingRegressor_staged_predict.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingRegressor_staged_predict = bridgeGradientBoostingRegressor[${this.id}].staged_predict(**pms_GradientBoostingRegressor_staged_predict)`;
    return this._py`res_GradientBoostingRegressor_staged_predict.tolist() if hasattr(res_GradientBoostingRegressor_staged_predict, 'tolist') else res_GradientBoostingRegressor_staged_predict`;
  }
  /**
    The improvement in loss on the out-of-bag samples relative to the previous iteration. `oob\_improvement\_\[0\]` is the improvement in loss of the first stage over the `init` estimator. Only available if `subsample < 1.0`.
   */
  get oob_improvement_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before accessing oob_improvement_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingRegressor_oob_improvement_ = bridgeGradientBoostingRegressor[${this.id}].oob_improvement_`;
      return this._py`attr_GradientBoostingRegressor_oob_improvement_.tolist() if hasattr(attr_GradientBoostingRegressor_oob_improvement_, 'tolist') else attr_GradientBoostingRegressor_oob_improvement_`;
    })();
  }
  /**
    The full history of the loss values on the out-of-bag samples. Only available if `subsample < 1.0`.
   */
  get oob_scores_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before accessing oob_scores_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingRegressor_oob_scores_ = bridgeGradientBoostingRegressor[${this.id}].oob_scores_`;
      return this._py`attr_GradientBoostingRegressor_oob_scores_.tolist() if hasattr(attr_GradientBoostingRegressor_oob_scores_, 'tolist') else attr_GradientBoostingRegressor_oob_scores_`;
    })();
  }
  /**
    The last value of the loss on the out-of-bag samples. It is the same as `oob\_scores\_\[-1\]`. Only available if `subsample < 1.0`.
   */
  get oob_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before accessing oob_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingRegressor_oob_score_ = bridgeGradientBoostingRegressor[${this.id}].oob_score_`;
      return this._py`attr_GradientBoostingRegressor_oob_score_.tolist() if hasattr(attr_GradientBoostingRegressor_oob_score_, 'tolist') else attr_GradientBoostingRegressor_oob_score_`;
    })();
  }
  /**
    The i-th score `train\_score\_\[i\]` is the loss of the model at iteration `i` on the in-bag sample. If `subsample \== 1` this is the loss on the training data.
   */
  get train_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before accessing train_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingRegressor_train_score_ = bridgeGradientBoostingRegressor[${this.id}].train_score_`;
      return this._py`attr_GradientBoostingRegressor_train_score_.tolist() if hasattr(attr_GradientBoostingRegressor_train_score_, 'tolist') else attr_GradientBoostingRegressor_train_score_`;
    })();
  }
  /**
    The estimator that provides the initial predictions. Set via the `init` argument or `loss.init\_estimator`.
   */
  get init_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before accessing init_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingRegressor_init_ = bridgeGradientBoostingRegressor[${this.id}].init_`;
      return this._py`attr_GradientBoostingRegressor_init_.tolist() if hasattr(attr_GradientBoostingRegressor_init_, 'tolist') else attr_GradientBoostingRegressor_init_`;
    })();
  }
  /**
    The collection of fitted sub-estimators.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingRegressor_estimators_ = bridgeGradientBoostingRegressor[${this.id}].estimators_`;
      return this._py`attr_GradientBoostingRegressor_estimators_.tolist() if hasattr(attr_GradientBoostingRegressor_estimators_, 'tolist') else attr_GradientBoostingRegressor_estimators_`;
    })();
  }
  /**
    The number of estimators as selected by early stopping (if `n\_iter\_no\_change` is specified). Otherwise it is set to `n\_estimators`.
   */
  get n_estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before accessing n_estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingRegressor_n_estimators_ = bridgeGradientBoostingRegressor[${this.id}].n_estimators_`;
      return this._py`attr_GradientBoostingRegressor_n_estimators_.tolist() if hasattr(attr_GradientBoostingRegressor_n_estimators_, 'tolist') else attr_GradientBoostingRegressor_n_estimators_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingRegressor_n_features_in_ = bridgeGradientBoostingRegressor[${this.id}].n_features_in_`;
      return this._py`attr_GradientBoostingRegressor_n_features_in_.tolist() if hasattr(attr_GradientBoostingRegressor_n_features_in_, 'tolist') else attr_GradientBoostingRegressor_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingRegressor_feature_names_in_ = bridgeGradientBoostingRegressor[${this.id}].feature_names_in_`;
      return this._py`attr_GradientBoostingRegressor_feature_names_in_.tolist() if hasattr(attr_GradientBoostingRegressor_feature_names_in_, 'tolist') else attr_GradientBoostingRegressor_feature_names_in_`;
    })();
  }
  /**
    The inferred value of max\_features.
   */
  get max_features_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingRegressor must call init() before accessing max_features_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingRegressor_max_features_ = bridgeGradientBoostingRegressor[${this.id}].max_features_`;
      return this._py`attr_GradientBoostingRegressor_max_features_.tolist() if hasattr(attr_GradientBoostingRegressor_max_features_, 'tolist') else attr_GradientBoostingRegressor_max_features_`;
    })();
  }
};

// src/generated/ensemble/HistGradientBoostingClassifier.ts
import crypto9 from "node:crypto";
var HistGradientBoostingClassifier = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `HistGradientBoostingClassifier${crypto9.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "HistGradientBoostingClassifier.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import HistGradientBoostingClassifier
try: bridgeHistGradientBoostingClassifier
except NameError: bridgeHistGradientBoostingClassifier = {}
`;
    await this._py.ex`ctor_HistGradientBoostingClassifier = {'loss': ${this.opts["loss"] ?? void 0}, 'learning_rate': ${this.opts["learning_rate"] ?? void 0}, 'max_iter': ${this.opts["max_iter"] ?? void 0}, 'max_leaf_nodes': ${this.opts["max_leaf_nodes"] ?? void 0}, 'max_depth': ${this.opts["max_depth"] ?? void 0}, 'min_samples_leaf': ${this.opts["min_samples_leaf"] ?? void 0}, 'l2_regularization': ${this.opts["l2_regularization"] ?? void 0}, 'max_bins': ${this.opts["max_bins"] ?? void 0}, 'categorical_features': np.array(${this.opts["categorical_features"] ?? void 0}) if ${this.opts["categorical_features"] !== void 0} else None, 'monotonic_cst': np.array(${this.opts["monotonic_cst"] ?? void 0}) if ${this.opts["monotonic_cst"] !== void 0} else None, 'interaction_cst': ${this.opts["interaction_cst"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'early_stopping': ${this.opts["early_stopping"] ?? void 0}, 'scoring': ${this.opts["scoring"] ?? void 0}, 'validation_fraction': ${this.opts["validation_fraction"] ?? void 0}, 'n_iter_no_change': ${this.opts["n_iter_no_change"] ?? void 0}, 'tol': ${this.opts["tol"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'class_weight': ${this.opts["class_weight"] ?? void 0}}

ctor_HistGradientBoostingClassifier = {k: v for k, v in ctor_HistGradientBoostingClassifier.items() if v is not None}`;
    await this._py.ex`bridgeHistGradientBoostingClassifier[${this.id}] = HistGradientBoostingClassifier(**ctor_HistGradientBoostingClassifier)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeHistGradientBoostingClassifier[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Compute the decision function of `X`.
   */
  async decision_function(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before decision_function()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingClassifier_decision_function = {'X': ${opts["X"] ?? void 0}}

pms_HistGradientBoostingClassifier_decision_function = {k: v for k, v in pms_HistGradientBoostingClassifier_decision_function.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingClassifier_decision_function = bridgeHistGradientBoostingClassifier[${this.id}].decision_function(**pms_HistGradientBoostingClassifier_decision_function)`;
    return this._py`res_HistGradientBoostingClassifier_decision_function.tolist() if hasattr(res_HistGradientBoostingClassifier_decision_function, 'tolist') else res_HistGradientBoostingClassifier_decision_function`;
  }
  /**
    Fit the gradient boosting model.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before fit()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingClassifier_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_HistGradientBoostingClassifier_fit = {k: v for k, v in pms_HistGradientBoostingClassifier_fit.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingClassifier_fit = bridgeHistGradientBoostingClassifier[${this.id}].fit(**pms_HistGradientBoostingClassifier_fit)`;
    return this._py`res_HistGradientBoostingClassifier_fit.tolist() if hasattr(res_HistGradientBoostingClassifier_fit, 'tolist') else res_HistGradientBoostingClassifier_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingClassifier_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_HistGradientBoostingClassifier_get_metadata_routing = {k: v for k, v in pms_HistGradientBoostingClassifier_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingClassifier_get_metadata_routing = bridgeHistGradientBoostingClassifier[${this.id}].get_metadata_routing(**pms_HistGradientBoostingClassifier_get_metadata_routing)`;
    return this._py`res_HistGradientBoostingClassifier_get_metadata_routing.tolist() if hasattr(res_HistGradientBoostingClassifier_get_metadata_routing, 'tolist') else res_HistGradientBoostingClassifier_get_metadata_routing`;
  }
  /**
    Predict classes for X.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before predict()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingClassifier_predict = {'X': ${opts["X"] ?? void 0}}

pms_HistGradientBoostingClassifier_predict = {k: v for k, v in pms_HistGradientBoostingClassifier_predict.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingClassifier_predict = bridgeHistGradientBoostingClassifier[${this.id}].predict(**pms_HistGradientBoostingClassifier_predict)`;
    return this._py`res_HistGradientBoostingClassifier_predict.tolist() if hasattr(res_HistGradientBoostingClassifier_predict, 'tolist') else res_HistGradientBoostingClassifier_predict`;
  }
  /**
    Predict class probabilities for X.
   */
  async predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before predict_proba()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingClassifier_predict_proba = {'X': ${opts["X"] ?? void 0}}

pms_HistGradientBoostingClassifier_predict_proba = {k: v for k, v in pms_HistGradientBoostingClassifier_predict_proba.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingClassifier_predict_proba = bridgeHistGradientBoostingClassifier[${this.id}].predict_proba(**pms_HistGradientBoostingClassifier_predict_proba)`;
    return this._py`res_HistGradientBoostingClassifier_predict_proba.tolist() if hasattr(res_HistGradientBoostingClassifier_predict_proba, 'tolist') else res_HistGradientBoostingClassifier_predict_proba`;
  }
  /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before score()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingClassifier_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_HistGradientBoostingClassifier_score = {k: v for k, v in pms_HistGradientBoostingClassifier_score.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingClassifier_score = bridgeHistGradientBoostingClassifier[${this.id}].score(**pms_HistGradientBoostingClassifier_score)`;
    return this._py`res_HistGradientBoostingClassifier_score.tolist() if hasattr(res_HistGradientBoostingClassifier_score, 'tolist') else res_HistGradientBoostingClassifier_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingClassifier_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_HistGradientBoostingClassifier_set_fit_request = {k: v for k, v in pms_HistGradientBoostingClassifier_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingClassifier_set_fit_request = bridgeHistGradientBoostingClassifier[${this.id}].set_fit_request(**pms_HistGradientBoostingClassifier_set_fit_request)`;
    return this._py`res_HistGradientBoostingClassifier_set_fit_request.tolist() if hasattr(res_HistGradientBoostingClassifier_set_fit_request, 'tolist') else res_HistGradientBoostingClassifier_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingClassifier_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_HistGradientBoostingClassifier_set_score_request = {k: v for k, v in pms_HistGradientBoostingClassifier_set_score_request.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingClassifier_set_score_request = bridgeHistGradientBoostingClassifier[${this.id}].set_score_request(**pms_HistGradientBoostingClassifier_set_score_request)`;
    return this._py`res_HistGradientBoostingClassifier_set_score_request.tolist() if hasattr(res_HistGradientBoostingClassifier_set_score_request, 'tolist') else res_HistGradientBoostingClassifier_set_score_request`;
  }
  /**
      Compute decision function of `X` for each iteration.
  
      This method allows monitoring (i.e. determine error on testing set) after each stage.
     */
  async staged_decision_function(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before staged_decision_function()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingClassifier_staged_decision_function = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_HistGradientBoostingClassifier_staged_decision_function = {k: v for k, v in pms_HistGradientBoostingClassifier_staged_decision_function.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingClassifier_staged_decision_function = bridgeHistGradientBoostingClassifier[${this.id}].staged_decision_function(**pms_HistGradientBoostingClassifier_staged_decision_function)`;
    return this._py`res_HistGradientBoostingClassifier_staged_decision_function.tolist() if hasattr(res_HistGradientBoostingClassifier_staged_decision_function, 'tolist') else res_HistGradientBoostingClassifier_staged_decision_function`;
  }
  /**
      Predict classes at each iteration.
  
      This method allows monitoring (i.e. determine error on testing set) after each stage.
     */
  async staged_predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before staged_predict()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingClassifier_staged_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_HistGradientBoostingClassifier_staged_predict = {k: v for k, v in pms_HistGradientBoostingClassifier_staged_predict.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingClassifier_staged_predict = bridgeHistGradientBoostingClassifier[${this.id}].staged_predict(**pms_HistGradientBoostingClassifier_staged_predict)`;
    return this._py`res_HistGradientBoostingClassifier_staged_predict.tolist() if hasattr(res_HistGradientBoostingClassifier_staged_predict, 'tolist') else res_HistGradientBoostingClassifier_staged_predict`;
  }
  /**
      Predict class probabilities at each iteration.
  
      This method allows monitoring (i.e. determine error on testing set) after each stage.
     */
  async staged_predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before staged_predict_proba()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingClassifier_staged_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_HistGradientBoostingClassifier_staged_predict_proba = {k: v for k, v in pms_HistGradientBoostingClassifier_staged_predict_proba.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingClassifier_staged_predict_proba = bridgeHistGradientBoostingClassifier[${this.id}].staged_predict_proba(**pms_HistGradientBoostingClassifier_staged_predict_proba)`;
    return this._py`res_HistGradientBoostingClassifier_staged_predict_proba.tolist() if hasattr(res_HistGradientBoostingClassifier_staged_predict_proba, 'tolist') else res_HistGradientBoostingClassifier_staged_predict_proba`;
  }
  /**
    Class labels.
   */
  get classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before accessing classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingClassifier_classes_ = bridgeHistGradientBoostingClassifier[${this.id}].classes_`;
      return this._py`attr_HistGradientBoostingClassifier_classes_.tolist() if hasattr(attr_HistGradientBoostingClassifier_classes_, 'tolist') else attr_HistGradientBoostingClassifier_classes_`;
    })();
  }
  /**
    Indicates whether early stopping is used during training.
   */
  get do_early_stopping_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before accessing do_early_stopping_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingClassifier_do_early_stopping_ = bridgeHistGradientBoostingClassifier[${this.id}].do_early_stopping_`;
      return this._py`attr_HistGradientBoostingClassifier_do_early_stopping_.tolist() if hasattr(attr_HistGradientBoostingClassifier_do_early_stopping_, 'tolist') else attr_HistGradientBoostingClassifier_do_early_stopping_`;
    })();
  }
  /**
    The number of tree that are built at each iteration. This is equal to 1 for binary classification, and to `n\_classes` for multiclass classification.
   */
  get n_trees_per_iteration_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before accessing n_trees_per_iteration_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingClassifier_n_trees_per_iteration_ = bridgeHistGradientBoostingClassifier[${this.id}].n_trees_per_iteration_`;
      return this._py`attr_HistGradientBoostingClassifier_n_trees_per_iteration_.tolist() if hasattr(attr_HistGradientBoostingClassifier_n_trees_per_iteration_, 'tolist') else attr_HistGradientBoostingClassifier_n_trees_per_iteration_`;
    })();
  }
  /**
    The scores at each iteration on the training data. The first entry is the score of the ensemble before the first iteration. Scores are computed according to the `scoring` parameter. If `scoring` is not loss, scores are computed on a subset of at most 10 000 samples. Empty if no early stopping.
   */
  get train_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before accessing train_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingClassifier_train_score_ = bridgeHistGradientBoostingClassifier[${this.id}].train_score_`;
      return this._py`attr_HistGradientBoostingClassifier_train_score_.tolist() if hasattr(attr_HistGradientBoostingClassifier_train_score_, 'tolist') else attr_HistGradientBoostingClassifier_train_score_`;
    })();
  }
  /**
    The scores at each iteration on the held-out validation data. The first entry is the score of the ensemble before the first iteration. Scores are computed according to the `scoring` parameter. Empty if no early stopping or if `validation\_fraction` is `undefined`.
   */
  get validation_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before accessing validation_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingClassifier_validation_score_ = bridgeHistGradientBoostingClassifier[${this.id}].validation_score_`;
      return this._py`attr_HistGradientBoostingClassifier_validation_score_.tolist() if hasattr(attr_HistGradientBoostingClassifier_validation_score_, 'tolist') else attr_HistGradientBoostingClassifier_validation_score_`;
    })();
  }
  /**
    Boolean mask for the categorical features. `undefined` if there are no categorical features.
   */
  get is_categorical_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before accessing is_categorical_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingClassifier_is_categorical_ = bridgeHistGradientBoostingClassifier[${this.id}].is_categorical_`;
      return this._py`attr_HistGradientBoostingClassifier_is_categorical_.tolist() if hasattr(attr_HistGradientBoostingClassifier_is_categorical_, 'tolist') else attr_HistGradientBoostingClassifier_is_categorical_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingClassifier_n_features_in_ = bridgeHistGradientBoostingClassifier[${this.id}].n_features_in_`;
      return this._py`attr_HistGradientBoostingClassifier_n_features_in_.tolist() if hasattr(attr_HistGradientBoostingClassifier_n_features_in_, 'tolist') else attr_HistGradientBoostingClassifier_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingClassifier must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingClassifier_feature_names_in_ = bridgeHistGradientBoostingClassifier[${this.id}].feature_names_in_`;
      return this._py`attr_HistGradientBoostingClassifier_feature_names_in_.tolist() if hasattr(attr_HistGradientBoostingClassifier_feature_names_in_, 'tolist') else attr_HistGradientBoostingClassifier_feature_names_in_`;
    })();
  }
};

// src/generated/ensemble/HistGradientBoostingRegressor.ts
import crypto10 from "node:crypto";
var HistGradientBoostingRegressor = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `HistGradientBoostingRegressor${crypto10.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "HistGradientBoostingRegressor.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import HistGradientBoostingRegressor
try: bridgeHistGradientBoostingRegressor
except NameError: bridgeHistGradientBoostingRegressor = {}
`;
    await this._py.ex`ctor_HistGradientBoostingRegressor = {'loss': ${this.opts["loss"] ?? void 0}, 'quantile': ${this.opts["quantile"] ?? void 0}, 'learning_rate': ${this.opts["learning_rate"] ?? void 0}, 'max_iter': ${this.opts["max_iter"] ?? void 0}, 'max_leaf_nodes': ${this.opts["max_leaf_nodes"] ?? void 0}, 'max_depth': ${this.opts["max_depth"] ?? void 0}, 'min_samples_leaf': ${this.opts["min_samples_leaf"] ?? void 0}, 'l2_regularization': ${this.opts["l2_regularization"] ?? void 0}, 'max_bins': ${this.opts["max_bins"] ?? void 0}, 'categorical_features': np.array(${this.opts["categorical_features"] ?? void 0}) if ${this.opts["categorical_features"] !== void 0} else None, 'monotonic_cst': np.array(${this.opts["monotonic_cst"] ?? void 0}) if ${this.opts["monotonic_cst"] !== void 0} else None, 'interaction_cst': ${this.opts["interaction_cst"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'early_stopping': ${this.opts["early_stopping"] ?? void 0}, 'scoring': ${this.opts["scoring"] ?? void 0}, 'validation_fraction': ${this.opts["validation_fraction"] ?? void 0}, 'n_iter_no_change': ${this.opts["n_iter_no_change"] ?? void 0}, 'tol': ${this.opts["tol"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}}

ctor_HistGradientBoostingRegressor = {k: v for k, v in ctor_HistGradientBoostingRegressor.items() if v is not None}`;
    await this._py.ex`bridgeHistGradientBoostingRegressor[${this.id}] = HistGradientBoostingRegressor(**ctor_HistGradientBoostingRegressor)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeHistGradientBoostingRegressor[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Fit the gradient boosting model.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before fit()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingRegressor_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_HistGradientBoostingRegressor_fit = {k: v for k, v in pms_HistGradientBoostingRegressor_fit.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingRegressor_fit = bridgeHistGradientBoostingRegressor[${this.id}].fit(**pms_HistGradientBoostingRegressor_fit)`;
    return this._py`res_HistGradientBoostingRegressor_fit.tolist() if hasattr(res_HistGradientBoostingRegressor_fit, 'tolist') else res_HistGradientBoostingRegressor_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingRegressor_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_HistGradientBoostingRegressor_get_metadata_routing = {k: v for k, v in pms_HistGradientBoostingRegressor_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingRegressor_get_metadata_routing = bridgeHistGradientBoostingRegressor[${this.id}].get_metadata_routing(**pms_HistGradientBoostingRegressor_get_metadata_routing)`;
    return this._py`res_HistGradientBoostingRegressor_get_metadata_routing.tolist() if hasattr(res_HistGradientBoostingRegressor_get_metadata_routing, 'tolist') else res_HistGradientBoostingRegressor_get_metadata_routing`;
  }
  /**
    Predict values for X.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before predict()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingRegressor_predict = {'X': ${opts["X"] ?? void 0}}

pms_HistGradientBoostingRegressor_predict = {k: v for k, v in pms_HistGradientBoostingRegressor_predict.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingRegressor_predict = bridgeHistGradientBoostingRegressor[${this.id}].predict(**pms_HistGradientBoostingRegressor_predict)`;
    return this._py`res_HistGradientBoostingRegressor_predict.tolist() if hasattr(res_HistGradientBoostingRegressor_predict, 'tolist') else res_HistGradientBoostingRegressor_predict`;
  }
  /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before score()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingRegressor_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_HistGradientBoostingRegressor_score = {k: v for k, v in pms_HistGradientBoostingRegressor_score.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingRegressor_score = bridgeHistGradientBoostingRegressor[${this.id}].score(**pms_HistGradientBoostingRegressor_score)`;
    return this._py`res_HistGradientBoostingRegressor_score.tolist() if hasattr(res_HistGradientBoostingRegressor_score, 'tolist') else res_HistGradientBoostingRegressor_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingRegressor_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_HistGradientBoostingRegressor_set_fit_request = {k: v for k, v in pms_HistGradientBoostingRegressor_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingRegressor_set_fit_request = bridgeHistGradientBoostingRegressor[${this.id}].set_fit_request(**pms_HistGradientBoostingRegressor_set_fit_request)`;
    return this._py`res_HistGradientBoostingRegressor_set_fit_request.tolist() if hasattr(res_HistGradientBoostingRegressor_set_fit_request, 'tolist') else res_HistGradientBoostingRegressor_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingRegressor_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_HistGradientBoostingRegressor_set_score_request = {k: v for k, v in pms_HistGradientBoostingRegressor_set_score_request.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingRegressor_set_score_request = bridgeHistGradientBoostingRegressor[${this.id}].set_score_request(**pms_HistGradientBoostingRegressor_set_score_request)`;
    return this._py`res_HistGradientBoostingRegressor_set_score_request.tolist() if hasattr(res_HistGradientBoostingRegressor_set_score_request, 'tolist') else res_HistGradientBoostingRegressor_set_score_request`;
  }
  /**
      Predict regression target for each iteration.
  
      This method allows monitoring (i.e. determine error on testing set) after each stage.
     */
  async staged_predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before staged_predict()"
      );
    }
    await this._py.ex`pms_HistGradientBoostingRegressor_staged_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_HistGradientBoostingRegressor_staged_predict = {k: v for k, v in pms_HistGradientBoostingRegressor_staged_predict.items() if v is not None}`;
    await this._py.ex`res_HistGradientBoostingRegressor_staged_predict = bridgeHistGradientBoostingRegressor[${this.id}].staged_predict(**pms_HistGradientBoostingRegressor_staged_predict)`;
    return this._py`res_HistGradientBoostingRegressor_staged_predict.tolist() if hasattr(res_HistGradientBoostingRegressor_staged_predict, 'tolist') else res_HistGradientBoostingRegressor_staged_predict`;
  }
  /**
    Indicates whether early stopping is used during training.
   */
  get do_early_stopping_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before accessing do_early_stopping_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingRegressor_do_early_stopping_ = bridgeHistGradientBoostingRegressor[${this.id}].do_early_stopping_`;
      return this._py`attr_HistGradientBoostingRegressor_do_early_stopping_.tolist() if hasattr(attr_HistGradientBoostingRegressor_do_early_stopping_, 'tolist') else attr_HistGradientBoostingRegressor_do_early_stopping_`;
    })();
  }
  /**
    The number of tree that are built at each iteration. For regressors, this is always 1.
   */
  get n_trees_per_iteration_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before accessing n_trees_per_iteration_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingRegressor_n_trees_per_iteration_ = bridgeHistGradientBoostingRegressor[${this.id}].n_trees_per_iteration_`;
      return this._py`attr_HistGradientBoostingRegressor_n_trees_per_iteration_.tolist() if hasattr(attr_HistGradientBoostingRegressor_n_trees_per_iteration_, 'tolist') else attr_HistGradientBoostingRegressor_n_trees_per_iteration_`;
    })();
  }
  /**
    The scores at each iteration on the training data. The first entry is the score of the ensemble before the first iteration. Scores are computed according to the `scoring` parameter. If `scoring` is not loss, scores are computed on a subset of at most 10 000 samples. Empty if no early stopping.
   */
  get train_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before accessing train_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingRegressor_train_score_ = bridgeHistGradientBoostingRegressor[${this.id}].train_score_`;
      return this._py`attr_HistGradientBoostingRegressor_train_score_.tolist() if hasattr(attr_HistGradientBoostingRegressor_train_score_, 'tolist') else attr_HistGradientBoostingRegressor_train_score_`;
    })();
  }
  /**
    The scores at each iteration on the held-out validation data. The first entry is the score of the ensemble before the first iteration. Scores are computed according to the `scoring` parameter. Empty if no early stopping or if `validation\_fraction` is `undefined`.
   */
  get validation_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before accessing validation_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingRegressor_validation_score_ = bridgeHistGradientBoostingRegressor[${this.id}].validation_score_`;
      return this._py`attr_HistGradientBoostingRegressor_validation_score_.tolist() if hasattr(attr_HistGradientBoostingRegressor_validation_score_, 'tolist') else attr_HistGradientBoostingRegressor_validation_score_`;
    })();
  }
  /**
    Boolean mask for the categorical features. `undefined` if there are no categorical features.
   */
  get is_categorical_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before accessing is_categorical_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingRegressor_is_categorical_ = bridgeHistGradientBoostingRegressor[${this.id}].is_categorical_`;
      return this._py`attr_HistGradientBoostingRegressor_is_categorical_.tolist() if hasattr(attr_HistGradientBoostingRegressor_is_categorical_, 'tolist') else attr_HistGradientBoostingRegressor_is_categorical_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingRegressor_n_features_in_ = bridgeHistGradientBoostingRegressor[${this.id}].n_features_in_`;
      return this._py`attr_HistGradientBoostingRegressor_n_features_in_.tolist() if hasattr(attr_HistGradientBoostingRegressor_n_features_in_, 'tolist') else attr_HistGradientBoostingRegressor_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This HistGradientBoostingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HistGradientBoostingRegressor must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_HistGradientBoostingRegressor_feature_names_in_ = bridgeHistGradientBoostingRegressor[${this.id}].feature_names_in_`;
      return this._py`attr_HistGradientBoostingRegressor_feature_names_in_.tolist() if hasattr(attr_HistGradientBoostingRegressor_feature_names_in_, 'tolist') else attr_HistGradientBoostingRegressor_feature_names_in_`;
    })();
  }
};

// src/generated/ensemble/IsolationForest.ts
import crypto11 from "node:crypto";
var IsolationForest = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `IsolationForest${crypto11.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("IsolationForest.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import IsolationForest
try: bridgeIsolationForest
except NameError: bridgeIsolationForest = {}
`;
    await this._py.ex`ctor_IsolationForest = {'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'max_samples': ${this.opts["max_samples"] ?? void 0}, 'contamination': ${this.opts["contamination"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'bootstrap': ${this.opts["bootstrap"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}}

ctor_IsolationForest = {k: v for k, v in ctor_IsolationForest.items() if v is not None}`;
    await this._py.ex`bridgeIsolationForest[${this.id}] = IsolationForest(**ctor_IsolationForest)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeIsolationForest[${this.id}]`;
    this._isDisposed = true;
  }
  /**
      Average anomaly score of X of the base classifiers.
  
      The anomaly score of an input sample is computed as the mean anomaly score of the trees in the forest.
  
      The measure of normality of an observation given a tree is the depth of the leaf containing this observation, which is equivalent to the number of splittings required to isolate this point. In case of several observations n\_left in the leaf, the average path length of a n\_left samples isolation tree is added.
     */
  async decision_function(opts) {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "IsolationForest must call init() before decision_function()"
      );
    }
    await this._py.ex`pms_IsolationForest_decision_function = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_IsolationForest_decision_function = {k: v for k, v in pms_IsolationForest_decision_function.items() if v is not None}`;
    await this._py.ex`res_IsolationForest_decision_function = bridgeIsolationForest[${this.id}].decision_function(**pms_IsolationForest_decision_function)`;
    return this._py`res_IsolationForest_decision_function.tolist() if hasattr(res_IsolationForest_decision_function, 'tolist') else res_IsolationForest_decision_function`;
  }
  /**
    Fit estimator.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("IsolationForest must call init() before fit()");
    }
    await this._py.ex`pms_IsolationForest_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': ${opts["y"] ?? void 0}, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_IsolationForest_fit = {k: v for k, v in pms_IsolationForest_fit.items() if v is not None}`;
    await this._py.ex`res_IsolationForest_fit = bridgeIsolationForest[${this.id}].fit(**pms_IsolationForest_fit)`;
    return this._py`res_IsolationForest_fit.tolist() if hasattr(res_IsolationForest_fit, 'tolist') else res_IsolationForest_fit`;
  }
  /**
      Perform fit on X and returns labels for X.
  
      Returns -1 for outliers and 1 for inliers.
     */
  async fit_predict(opts) {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("IsolationForest must call init() before fit_predict()");
    }
    await this._py.ex`pms_IsolationForest_fit_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': ${opts["y"] ?? void 0}}

pms_IsolationForest_fit_predict = {k: v for k, v in pms_IsolationForest_fit_predict.items() if v is not None}`;
    await this._py.ex`res_IsolationForest_fit_predict = bridgeIsolationForest[${this.id}].fit_predict(**pms_IsolationForest_fit_predict)`;
    return this._py`res_IsolationForest_fit_predict.tolist() if hasattr(res_IsolationForest_fit_predict, 'tolist') else res_IsolationForest_fit_predict`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "IsolationForest must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_IsolationForest_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_IsolationForest_get_metadata_routing = {k: v for k, v in pms_IsolationForest_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_IsolationForest_get_metadata_routing = bridgeIsolationForest[${this.id}].get_metadata_routing(**pms_IsolationForest_get_metadata_routing)`;
    return this._py`res_IsolationForest_get_metadata_routing.tolist() if hasattr(res_IsolationForest_get_metadata_routing, 'tolist') else res_IsolationForest_get_metadata_routing`;
  }
  /**
    Predict if a particular sample is an outlier or not.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("IsolationForest must call init() before predict()");
    }
    await this._py.ex`pms_IsolationForest_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_IsolationForest_predict = {k: v for k, v in pms_IsolationForest_predict.items() if v is not None}`;
    await this._py.ex`res_IsolationForest_predict = bridgeIsolationForest[${this.id}].predict(**pms_IsolationForest_predict)`;
    return this._py`res_IsolationForest_predict.tolist() if hasattr(res_IsolationForest_predict, 'tolist') else res_IsolationForest_predict`;
  }
  /**
      Opposite of the anomaly score defined in the original paper.
  
      The anomaly score of an input sample is computed as the mean anomaly score of the trees in the forest.
  
      The measure of normality of an observation given a tree is the depth of the leaf containing this observation, which is equivalent to the number of splittings required to isolate this point. In case of several observations n\_left in the leaf, the average path length of a n\_left samples isolation tree is added.
     */
  async score_samples(opts) {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("IsolationForest must call init() before score_samples()");
    }
    await this._py.ex`pms_IsolationForest_score_samples = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_IsolationForest_score_samples = {k: v for k, v in pms_IsolationForest_score_samples.items() if v is not None}`;
    await this._py.ex`res_IsolationForest_score_samples = bridgeIsolationForest[${this.id}].score_samples(**pms_IsolationForest_score_samples)`;
    return this._py`res_IsolationForest_score_samples.tolist() if hasattr(res_IsolationForest_score_samples, 'tolist') else res_IsolationForest_score_samples`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "IsolationForest must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_IsolationForest_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_IsolationForest_set_fit_request = {k: v for k, v in pms_IsolationForest_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_IsolationForest_set_fit_request = bridgeIsolationForest[${this.id}].set_fit_request(**pms_IsolationForest_set_fit_request)`;
    return this._py`res_IsolationForest_set_fit_request.tolist() if hasattr(res_IsolationForest_set_fit_request, 'tolist') else res_IsolationForest_set_fit_request`;
  }
  /**
    The child estimator template used to create the collection of fitted sub-estimators.
   */
  get estimator_() {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "IsolationForest must call init() before accessing estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_IsolationForest_estimator_ = bridgeIsolationForest[${this.id}].estimator_`;
      return this._py`attr_IsolationForest_estimator_.tolist() if hasattr(attr_IsolationForest_estimator_, 'tolist') else attr_IsolationForest_estimator_`;
    })();
  }
  /**
    The collection of fitted sub-estimators.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "IsolationForest must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_IsolationForest_estimators_ = bridgeIsolationForest[${this.id}].estimators_`;
      return this._py`attr_IsolationForest_estimators_.tolist() if hasattr(attr_IsolationForest_estimators_, 'tolist') else attr_IsolationForest_estimators_`;
    })();
  }
  /**
    The subset of drawn features for each base estimator.
   */
  get estimators_features_() {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "IsolationForest must call init() before accessing estimators_features_"
      );
    }
    return (async () => {
      await this._py.ex`attr_IsolationForest_estimators_features_ = bridgeIsolationForest[${this.id}].estimators_features_`;
      return this._py`attr_IsolationForest_estimators_features_.tolist() if hasattr(attr_IsolationForest_estimators_features_, 'tolist') else attr_IsolationForest_estimators_features_`;
    })();
  }
  /**
    The actual number of samples.
   */
  get max_samples_() {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "IsolationForest must call init() before accessing max_samples_"
      );
    }
    return (async () => {
      await this._py.ex`attr_IsolationForest_max_samples_ = bridgeIsolationForest[${this.id}].max_samples_`;
      return this._py`attr_IsolationForest_max_samples_.tolist() if hasattr(attr_IsolationForest_max_samples_, 'tolist') else attr_IsolationForest_max_samples_`;
    })();
  }
  /**
    Offset used to define the decision function from the raw scores. We have the relation: `decision\_function \= score\_samples \- offset\_`. `offset\_` is defined as follows. When the contamination parameter is set to auto, the offset is equal to -0.5 as the scores of inliers are close to 0 and the scores of outliers are close to -1. When a contamination parameter different than auto is provided, the offset is defined in such a way we obtain the expected number of outliers (samples with decision function < 0) in training.
   */
  get offset_() {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "IsolationForest must call init() before accessing offset_"
      );
    }
    return (async () => {
      await this._py.ex`attr_IsolationForest_offset_ = bridgeIsolationForest[${this.id}].offset_`;
      return this._py`attr_IsolationForest_offset_.tolist() if hasattr(attr_IsolationForest_offset_, 'tolist') else attr_IsolationForest_offset_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "IsolationForest must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_IsolationForest_n_features_in_ = bridgeIsolationForest[${this.id}].n_features_in_`;
      return this._py`attr_IsolationForest_n_features_in_.tolist() if hasattr(attr_IsolationForest_n_features_in_, 'tolist') else attr_IsolationForest_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error("This IsolationForest instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "IsolationForest must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_IsolationForest_feature_names_in_ = bridgeIsolationForest[${this.id}].feature_names_in_`;
      return this._py`attr_IsolationForest_feature_names_in_.tolist() if hasattr(attr_IsolationForest_feature_names_in_, 'tolist') else attr_IsolationForest_feature_names_in_`;
    })();
  }
};

// src/generated/ensemble/RandomForestClassifier.ts
import crypto12 from "node:crypto";
var RandomForestClassifier = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `RandomForestClassifier${crypto12.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "RandomForestClassifier.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import RandomForestClassifier
try: bridgeRandomForestClassifier
except NameError: bridgeRandomForestClassifier = {}
`;
    await this._py.ex`ctor_RandomForestClassifier = {'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'criterion': ${this.opts["criterion"] ?? void 0}, 'max_depth': ${this.opts["max_depth"] ?? void 0}, 'min_samples_split': ${this.opts["min_samples_split"] ?? void 0}, 'min_samples_leaf': ${this.opts["min_samples_leaf"] ?? void 0}, 'min_weight_fraction_leaf': ${this.opts["min_weight_fraction_leaf"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'max_leaf_nodes': ${this.opts["max_leaf_nodes"] ?? void 0}, 'min_impurity_decrease': ${this.opts["min_impurity_decrease"] ?? void 0}, 'bootstrap': ${this.opts["bootstrap"] ?? void 0}, 'oob_score': ${this.opts["oob_score"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'class_weight': ${this.opts["class_weight"] ?? void 0}, 'ccp_alpha': ${this.opts["ccp_alpha"] ?? void 0}, 'max_samples': ${this.opts["max_samples"] ?? void 0}}

ctor_RandomForestClassifier = {k: v for k, v in ctor_RandomForestClassifier.items() if v is not None}`;
    await this._py.ex`bridgeRandomForestClassifier[${this.id}] = RandomForestClassifier(**ctor_RandomForestClassifier)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeRandomForestClassifier[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Apply trees in the forest to X, return leaf indices.
   */
  async apply(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("RandomForestClassifier must call init() before apply()");
    }
    await this._py.ex`pms_RandomForestClassifier_apply = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_RandomForestClassifier_apply = {k: v for k, v in pms_RandomForestClassifier_apply.items() if v is not None}`;
    await this._py.ex`res_RandomForestClassifier_apply = bridgeRandomForestClassifier[${this.id}].apply(**pms_RandomForestClassifier_apply)`;
    return this._py`res_RandomForestClassifier_apply.tolist() if hasattr(res_RandomForestClassifier_apply, 'tolist') else res_RandomForestClassifier_apply`;
  }
  /**
    Return the decision path in the forest.
   */
  async decision_path(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before decision_path()"
      );
    }
    await this._py.ex`pms_RandomForestClassifier_decision_path = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_RandomForestClassifier_decision_path = {k: v for k, v in pms_RandomForestClassifier_decision_path.items() if v is not None}`;
    await this._py.ex`res_RandomForestClassifier_decision_path = bridgeRandomForestClassifier[${this.id}].decision_path(**pms_RandomForestClassifier_decision_path)`;
    return this._py`res_RandomForestClassifier_decision_path.tolist() if hasattr(res_RandomForestClassifier_decision_path, 'tolist') else res_RandomForestClassifier_decision_path`;
  }
  /**
    Build a forest of trees from the training set (X, y).
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("RandomForestClassifier must call init() before fit()");
    }
    await this._py.ex`pms_RandomForestClassifier_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_RandomForestClassifier_fit = {k: v for k, v in pms_RandomForestClassifier_fit.items() if v is not None}`;
    await this._py.ex`res_RandomForestClassifier_fit = bridgeRandomForestClassifier[${this.id}].fit(**pms_RandomForestClassifier_fit)`;
    return this._py`res_RandomForestClassifier_fit.tolist() if hasattr(res_RandomForestClassifier_fit, 'tolist') else res_RandomForestClassifier_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_RandomForestClassifier_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_RandomForestClassifier_get_metadata_routing = {k: v for k, v in pms_RandomForestClassifier_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_RandomForestClassifier_get_metadata_routing = bridgeRandomForestClassifier[${this.id}].get_metadata_routing(**pms_RandomForestClassifier_get_metadata_routing)`;
    return this._py`res_RandomForestClassifier_get_metadata_routing.tolist() if hasattr(res_RandomForestClassifier_get_metadata_routing, 'tolist') else res_RandomForestClassifier_get_metadata_routing`;
  }
  /**
      Predict class for X.
  
      The predicted class of an input sample is a vote by the trees in the forest, weighted by their probability estimates. That is, the predicted class is the one with highest mean probability estimate across the trees.
     */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before predict()"
      );
    }
    await this._py.ex`pms_RandomForestClassifier_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_RandomForestClassifier_predict = {k: v for k, v in pms_RandomForestClassifier_predict.items() if v is not None}`;
    await this._py.ex`res_RandomForestClassifier_predict = bridgeRandomForestClassifier[${this.id}].predict(**pms_RandomForestClassifier_predict)`;
    return this._py`res_RandomForestClassifier_predict.tolist() if hasattr(res_RandomForestClassifier_predict, 'tolist') else res_RandomForestClassifier_predict`;
  }
  /**
      Predict class log-probabilities for X.
  
      The predicted class log-probabilities of an input sample is computed as the log of the mean predicted class probabilities of the trees in the forest.
     */
  async predict_log_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before predict_log_proba()"
      );
    }
    await this._py.ex`pms_RandomForestClassifier_predict_log_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_RandomForestClassifier_predict_log_proba = {k: v for k, v in pms_RandomForestClassifier_predict_log_proba.items() if v is not None}`;
    await this._py.ex`res_RandomForestClassifier_predict_log_proba = bridgeRandomForestClassifier[${this.id}].predict_log_proba(**pms_RandomForestClassifier_predict_log_proba)`;
    return this._py`res_RandomForestClassifier_predict_log_proba.tolist() if hasattr(res_RandomForestClassifier_predict_log_proba, 'tolist') else res_RandomForestClassifier_predict_log_proba`;
  }
  /**
      Predict class probabilities for X.
  
      The predicted class probabilities of an input sample are computed as the mean predicted class probabilities of the trees in the forest. The class probability of a single tree is the fraction of samples of the same class in a leaf.
     */
  async predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before predict_proba()"
      );
    }
    await this._py.ex`pms_RandomForestClassifier_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_RandomForestClassifier_predict_proba = {k: v for k, v in pms_RandomForestClassifier_predict_proba.items() if v is not None}`;
    await this._py.ex`res_RandomForestClassifier_predict_proba = bridgeRandomForestClassifier[${this.id}].predict_proba(**pms_RandomForestClassifier_predict_proba)`;
    return this._py`res_RandomForestClassifier_predict_proba.tolist() if hasattr(res_RandomForestClassifier_predict_proba, 'tolist') else res_RandomForestClassifier_predict_proba`;
  }
  /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("RandomForestClassifier must call init() before score()");
    }
    await this._py.ex`pms_RandomForestClassifier_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_RandomForestClassifier_score = {k: v for k, v in pms_RandomForestClassifier_score.items() if v is not None}`;
    await this._py.ex`res_RandomForestClassifier_score = bridgeRandomForestClassifier[${this.id}].score(**pms_RandomForestClassifier_score)`;
    return this._py`res_RandomForestClassifier_score.tolist() if hasattr(res_RandomForestClassifier_score, 'tolist') else res_RandomForestClassifier_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_RandomForestClassifier_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_RandomForestClassifier_set_fit_request = {k: v for k, v in pms_RandomForestClassifier_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_RandomForestClassifier_set_fit_request = bridgeRandomForestClassifier[${this.id}].set_fit_request(**pms_RandomForestClassifier_set_fit_request)`;
    return this._py`res_RandomForestClassifier_set_fit_request.tolist() if hasattr(res_RandomForestClassifier_set_fit_request, 'tolist') else res_RandomForestClassifier_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_RandomForestClassifier_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_RandomForestClassifier_set_score_request = {k: v for k, v in pms_RandomForestClassifier_set_score_request.items() if v is not None}`;
    await this._py.ex`res_RandomForestClassifier_set_score_request = bridgeRandomForestClassifier[${this.id}].set_score_request(**pms_RandomForestClassifier_set_score_request)`;
    return this._py`res_RandomForestClassifier_set_score_request.tolist() if hasattr(res_RandomForestClassifier_set_score_request, 'tolist') else res_RandomForestClassifier_set_score_request`;
  }
  /**
    The child estimator template used to create the collection of fitted sub-estimators.
   */
  get estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before accessing estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestClassifier_estimator_ = bridgeRandomForestClassifier[${this.id}].estimator_`;
      return this._py`attr_RandomForestClassifier_estimator_.tolist() if hasattr(attr_RandomForestClassifier_estimator_, 'tolist') else attr_RandomForestClassifier_estimator_`;
    })();
  }
  /**
    The collection of fitted sub-estimators.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestClassifier_estimators_ = bridgeRandomForestClassifier[${this.id}].estimators_`;
      return this._py`attr_RandomForestClassifier_estimators_.tolist() if hasattr(attr_RandomForestClassifier_estimators_, 'tolist') else attr_RandomForestClassifier_estimators_`;
    })();
  }
  /**
    The classes labels (single output problem), or a list of arrays of class labels (multi-output problem).
   */
  get classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before accessing classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestClassifier_classes_ = bridgeRandomForestClassifier[${this.id}].classes_`;
      return this._py`attr_RandomForestClassifier_classes_.tolist() if hasattr(attr_RandomForestClassifier_classes_, 'tolist') else attr_RandomForestClassifier_classes_`;
    })();
  }
  /**
    The number of classes (single output problem), or a list containing the number of classes for each output (multi-output problem).
   */
  get n_classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before accessing n_classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestClassifier_n_classes_ = bridgeRandomForestClassifier[${this.id}].n_classes_`;
      return this._py`attr_RandomForestClassifier_n_classes_.tolist() if hasattr(attr_RandomForestClassifier_n_classes_, 'tolist') else attr_RandomForestClassifier_n_classes_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestClassifier_n_features_in_ = bridgeRandomForestClassifier[${this.id}].n_features_in_`;
      return this._py`attr_RandomForestClassifier_n_features_in_.tolist() if hasattr(attr_RandomForestClassifier_n_features_in_, 'tolist') else attr_RandomForestClassifier_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestClassifier_feature_names_in_ = bridgeRandomForestClassifier[${this.id}].feature_names_in_`;
      return this._py`attr_RandomForestClassifier_feature_names_in_.tolist() if hasattr(attr_RandomForestClassifier_feature_names_in_, 'tolist') else attr_RandomForestClassifier_feature_names_in_`;
    })();
  }
  /**
    The number of outputs when `fit` is performed.
   */
  get n_outputs_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before accessing n_outputs_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestClassifier_n_outputs_ = bridgeRandomForestClassifier[${this.id}].n_outputs_`;
      return this._py`attr_RandomForestClassifier_n_outputs_.tolist() if hasattr(attr_RandomForestClassifier_n_outputs_, 'tolist') else attr_RandomForestClassifier_n_outputs_`;
    })();
  }
  /**
    Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before accessing oob_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestClassifier_oob_score_ = bridgeRandomForestClassifier[${this.id}].oob_score_`;
      return this._py`attr_RandomForestClassifier_oob_score_.tolist() if hasattr(attr_RandomForestClassifier_oob_score_, 'tolist') else attr_RandomForestClassifier_oob_score_`;
    })();
  }
  /**
    Decision function computed with out-of-bag estimate on the training set. If n\_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, `oob\_decision\_function\_` might contain NaN. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_decision_function_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestClassifier must call init() before accessing oob_decision_function_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestClassifier_oob_decision_function_ = bridgeRandomForestClassifier[${this.id}].oob_decision_function_`;
      return this._py`attr_RandomForestClassifier_oob_decision_function_.tolist() if hasattr(attr_RandomForestClassifier_oob_decision_function_, 'tolist') else attr_RandomForestClassifier_oob_decision_function_`;
    })();
  }
};

// src/generated/ensemble/RandomForestRegressor.ts
import crypto13 from "node:crypto";
var RandomForestRegressor = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `RandomForestRegressor${crypto13.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "RandomForestRegressor.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import RandomForestRegressor
try: bridgeRandomForestRegressor
except NameError: bridgeRandomForestRegressor = {}
`;
    await this._py.ex`ctor_RandomForestRegressor = {'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'criterion': ${this.opts["criterion"] ?? void 0}, 'max_depth': ${this.opts["max_depth"] ?? void 0}, 'min_samples_split': ${this.opts["min_samples_split"] ?? void 0}, 'min_samples_leaf': ${this.opts["min_samples_leaf"] ?? void 0}, 'min_weight_fraction_leaf': ${this.opts["min_weight_fraction_leaf"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'max_leaf_nodes': ${this.opts["max_leaf_nodes"] ?? void 0}, 'min_impurity_decrease': ${this.opts["min_impurity_decrease"] ?? void 0}, 'bootstrap': ${this.opts["bootstrap"] ?? void 0}, 'oob_score': ${this.opts["oob_score"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'ccp_alpha': ${this.opts["ccp_alpha"] ?? void 0}, 'max_samples': ${this.opts["max_samples"] ?? void 0}}

ctor_RandomForestRegressor = {k: v for k, v in ctor_RandomForestRegressor.items() if v is not None}`;
    await this._py.ex`bridgeRandomForestRegressor[${this.id}] = RandomForestRegressor(**ctor_RandomForestRegressor)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeRandomForestRegressor[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Apply trees in the forest to X, return leaf indices.
   */
  async apply(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("RandomForestRegressor must call init() before apply()");
    }
    await this._py.ex`pms_RandomForestRegressor_apply = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_RandomForestRegressor_apply = {k: v for k, v in pms_RandomForestRegressor_apply.items() if v is not None}`;
    await this._py.ex`res_RandomForestRegressor_apply = bridgeRandomForestRegressor[${this.id}].apply(**pms_RandomForestRegressor_apply)`;
    return this._py`res_RandomForestRegressor_apply.tolist() if hasattr(res_RandomForestRegressor_apply, 'tolist') else res_RandomForestRegressor_apply`;
  }
  /**
    Return the decision path in the forest.
   */
  async decision_path(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestRegressor must call init() before decision_path()"
      );
    }
    await this._py.ex`pms_RandomForestRegressor_decision_path = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_RandomForestRegressor_decision_path = {k: v for k, v in pms_RandomForestRegressor_decision_path.items() if v is not None}`;
    await this._py.ex`res_RandomForestRegressor_decision_path = bridgeRandomForestRegressor[${this.id}].decision_path(**pms_RandomForestRegressor_decision_path)`;
    return this._py`res_RandomForestRegressor_decision_path.tolist() if hasattr(res_RandomForestRegressor_decision_path, 'tolist') else res_RandomForestRegressor_decision_path`;
  }
  /**
    Build a forest of trees from the training set (X, y).
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("RandomForestRegressor must call init() before fit()");
    }
    await this._py.ex`pms_RandomForestRegressor_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_RandomForestRegressor_fit = {k: v for k, v in pms_RandomForestRegressor_fit.items() if v is not None}`;
    await this._py.ex`res_RandomForestRegressor_fit = bridgeRandomForestRegressor[${this.id}].fit(**pms_RandomForestRegressor_fit)`;
    return this._py`res_RandomForestRegressor_fit.tolist() if hasattr(res_RandomForestRegressor_fit, 'tolist') else res_RandomForestRegressor_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestRegressor must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_RandomForestRegressor_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_RandomForestRegressor_get_metadata_routing = {k: v for k, v in pms_RandomForestRegressor_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_RandomForestRegressor_get_metadata_routing = bridgeRandomForestRegressor[${this.id}].get_metadata_routing(**pms_RandomForestRegressor_get_metadata_routing)`;
    return this._py`res_RandomForestRegressor_get_metadata_routing.tolist() if hasattr(res_RandomForestRegressor_get_metadata_routing, 'tolist') else res_RandomForestRegressor_get_metadata_routing`;
  }
  /**
      Predict regression target for X.
  
      The predicted regression target of an input sample is computed as the mean predicted regression targets of the trees in the forest.
     */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("RandomForestRegressor must call init() before predict()");
    }
    await this._py.ex`pms_RandomForestRegressor_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_RandomForestRegressor_predict = {k: v for k, v in pms_RandomForestRegressor_predict.items() if v is not None}`;
    await this._py.ex`res_RandomForestRegressor_predict = bridgeRandomForestRegressor[${this.id}].predict(**pms_RandomForestRegressor_predict)`;
    return this._py`res_RandomForestRegressor_predict.tolist() if hasattr(res_RandomForestRegressor_predict, 'tolist') else res_RandomForestRegressor_predict`;
  }
  /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("RandomForestRegressor must call init() before score()");
    }
    await this._py.ex`pms_RandomForestRegressor_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_RandomForestRegressor_score = {k: v for k, v in pms_RandomForestRegressor_score.items() if v is not None}`;
    await this._py.ex`res_RandomForestRegressor_score = bridgeRandomForestRegressor[${this.id}].score(**pms_RandomForestRegressor_score)`;
    return this._py`res_RandomForestRegressor_score.tolist() if hasattr(res_RandomForestRegressor_score, 'tolist') else res_RandomForestRegressor_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestRegressor must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_RandomForestRegressor_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_RandomForestRegressor_set_fit_request = {k: v for k, v in pms_RandomForestRegressor_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_RandomForestRegressor_set_fit_request = bridgeRandomForestRegressor[${this.id}].set_fit_request(**pms_RandomForestRegressor_set_fit_request)`;
    return this._py`res_RandomForestRegressor_set_fit_request.tolist() if hasattr(res_RandomForestRegressor_set_fit_request, 'tolist') else res_RandomForestRegressor_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestRegressor must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_RandomForestRegressor_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_RandomForestRegressor_set_score_request = {k: v for k, v in pms_RandomForestRegressor_set_score_request.items() if v is not None}`;
    await this._py.ex`res_RandomForestRegressor_set_score_request = bridgeRandomForestRegressor[${this.id}].set_score_request(**pms_RandomForestRegressor_set_score_request)`;
    return this._py`res_RandomForestRegressor_set_score_request.tolist() if hasattr(res_RandomForestRegressor_set_score_request, 'tolist') else res_RandomForestRegressor_set_score_request`;
  }
  /**
    The child estimator template used to create the collection of fitted sub-estimators.
   */
  get estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestRegressor must call init() before accessing estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestRegressor_estimator_ = bridgeRandomForestRegressor[${this.id}].estimator_`;
      return this._py`attr_RandomForestRegressor_estimator_.tolist() if hasattr(attr_RandomForestRegressor_estimator_, 'tolist') else attr_RandomForestRegressor_estimator_`;
    })();
  }
  /**
    The collection of fitted sub-estimators.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestRegressor must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestRegressor_estimators_ = bridgeRandomForestRegressor[${this.id}].estimators_`;
      return this._py`attr_RandomForestRegressor_estimators_.tolist() if hasattr(attr_RandomForestRegressor_estimators_, 'tolist') else attr_RandomForestRegressor_estimators_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestRegressor must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestRegressor_n_features_in_ = bridgeRandomForestRegressor[${this.id}].n_features_in_`;
      return this._py`attr_RandomForestRegressor_n_features_in_.tolist() if hasattr(attr_RandomForestRegressor_n_features_in_, 'tolist') else attr_RandomForestRegressor_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestRegressor must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestRegressor_feature_names_in_ = bridgeRandomForestRegressor[${this.id}].feature_names_in_`;
      return this._py`attr_RandomForestRegressor_feature_names_in_.tolist() if hasattr(attr_RandomForestRegressor_feature_names_in_, 'tolist') else attr_RandomForestRegressor_feature_names_in_`;
    })();
  }
  /**
    The number of outputs when `fit` is performed.
   */
  get n_outputs_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestRegressor must call init() before accessing n_outputs_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestRegressor_n_outputs_ = bridgeRandomForestRegressor[${this.id}].n_outputs_`;
      return this._py`attr_RandomForestRegressor_n_outputs_.tolist() if hasattr(attr_RandomForestRegressor_n_outputs_, 'tolist') else attr_RandomForestRegressor_n_outputs_`;
    })();
  }
  /**
    Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestRegressor must call init() before accessing oob_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestRegressor_oob_score_ = bridgeRandomForestRegressor[${this.id}].oob_score_`;
      return this._py`attr_RandomForestRegressor_oob_score_.tolist() if hasattr(attr_RandomForestRegressor_oob_score_, 'tolist') else attr_RandomForestRegressor_oob_score_`;
    })();
  }
  /**
    Prediction computed with out-of-bag estimate on the training set. This attribute exists only when `oob\_score` is `true`.
   */
  get oob_prediction_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomForestRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomForestRegressor must call init() before accessing oob_prediction_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomForestRegressor_oob_prediction_ = bridgeRandomForestRegressor[${this.id}].oob_prediction_`;
      return this._py`attr_RandomForestRegressor_oob_prediction_.tolist() if hasattr(attr_RandomForestRegressor_oob_prediction_, 'tolist') else attr_RandomForestRegressor_oob_prediction_`;
    })();
  }
};

// src/generated/ensemble/RandomTreesEmbedding.ts
import crypto14 from "node:crypto";
var RandomTreesEmbedding = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `RandomTreesEmbedding${crypto14.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "RandomTreesEmbedding.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import RandomTreesEmbedding
try: bridgeRandomTreesEmbedding
except NameError: bridgeRandomTreesEmbedding = {}
`;
    await this._py.ex`ctor_RandomTreesEmbedding = {'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'max_depth': ${this.opts["max_depth"] ?? void 0}, 'min_samples_split': ${this.opts["min_samples_split"] ?? void 0}, 'min_samples_leaf': ${this.opts["min_samples_leaf"] ?? void 0}, 'min_weight_fraction_leaf': ${this.opts["min_weight_fraction_leaf"] ?? void 0}, 'max_leaf_nodes': ${this.opts["max_leaf_nodes"] ?? void 0}, 'min_impurity_decrease': ${this.opts["min_impurity_decrease"] ?? void 0}, 'sparse_output': ${this.opts["sparse_output"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}}

ctor_RandomTreesEmbedding = {k: v for k, v in ctor_RandomTreesEmbedding.items() if v is not None}`;
    await this._py.ex`bridgeRandomTreesEmbedding[${this.id}] = RandomTreesEmbedding(**ctor_RandomTreesEmbedding)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeRandomTreesEmbedding[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Apply trees in the forest to X, return leaf indices.
   */
  async apply(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("RandomTreesEmbedding must call init() before apply()");
    }
    await this._py.ex`pms_RandomTreesEmbedding_apply = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_RandomTreesEmbedding_apply = {k: v for k, v in pms_RandomTreesEmbedding_apply.items() if v is not None}`;
    await this._py.ex`res_RandomTreesEmbedding_apply = bridgeRandomTreesEmbedding[${this.id}].apply(**pms_RandomTreesEmbedding_apply)`;
    return this._py`res_RandomTreesEmbedding_apply.tolist() if hasattr(res_RandomTreesEmbedding_apply, 'tolist') else res_RandomTreesEmbedding_apply`;
  }
  /**
    Return the decision path in the forest.
   */
  async decision_path(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before decision_path()"
      );
    }
    await this._py.ex`pms_RandomTreesEmbedding_decision_path = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_RandomTreesEmbedding_decision_path = {k: v for k, v in pms_RandomTreesEmbedding_decision_path.items() if v is not None}`;
    await this._py.ex`res_RandomTreesEmbedding_decision_path = bridgeRandomTreesEmbedding[${this.id}].decision_path(**pms_RandomTreesEmbedding_decision_path)`;
    return this._py`res_RandomTreesEmbedding_decision_path.tolist() if hasattr(res_RandomTreesEmbedding_decision_path, 'tolist') else res_RandomTreesEmbedding_decision_path`;
  }
  /**
    Fit estimator.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("RandomTreesEmbedding must call init() before fit()");
    }
    await this._py.ex`pms_RandomTreesEmbedding_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': ${opts["y"] ?? void 0}, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_RandomTreesEmbedding_fit = {k: v for k, v in pms_RandomTreesEmbedding_fit.items() if v is not None}`;
    await this._py.ex`res_RandomTreesEmbedding_fit = bridgeRandomTreesEmbedding[${this.id}].fit(**pms_RandomTreesEmbedding_fit)`;
    return this._py`res_RandomTreesEmbedding_fit.tolist() if hasattr(res_RandomTreesEmbedding_fit, 'tolist') else res_RandomTreesEmbedding_fit`;
  }
  /**
    Fit estimator and transform dataset.
   */
  async fit_transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before fit_transform()"
      );
    }
    await this._py.ex`pms_RandomTreesEmbedding_fit_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': ${opts["y"] ?? void 0}, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_RandomTreesEmbedding_fit_transform = {k: v for k, v in pms_RandomTreesEmbedding_fit_transform.items() if v is not None}`;
    await this._py.ex`res_RandomTreesEmbedding_fit_transform = bridgeRandomTreesEmbedding[${this.id}].fit_transform(**pms_RandomTreesEmbedding_fit_transform)`;
    return this._py`res_RandomTreesEmbedding_fit_transform.tolist() if hasattr(res_RandomTreesEmbedding_fit_transform, 'tolist') else res_RandomTreesEmbedding_fit_transform`;
  }
  /**
    Get output feature names for transformation.
   */
  async get_feature_names_out(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before get_feature_names_out()"
      );
    }
    await this._py.ex`pms_RandomTreesEmbedding_get_feature_names_out = {'input_features': ${opts["input_features"] ?? void 0}}

pms_RandomTreesEmbedding_get_feature_names_out = {k: v for k, v in pms_RandomTreesEmbedding_get_feature_names_out.items() if v is not None}`;
    await this._py.ex`res_RandomTreesEmbedding_get_feature_names_out = bridgeRandomTreesEmbedding[${this.id}].get_feature_names_out(**pms_RandomTreesEmbedding_get_feature_names_out)`;
    return this._py`res_RandomTreesEmbedding_get_feature_names_out.tolist() if hasattr(res_RandomTreesEmbedding_get_feature_names_out, 'tolist') else res_RandomTreesEmbedding_get_feature_names_out`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_RandomTreesEmbedding_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_RandomTreesEmbedding_get_metadata_routing = {k: v for k, v in pms_RandomTreesEmbedding_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_RandomTreesEmbedding_get_metadata_routing = bridgeRandomTreesEmbedding[${this.id}].get_metadata_routing(**pms_RandomTreesEmbedding_get_metadata_routing)`;
    return this._py`res_RandomTreesEmbedding_get_metadata_routing.tolist() if hasattr(res_RandomTreesEmbedding_get_metadata_routing, 'tolist') else res_RandomTreesEmbedding_get_metadata_routing`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_RandomTreesEmbedding_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_RandomTreesEmbedding_set_fit_request = {k: v for k, v in pms_RandomTreesEmbedding_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_RandomTreesEmbedding_set_fit_request = bridgeRandomTreesEmbedding[${this.id}].set_fit_request(**pms_RandomTreesEmbedding_set_fit_request)`;
    return this._py`res_RandomTreesEmbedding_set_fit_request.tolist() if hasattr(res_RandomTreesEmbedding_set_fit_request, 'tolist') else res_RandomTreesEmbedding_set_fit_request`;
  }
  /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
  async set_output(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before set_output()"
      );
    }
    await this._py.ex`pms_RandomTreesEmbedding_set_output = {'transform': ${opts["transform"] ?? void 0}}

pms_RandomTreesEmbedding_set_output = {k: v for k, v in pms_RandomTreesEmbedding_set_output.items() if v is not None}`;
    await this._py.ex`res_RandomTreesEmbedding_set_output = bridgeRandomTreesEmbedding[${this.id}].set_output(**pms_RandomTreesEmbedding_set_output)`;
    return this._py`res_RandomTreesEmbedding_set_output.tolist() if hasattr(res_RandomTreesEmbedding_set_output, 'tolist') else res_RandomTreesEmbedding_set_output`;
  }
  /**
    Transform dataset.
   */
  async transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before transform()"
      );
    }
    await this._py.ex`pms_RandomTreesEmbedding_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_RandomTreesEmbedding_transform = {k: v for k, v in pms_RandomTreesEmbedding_transform.items() if v is not None}`;
    await this._py.ex`res_RandomTreesEmbedding_transform = bridgeRandomTreesEmbedding[${this.id}].transform(**pms_RandomTreesEmbedding_transform)`;
    return this._py`res_RandomTreesEmbedding_transform.tolist() if hasattr(res_RandomTreesEmbedding_transform, 'tolist') else res_RandomTreesEmbedding_transform`;
  }
  /**
    The child estimator template used to create the collection of fitted sub-estimators.
   */
  get estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before accessing estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomTreesEmbedding_estimator_ = bridgeRandomTreesEmbedding[${this.id}].estimator_`;
      return this._py`attr_RandomTreesEmbedding_estimator_.tolist() if hasattr(attr_RandomTreesEmbedding_estimator_, 'tolist') else attr_RandomTreesEmbedding_estimator_`;
    })();
  }
  /**
    The collection of fitted sub-estimators.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomTreesEmbedding_estimators_ = bridgeRandomTreesEmbedding[${this.id}].estimators_`;
      return this._py`attr_RandomTreesEmbedding_estimators_.tolist() if hasattr(attr_RandomTreesEmbedding_estimators_, 'tolist') else attr_RandomTreesEmbedding_estimators_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomTreesEmbedding_n_features_in_ = bridgeRandomTreesEmbedding[${this.id}].n_features_in_`;
      return this._py`attr_RandomTreesEmbedding_n_features_in_.tolist() if hasattr(attr_RandomTreesEmbedding_n_features_in_, 'tolist') else attr_RandomTreesEmbedding_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomTreesEmbedding_feature_names_in_ = bridgeRandomTreesEmbedding[${this.id}].feature_names_in_`;
      return this._py`attr_RandomTreesEmbedding_feature_names_in_.tolist() if hasattr(attr_RandomTreesEmbedding_feature_names_in_, 'tolist') else attr_RandomTreesEmbedding_feature_names_in_`;
    })();
  }
  /**
    The number of outputs when `fit` is performed.
   */
  get n_outputs_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before accessing n_outputs_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomTreesEmbedding_n_outputs_ = bridgeRandomTreesEmbedding[${this.id}].n_outputs_`;
      return this._py`attr_RandomTreesEmbedding_n_outputs_.tolist() if hasattr(attr_RandomTreesEmbedding_n_outputs_, 'tolist') else attr_RandomTreesEmbedding_n_outputs_`;
    })();
  }
  /**
    One-hot encoder used to create the sparse embedding.
   */
  get one_hot_encoder_() {
    if (this._isDisposed) {
      throw new Error(
        "This RandomTreesEmbedding instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "RandomTreesEmbedding must call init() before accessing one_hot_encoder_"
      );
    }
    return (async () => {
      await this._py.ex`attr_RandomTreesEmbedding_one_hot_encoder_ = bridgeRandomTreesEmbedding[${this.id}].one_hot_encoder_`;
      return this._py`attr_RandomTreesEmbedding_one_hot_encoder_.tolist() if hasattr(attr_RandomTreesEmbedding_one_hot_encoder_, 'tolist') else attr_RandomTreesEmbedding_one_hot_encoder_`;
    })();
  }
};

// src/generated/ensemble/StackingClassifier.ts
import crypto15 from "node:crypto";
var StackingClassifier = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `StackingClassifier${crypto15.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "StackingClassifier.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import StackingClassifier
try: bridgeStackingClassifier
except NameError: bridgeStackingClassifier = {}
`;
    await this._py.ex`ctor_StackingClassifier = {'estimators': ${this.opts["estimators"] ?? void 0}, 'final_estimator': ${this.opts["final_estimator"] ?? void 0}, 'cv': ${this.opts["cv"] ?? void 0}, 'stack_method': ${this.opts["stack_method"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'passthrough': ${this.opts["passthrough"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}}

ctor_StackingClassifier = {k: v for k, v in ctor_StackingClassifier.items() if v is not None}`;
    await this._py.ex`bridgeStackingClassifier[${this.id}] = StackingClassifier(**ctor_StackingClassifier)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeStackingClassifier[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Decision function for samples in `X` using the final estimator.
   */
  async decision_function(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before decision_function()"
      );
    }
    await this._py.ex`pms_StackingClassifier_decision_function = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_StackingClassifier_decision_function = {k: v for k, v in pms_StackingClassifier_decision_function.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_decision_function = bridgeStackingClassifier[${this.id}].decision_function(**pms_StackingClassifier_decision_function)`;
    return this._py`res_StackingClassifier_decision_function.tolist() if hasattr(res_StackingClassifier_decision_function, 'tolist') else res_StackingClassifier_decision_function`;
  }
  /**
    Fit the estimators.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingClassifier must call init() before fit()");
    }
    await this._py.ex`pms_StackingClassifier_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_StackingClassifier_fit = {k: v for k, v in pms_StackingClassifier_fit.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_fit = bridgeStackingClassifier[${this.id}].fit(**pms_StackingClassifier_fit)`;
    return this._py`res_StackingClassifier_fit.tolist() if hasattr(res_StackingClassifier_fit, 'tolist') else res_StackingClassifier_fit`;
  }
  /**
      Fit to data, then transform it.
  
      Fits transformer to `X` and `y` with optional parameters `fit\_params` and returns a transformed version of `X`.
     */
  async fit_transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before fit_transform()"
      );
    }
    await this._py.ex`pms_StackingClassifier_fit_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'fit_params': ${opts["fit_params"] ?? void 0}}

pms_StackingClassifier_fit_transform = {k: v for k, v in pms_StackingClassifier_fit_transform.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_fit_transform = bridgeStackingClassifier[${this.id}].fit_transform(**pms_StackingClassifier_fit_transform)`;
    return this._py`res_StackingClassifier_fit_transform.tolist() if hasattr(res_StackingClassifier_fit_transform, 'tolist') else res_StackingClassifier_fit_transform`;
  }
  /**
    Get output feature names for transformation.
   */
  async get_feature_names_out(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before get_feature_names_out()"
      );
    }
    await this._py.ex`pms_StackingClassifier_get_feature_names_out = {'input_features': ${opts["input_features"] ?? void 0}}

pms_StackingClassifier_get_feature_names_out = {k: v for k, v in pms_StackingClassifier_get_feature_names_out.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_get_feature_names_out = bridgeStackingClassifier[${this.id}].get_feature_names_out(**pms_StackingClassifier_get_feature_names_out)`;
    return this._py`res_StackingClassifier_get_feature_names_out.tolist() if hasattr(res_StackingClassifier_get_feature_names_out, 'tolist') else res_StackingClassifier_get_feature_names_out`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_StackingClassifier_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_StackingClassifier_get_metadata_routing = {k: v for k, v in pms_StackingClassifier_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_get_metadata_routing = bridgeStackingClassifier[${this.id}].get_metadata_routing(**pms_StackingClassifier_get_metadata_routing)`;
    return this._py`res_StackingClassifier_get_metadata_routing.tolist() if hasattr(res_StackingClassifier_get_metadata_routing, 'tolist') else res_StackingClassifier_get_metadata_routing`;
  }
  /**
    Predict target for X.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingClassifier must call init() before predict()");
    }
    await this._py.ex`pms_StackingClassifier_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'predict_params': ${opts["predict_params"] ?? void 0}}

pms_StackingClassifier_predict = {k: v for k, v in pms_StackingClassifier_predict.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_predict = bridgeStackingClassifier[${this.id}].predict(**pms_StackingClassifier_predict)`;
    return this._py`res_StackingClassifier_predict.tolist() if hasattr(res_StackingClassifier_predict, 'tolist') else res_StackingClassifier_predict`;
  }
  /**
    Predict class probabilities for `X` using the final estimator.
   */
  async predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before predict_proba()"
      );
    }
    await this._py.ex`pms_StackingClassifier_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_StackingClassifier_predict_proba = {k: v for k, v in pms_StackingClassifier_predict_proba.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_predict_proba = bridgeStackingClassifier[${this.id}].predict_proba(**pms_StackingClassifier_predict_proba)`;
    return this._py`res_StackingClassifier_predict_proba.tolist() if hasattr(res_StackingClassifier_predict_proba, 'tolist') else res_StackingClassifier_predict_proba`;
  }
  /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingClassifier must call init() before score()");
    }
    await this._py.ex`pms_StackingClassifier_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_StackingClassifier_score = {k: v for k, v in pms_StackingClassifier_score.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_score = bridgeStackingClassifier[${this.id}].score(**pms_StackingClassifier_score)`;
    return this._py`res_StackingClassifier_score.tolist() if hasattr(res_StackingClassifier_score, 'tolist') else res_StackingClassifier_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_StackingClassifier_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_StackingClassifier_set_fit_request = {k: v for k, v in pms_StackingClassifier_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_set_fit_request = bridgeStackingClassifier[${this.id}].set_fit_request(**pms_StackingClassifier_set_fit_request)`;
    return this._py`res_StackingClassifier_set_fit_request.tolist() if hasattr(res_StackingClassifier_set_fit_request, 'tolist') else res_StackingClassifier_set_fit_request`;
  }
  /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
  async set_output(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingClassifier must call init() before set_output()");
    }
    await this._py.ex`pms_StackingClassifier_set_output = {'transform': ${opts["transform"] ?? void 0}}

pms_StackingClassifier_set_output = {k: v for k, v in pms_StackingClassifier_set_output.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_set_output = bridgeStackingClassifier[${this.id}].set_output(**pms_StackingClassifier_set_output)`;
    return this._py`res_StackingClassifier_set_output.tolist() if hasattr(res_StackingClassifier_set_output, 'tolist') else res_StackingClassifier_set_output`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_StackingClassifier_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_StackingClassifier_set_score_request = {k: v for k, v in pms_StackingClassifier_set_score_request.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_set_score_request = bridgeStackingClassifier[${this.id}].set_score_request(**pms_StackingClassifier_set_score_request)`;
    return this._py`res_StackingClassifier_set_score_request.tolist() if hasattr(res_StackingClassifier_set_score_request, 'tolist') else res_StackingClassifier_set_score_request`;
  }
  /**
    Return class labels or probabilities for X for each estimator.
   */
  async transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingClassifier must call init() before transform()");
    }
    await this._py.ex`pms_StackingClassifier_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_StackingClassifier_transform = {k: v for k, v in pms_StackingClassifier_transform.items() if v is not None}`;
    await this._py.ex`res_StackingClassifier_transform = bridgeStackingClassifier[${this.id}].transform(**pms_StackingClassifier_transform)`;
    return this._py`res_StackingClassifier_transform.tolist() if hasattr(res_StackingClassifier_transform, 'tolist') else res_StackingClassifier_transform`;
  }
  /**
    Class labels.
   */
  get classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before accessing classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingClassifier_classes_ = bridgeStackingClassifier[${this.id}].classes_`;
      return this._py`attr_StackingClassifier_classes_.tolist() if hasattr(attr_StackingClassifier_classes_, 'tolist') else attr_StackingClassifier_classes_`;
    })();
  }
  /**
    The elements of the `estimators` parameter, having been fitted on the training data. If an estimator has been set to `'drop'`, it will not appear in `estimators\_`. When `cv="prefit"`, `estimators\_` is set to `estimators` and is not fitted again.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingClassifier_estimators_ = bridgeStackingClassifier[${this.id}].estimators_`;
      return this._py`attr_StackingClassifier_estimators_.tolist() if hasattr(attr_StackingClassifier_estimators_, 'tolist') else attr_StackingClassifier_estimators_`;
    })();
  }
  /**
    Attribute to access any fitted sub-estimators by name.
   */
  get named_estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before accessing named_estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingClassifier_named_estimators_ = bridgeStackingClassifier[${this.id}].named_estimators_`;
      return this._py`attr_StackingClassifier_named_estimators_.tolist() if hasattr(attr_StackingClassifier_named_estimators_, 'tolist') else attr_StackingClassifier_named_estimators_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying estimators expose such an attribute when fit.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingClassifier_feature_names_in_ = bridgeStackingClassifier[${this.id}].feature_names_in_`;
      return this._py`attr_StackingClassifier_feature_names_in_.tolist() if hasattr(attr_StackingClassifier_feature_names_in_, 'tolist') else attr_StackingClassifier_feature_names_in_`;
    })();
  }
  /**
    The classifier which predicts given the output of `estimators\_`.
   */
  get final_estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before accessing final_estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingClassifier_final_estimator_ = bridgeStackingClassifier[${this.id}].final_estimator_`;
      return this._py`attr_StackingClassifier_final_estimator_.tolist() if hasattr(attr_StackingClassifier_final_estimator_, 'tolist') else attr_StackingClassifier_final_estimator_`;
    })();
  }
  /**
    The method used by each base estimator.
   */
  get stack_method_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingClassifier must call init() before accessing stack_method_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingClassifier_stack_method_ = bridgeStackingClassifier[${this.id}].stack_method_`;
      return this._py`attr_StackingClassifier_stack_method_.tolist() if hasattr(attr_StackingClassifier_stack_method_, 'tolist') else attr_StackingClassifier_stack_method_`;
    })();
  }
};

// src/generated/ensemble/StackingRegressor.ts
import crypto16 from "node:crypto";
var StackingRegressor = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `StackingRegressor${crypto16.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("StackingRegressor.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import StackingRegressor
try: bridgeStackingRegressor
except NameError: bridgeStackingRegressor = {}
`;
    await this._py.ex`ctor_StackingRegressor = {'estimators': ${this.opts["estimators"] ?? void 0}, 'final_estimator': ${this.opts["final_estimator"] ?? void 0}, 'cv': ${this.opts["cv"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'passthrough': ${this.opts["passthrough"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}}

ctor_StackingRegressor = {k: v for k, v in ctor_StackingRegressor.items() if v is not None}`;
    await this._py.ex`bridgeStackingRegressor[${this.id}] = StackingRegressor(**ctor_StackingRegressor)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeStackingRegressor[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Fit the estimators.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingRegressor must call init() before fit()");
    }
    await this._py.ex`pms_StackingRegressor_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_StackingRegressor_fit = {k: v for k, v in pms_StackingRegressor_fit.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_fit = bridgeStackingRegressor[${this.id}].fit(**pms_StackingRegressor_fit)`;
    return this._py`res_StackingRegressor_fit.tolist() if hasattr(res_StackingRegressor_fit, 'tolist') else res_StackingRegressor_fit`;
  }
  /**
    Fit the estimators and return the predictions for X for each estimator.
   */
  async fit_transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before fit_transform()"
      );
    }
    await this._py.ex`pms_StackingRegressor_fit_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_StackingRegressor_fit_transform = {k: v for k, v in pms_StackingRegressor_fit_transform.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_fit_transform = bridgeStackingRegressor[${this.id}].fit_transform(**pms_StackingRegressor_fit_transform)`;
    return this._py`res_StackingRegressor_fit_transform.tolist() if hasattr(res_StackingRegressor_fit_transform, 'tolist') else res_StackingRegressor_fit_transform`;
  }
  /**
    Get output feature names for transformation.
   */
  async get_feature_names_out(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before get_feature_names_out()"
      );
    }
    await this._py.ex`pms_StackingRegressor_get_feature_names_out = {'input_features': ${opts["input_features"] ?? void 0}}

pms_StackingRegressor_get_feature_names_out = {k: v for k, v in pms_StackingRegressor_get_feature_names_out.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_get_feature_names_out = bridgeStackingRegressor[${this.id}].get_feature_names_out(**pms_StackingRegressor_get_feature_names_out)`;
    return this._py`res_StackingRegressor_get_feature_names_out.tolist() if hasattr(res_StackingRegressor_get_feature_names_out, 'tolist') else res_StackingRegressor_get_feature_names_out`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_StackingRegressor_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_StackingRegressor_get_metadata_routing = {k: v for k, v in pms_StackingRegressor_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_get_metadata_routing = bridgeStackingRegressor[${this.id}].get_metadata_routing(**pms_StackingRegressor_get_metadata_routing)`;
    return this._py`res_StackingRegressor_get_metadata_routing.tolist() if hasattr(res_StackingRegressor_get_metadata_routing, 'tolist') else res_StackingRegressor_get_metadata_routing`;
  }
  /**
    Predict target for X.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingRegressor must call init() before predict()");
    }
    await this._py.ex`pms_StackingRegressor_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'predict_params': ${opts["predict_params"] ?? void 0}}

pms_StackingRegressor_predict = {k: v for k, v in pms_StackingRegressor_predict.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_predict = bridgeStackingRegressor[${this.id}].predict(**pms_StackingRegressor_predict)`;
    return this._py`res_StackingRegressor_predict.tolist() if hasattr(res_StackingRegressor_predict, 'tolist') else res_StackingRegressor_predict`;
  }
  /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingRegressor must call init() before score()");
    }
    await this._py.ex`pms_StackingRegressor_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_StackingRegressor_score = {k: v for k, v in pms_StackingRegressor_score.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_score = bridgeStackingRegressor[${this.id}].score(**pms_StackingRegressor_score)`;
    return this._py`res_StackingRegressor_score.tolist() if hasattr(res_StackingRegressor_score, 'tolist') else res_StackingRegressor_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_StackingRegressor_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_StackingRegressor_set_fit_request = {k: v for k, v in pms_StackingRegressor_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_set_fit_request = bridgeStackingRegressor[${this.id}].set_fit_request(**pms_StackingRegressor_set_fit_request)`;
    return this._py`res_StackingRegressor_set_fit_request.tolist() if hasattr(res_StackingRegressor_set_fit_request, 'tolist') else res_StackingRegressor_set_fit_request`;
  }
  /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
  async set_output(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingRegressor must call init() before set_output()");
    }
    await this._py.ex`pms_StackingRegressor_set_output = {'transform': ${opts["transform"] ?? void 0}}

pms_StackingRegressor_set_output = {k: v for k, v in pms_StackingRegressor_set_output.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_set_output = bridgeStackingRegressor[${this.id}].set_output(**pms_StackingRegressor_set_output)`;
    return this._py`res_StackingRegressor_set_output.tolist() if hasattr(res_StackingRegressor_set_output, 'tolist') else res_StackingRegressor_set_output`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_StackingRegressor_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_StackingRegressor_set_score_request = {k: v for k, v in pms_StackingRegressor_set_score_request.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_set_score_request = bridgeStackingRegressor[${this.id}].set_score_request(**pms_StackingRegressor_set_score_request)`;
    return this._py`res_StackingRegressor_set_score_request.tolist() if hasattr(res_StackingRegressor_set_score_request, 'tolist') else res_StackingRegressor_set_score_request`;
  }
  /**
    Return the predictions for X for each estimator.
   */
  async transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("StackingRegressor must call init() before transform()");
    }
    await this._py.ex`pms_StackingRegressor_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_StackingRegressor_transform = {k: v for k, v in pms_StackingRegressor_transform.items() if v is not None}`;
    await this._py.ex`res_StackingRegressor_transform = bridgeStackingRegressor[${this.id}].transform(**pms_StackingRegressor_transform)`;
    return this._py`res_StackingRegressor_transform.tolist() if hasattr(res_StackingRegressor_transform, 'tolist') else res_StackingRegressor_transform`;
  }
  /**
    The elements of the `estimators` parameter, having been fitted on the training data. If an estimator has been set to `'drop'`, it will not appear in `estimators\_`. When `cv="prefit"`, `estimators\_` is set to `estimators` and is not fitted again.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingRegressor_estimators_ = bridgeStackingRegressor[${this.id}].estimators_`;
      return this._py`attr_StackingRegressor_estimators_.tolist() if hasattr(attr_StackingRegressor_estimators_, 'tolist') else attr_StackingRegressor_estimators_`;
    })();
  }
  /**
    Attribute to access any fitted sub-estimators by name.
   */
  get named_estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before accessing named_estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingRegressor_named_estimators_ = bridgeStackingRegressor[${this.id}].named_estimators_`;
      return this._py`attr_StackingRegressor_named_estimators_.tolist() if hasattr(attr_StackingRegressor_named_estimators_, 'tolist') else attr_StackingRegressor_named_estimators_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying estimators expose such an attribute when fit.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingRegressor_feature_names_in_ = bridgeStackingRegressor[${this.id}].feature_names_in_`;
      return this._py`attr_StackingRegressor_feature_names_in_.tolist() if hasattr(attr_StackingRegressor_feature_names_in_, 'tolist') else attr_StackingRegressor_feature_names_in_`;
    })();
  }
  /**
    The regressor to stacked the base estimators fitted.
   */
  get final_estimator_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before accessing final_estimator_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingRegressor_final_estimator_ = bridgeStackingRegressor[${this.id}].final_estimator_`;
      return this._py`attr_StackingRegressor_final_estimator_.tolist() if hasattr(attr_StackingRegressor_final_estimator_, 'tolist') else attr_StackingRegressor_final_estimator_`;
    })();
  }
  /**
    The method used by each base estimator.
   */
  get stack_method_() {
    if (this._isDisposed) {
      throw new Error(
        "This StackingRegressor instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "StackingRegressor must call init() before accessing stack_method_"
      );
    }
    return (async () => {
      await this._py.ex`attr_StackingRegressor_stack_method_ = bridgeStackingRegressor[${this.id}].stack_method_`;
      return this._py`attr_StackingRegressor_stack_method_.tolist() if hasattr(attr_StackingRegressor_stack_method_, 'tolist') else attr_StackingRegressor_stack_method_`;
    })();
  }
};

// src/generated/ensemble/VotingClassifier.ts
import crypto17 from "node:crypto";
var VotingClassifier = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `VotingClassifier${crypto17.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("VotingClassifier.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import VotingClassifier
try: bridgeVotingClassifier
except NameError: bridgeVotingClassifier = {}
`;
    await this._py.ex`ctor_VotingClassifier = {'estimators': ${this.opts["estimators"] ?? void 0}, 'voting': ${this.opts["voting"] ?? void 0}, 'weights': np.array(${this.opts["weights"] ?? void 0}) if ${this.opts["weights"] !== void 0} else None, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'flatten_transform': ${this.opts["flatten_transform"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}}

ctor_VotingClassifier = {k: v for k, v in ctor_VotingClassifier.items() if v is not None}`;
    await this._py.ex`bridgeVotingClassifier[${this.id}] = VotingClassifier(**ctor_VotingClassifier)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeVotingClassifier[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Fit the estimators.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("VotingClassifier must call init() before fit()");
    }
    await this._py.ex`pms_VotingClassifier_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_VotingClassifier_fit = {k: v for k, v in pms_VotingClassifier_fit.items() if v is not None}`;
    await this._py.ex`res_VotingClassifier_fit = bridgeVotingClassifier[${this.id}].fit(**pms_VotingClassifier_fit)`;
    return this._py`res_VotingClassifier_fit.tolist() if hasattr(res_VotingClassifier_fit, 'tolist') else res_VotingClassifier_fit`;
  }
  /**
      Return class labels or probabilities for each estimator.
  
      Return predictions for X for each estimator.
     */
  async fit_transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingClassifier must call init() before fit_transform()"
      );
    }
    await this._py.ex`pms_VotingClassifier_fit_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'fit_params': ${opts["fit_params"] ?? void 0}}

pms_VotingClassifier_fit_transform = {k: v for k, v in pms_VotingClassifier_fit_transform.items() if v is not None}`;
    await this._py.ex`res_VotingClassifier_fit_transform = bridgeVotingClassifier[${this.id}].fit_transform(**pms_VotingClassifier_fit_transform)`;
    return this._py`res_VotingClassifier_fit_transform.tolist() if hasattr(res_VotingClassifier_fit_transform, 'tolist') else res_VotingClassifier_fit_transform`;
  }
  /**
    Get output feature names for transformation.
   */
  async get_feature_names_out(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingClassifier must call init() before get_feature_names_out()"
      );
    }
    await this._py.ex`pms_VotingClassifier_get_feature_names_out = {'input_features': ${opts["input_features"] ?? void 0}}

pms_VotingClassifier_get_feature_names_out = {k: v for k, v in pms_VotingClassifier_get_feature_names_out.items() if v is not None}`;
    await this._py.ex`res_VotingClassifier_get_feature_names_out = bridgeVotingClassifier[${this.id}].get_feature_names_out(**pms_VotingClassifier_get_feature_names_out)`;
    return this._py`res_VotingClassifier_get_feature_names_out.tolist() if hasattr(res_VotingClassifier_get_feature_names_out, 'tolist') else res_VotingClassifier_get_feature_names_out`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingClassifier must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_VotingClassifier_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_VotingClassifier_get_metadata_routing = {k: v for k, v in pms_VotingClassifier_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_VotingClassifier_get_metadata_routing = bridgeVotingClassifier[${this.id}].get_metadata_routing(**pms_VotingClassifier_get_metadata_routing)`;
    return this._py`res_VotingClassifier_get_metadata_routing.tolist() if hasattr(res_VotingClassifier_get_metadata_routing, 'tolist') else res_VotingClassifier_get_metadata_routing`;
  }
  /**
    Predict class labels for X.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("VotingClassifier must call init() before predict()");
    }
    await this._py.ex`pms_VotingClassifier_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_VotingClassifier_predict = {k: v for k, v in pms_VotingClassifier_predict.items() if v is not None}`;
    await this._py.ex`res_VotingClassifier_predict = bridgeVotingClassifier[${this.id}].predict(**pms_VotingClassifier_predict)`;
    return this._py`res_VotingClassifier_predict.tolist() if hasattr(res_VotingClassifier_predict, 'tolist') else res_VotingClassifier_predict`;
  }
  /**
    Compute probabilities of possible outcomes for samples in X.
   */
  async predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingClassifier must call init() before predict_proba()"
      );
    }
    await this._py.ex`pms_VotingClassifier_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_VotingClassifier_predict_proba = {k: v for k, v in pms_VotingClassifier_predict_proba.items() if v is not None}`;
    await this._py.ex`res_VotingClassifier_predict_proba = bridgeVotingClassifier[${this.id}].predict_proba(**pms_VotingClassifier_predict_proba)`;
    return this._py`res_VotingClassifier_predict_proba.tolist() if hasattr(res_VotingClassifier_predict_proba, 'tolist') else res_VotingClassifier_predict_proba`;
  }
  /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("VotingClassifier must call init() before score()");
    }
    await this._py.ex`pms_VotingClassifier_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_VotingClassifier_score = {k: v for k, v in pms_VotingClassifier_score.items() if v is not None}`;
    await this._py.ex`res_VotingClassifier_score = bridgeVotingClassifier[${this.id}].score(**pms_VotingClassifier_score)`;
    return this._py`res_VotingClassifier_score.tolist() if hasattr(res_VotingClassifier_score, 'tolist') else res_VotingClassifier_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingClassifier must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_VotingClassifier_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_VotingClassifier_set_fit_request = {k: v for k, v in pms_VotingClassifier_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_VotingClassifier_set_fit_request = bridgeVotingClassifier[${this.id}].set_fit_request(**pms_VotingClassifier_set_fit_request)`;
    return this._py`res_VotingClassifier_set_fit_request.tolist() if hasattr(res_VotingClassifier_set_fit_request, 'tolist') else res_VotingClassifier_set_fit_request`;
  }
  /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
  async set_output(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("VotingClassifier must call init() before set_output()");
    }
    await this._py.ex`pms_VotingClassifier_set_output = {'transform': ${opts["transform"] ?? void 0}}

pms_VotingClassifier_set_output = {k: v for k, v in pms_VotingClassifier_set_output.items() if v is not None}`;
    await this._py.ex`res_VotingClassifier_set_output = bridgeVotingClassifier[${this.id}].set_output(**pms_VotingClassifier_set_output)`;
    return this._py`res_VotingClassifier_set_output.tolist() if hasattr(res_VotingClassifier_set_output, 'tolist') else res_VotingClassifier_set_output`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingClassifier must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_VotingClassifier_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_VotingClassifier_set_score_request = {k: v for k, v in pms_VotingClassifier_set_score_request.items() if v is not None}`;
    await this._py.ex`res_VotingClassifier_set_score_request = bridgeVotingClassifier[${this.id}].set_score_request(**pms_VotingClassifier_set_score_request)`;
    return this._py`res_VotingClassifier_set_score_request.tolist() if hasattr(res_VotingClassifier_set_score_request, 'tolist') else res_VotingClassifier_set_score_request`;
  }
  /**
    Return class labels or probabilities for X for each estimator.
   */
  async transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("VotingClassifier must call init() before transform()");
    }
    await this._py.ex`pms_VotingClassifier_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_VotingClassifier_transform = {k: v for k, v in pms_VotingClassifier_transform.items() if v is not None}`;
    await this._py.ex`res_VotingClassifier_transform = bridgeVotingClassifier[${this.id}].transform(**pms_VotingClassifier_transform)`;
    return this._py`res_VotingClassifier_transform.tolist() if hasattr(res_VotingClassifier_transform, 'tolist') else res_VotingClassifier_transform`;
  }
  /**
    The collection of fitted sub-estimators as defined in `estimators` that are not drop.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingClassifier must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_VotingClassifier_estimators_ = bridgeVotingClassifier[${this.id}].estimators_`;
      return this._py`attr_VotingClassifier_estimators_.tolist() if hasattr(attr_VotingClassifier_estimators_, 'tolist') else attr_VotingClassifier_estimators_`;
    })();
  }
  /**
    Attribute to access any fitted sub-estimators by name.
   */
  get named_estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingClassifier must call init() before accessing named_estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_VotingClassifier_named_estimators_ = bridgeVotingClassifier[${this.id}].named_estimators_`;
      return this._py`attr_VotingClassifier_named_estimators_.tolist() if hasattr(attr_VotingClassifier_named_estimators_, 'tolist') else attr_VotingClassifier_named_estimators_`;
    })();
  }
  /**
    Transformer used to encode the labels during fit and decode during prediction.
   */
  get le_() {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("VotingClassifier must call init() before accessing le_");
    }
    return (async () => {
      await this._py.ex`attr_VotingClassifier_le_ = bridgeVotingClassifier[${this.id}].le_`;
      return this._py`attr_VotingClassifier_le_.tolist() if hasattr(attr_VotingClassifier_le_, 'tolist') else attr_VotingClassifier_le_`;
    })();
  }
  /**
    The classes labels.
   */
  get classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingClassifier must call init() before accessing classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_VotingClassifier_classes_ = bridgeVotingClassifier[${this.id}].classes_`;
      return this._py`attr_VotingClassifier_classes_.tolist() if hasattr(attr_VotingClassifier_classes_, 'tolist') else attr_VotingClassifier_classes_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying estimators expose such an attribute when fit.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This VotingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingClassifier must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_VotingClassifier_feature_names_in_ = bridgeVotingClassifier[${this.id}].feature_names_in_`;
      return this._py`attr_VotingClassifier_feature_names_in_.tolist() if hasattr(attr_VotingClassifier_feature_names_in_, 'tolist') else attr_VotingClassifier_feature_names_in_`;
    })();
  }
};

// src/generated/ensemble/VotingRegressor.ts
import crypto18 from "node:crypto";
var VotingRegressor = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `VotingRegressor${crypto18.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("VotingRegressor.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import VotingRegressor
try: bridgeVotingRegressor
except NameError: bridgeVotingRegressor = {}
`;
    await this._py.ex`ctor_VotingRegressor = {'estimators': ${this.opts["estimators"] ?? void 0}, 'weights': np.array(${this.opts["weights"] ?? void 0}) if ${this.opts["weights"] !== void 0} else None, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}}

ctor_VotingRegressor = {k: v for k, v in ctor_VotingRegressor.items() if v is not None}`;
    await this._py.ex`bridgeVotingRegressor[${this.id}] = VotingRegressor(**ctor_VotingRegressor)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeVotingRegressor[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Fit the estimators.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("VotingRegressor must call init() before fit()");
    }
    await this._py.ex`pms_VotingRegressor_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_VotingRegressor_fit = {k: v for k, v in pms_VotingRegressor_fit.items() if v is not None}`;
    await this._py.ex`res_VotingRegressor_fit = bridgeVotingRegressor[${this.id}].fit(**pms_VotingRegressor_fit)`;
    return this._py`res_VotingRegressor_fit.tolist() if hasattr(res_VotingRegressor_fit, 'tolist') else res_VotingRegressor_fit`;
  }
  /**
      Return class labels or probabilities for each estimator.
  
      Return predictions for X for each estimator.
     */
  async fit_transform(opts) {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("VotingRegressor must call init() before fit_transform()");
    }
    await this._py.ex`pms_VotingRegressor_fit_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'fit_params': ${opts["fit_params"] ?? void 0}}

pms_VotingRegressor_fit_transform = {k: v for k, v in pms_VotingRegressor_fit_transform.items() if v is not None}`;
    await this._py.ex`res_VotingRegressor_fit_transform = bridgeVotingRegressor[${this.id}].fit_transform(**pms_VotingRegressor_fit_transform)`;
    return this._py`res_VotingRegressor_fit_transform.tolist() if hasattr(res_VotingRegressor_fit_transform, 'tolist') else res_VotingRegressor_fit_transform`;
  }
  /**
    Get output feature names for transformation.
   */
  async get_feature_names_out(opts) {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingRegressor must call init() before get_feature_names_out()"
      );
    }
    await this._py.ex`pms_VotingRegressor_get_feature_names_out = {'input_features': ${opts["input_features"] ?? void 0}}

pms_VotingRegressor_get_feature_names_out = {k: v for k, v in pms_VotingRegressor_get_feature_names_out.items() if v is not None}`;
    await this._py.ex`res_VotingRegressor_get_feature_names_out = bridgeVotingRegressor[${this.id}].get_feature_names_out(**pms_VotingRegressor_get_feature_names_out)`;
    return this._py`res_VotingRegressor_get_feature_names_out.tolist() if hasattr(res_VotingRegressor_get_feature_names_out, 'tolist') else res_VotingRegressor_get_feature_names_out`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingRegressor must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_VotingRegressor_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_VotingRegressor_get_metadata_routing = {k: v for k, v in pms_VotingRegressor_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_VotingRegressor_get_metadata_routing = bridgeVotingRegressor[${this.id}].get_metadata_routing(**pms_VotingRegressor_get_metadata_routing)`;
    return this._py`res_VotingRegressor_get_metadata_routing.tolist() if hasattr(res_VotingRegressor_get_metadata_routing, 'tolist') else res_VotingRegressor_get_metadata_routing`;
  }
  /**
      Predict regression target for X.
  
      The predicted regression target of an input sample is computed as the mean predicted regression targets of the estimators in the ensemble.
     */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("VotingRegressor must call init() before predict()");
    }
    await this._py.ex`pms_VotingRegressor_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_VotingRegressor_predict = {k: v for k, v in pms_VotingRegressor_predict.items() if v is not None}`;
    await this._py.ex`res_VotingRegressor_predict = bridgeVotingRegressor[${this.id}].predict(**pms_VotingRegressor_predict)`;
    return this._py`res_VotingRegressor_predict.tolist() if hasattr(res_VotingRegressor_predict, 'tolist') else res_VotingRegressor_predict`;
  }
  /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("VotingRegressor must call init() before score()");
    }
    await this._py.ex`pms_VotingRegressor_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_VotingRegressor_score = {k: v for k, v in pms_VotingRegressor_score.items() if v is not None}`;
    await this._py.ex`res_VotingRegressor_score = bridgeVotingRegressor[${this.id}].score(**pms_VotingRegressor_score)`;
    return this._py`res_VotingRegressor_score.tolist() if hasattr(res_VotingRegressor_score, 'tolist') else res_VotingRegressor_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingRegressor must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_VotingRegressor_set_fit_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_VotingRegressor_set_fit_request = {k: v for k, v in pms_VotingRegressor_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_VotingRegressor_set_fit_request = bridgeVotingRegressor[${this.id}].set_fit_request(**pms_VotingRegressor_set_fit_request)`;
    return this._py`res_VotingRegressor_set_fit_request.tolist() if hasattr(res_VotingRegressor_set_fit_request, 'tolist') else res_VotingRegressor_set_fit_request`;
  }
  /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
  async set_output(opts) {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("VotingRegressor must call init() before set_output()");
    }
    await this._py.ex`pms_VotingRegressor_set_output = {'transform': ${opts["transform"] ?? void 0}}

pms_VotingRegressor_set_output = {k: v for k, v in pms_VotingRegressor_set_output.items() if v is not None}`;
    await this._py.ex`res_VotingRegressor_set_output = bridgeVotingRegressor[${this.id}].set_output(**pms_VotingRegressor_set_output)`;
    return this._py`res_VotingRegressor_set_output.tolist() if hasattr(res_VotingRegressor_set_output, 'tolist') else res_VotingRegressor_set_output`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingRegressor must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_VotingRegressor_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_VotingRegressor_set_score_request = {k: v for k, v in pms_VotingRegressor_set_score_request.items() if v is not None}`;
    await this._py.ex`res_VotingRegressor_set_score_request = bridgeVotingRegressor[${this.id}].set_score_request(**pms_VotingRegressor_set_score_request)`;
    return this._py`res_VotingRegressor_set_score_request.tolist() if hasattr(res_VotingRegressor_set_score_request, 'tolist') else res_VotingRegressor_set_score_request`;
  }
  /**
    Return predictions for X for each estimator.
   */
  async transform(opts) {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("VotingRegressor must call init() before transform()");
    }
    await this._py.ex`pms_VotingRegressor_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_VotingRegressor_transform = {k: v for k, v in pms_VotingRegressor_transform.items() if v is not None}`;
    await this._py.ex`res_VotingRegressor_transform = bridgeVotingRegressor[${this.id}].transform(**pms_VotingRegressor_transform)`;
    return this._py`res_VotingRegressor_transform.tolist() if hasattr(res_VotingRegressor_transform, 'tolist') else res_VotingRegressor_transform`;
  }
  /**
    The collection of fitted sub-estimators as defined in `estimators` that are not drop.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingRegressor must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_VotingRegressor_estimators_ = bridgeVotingRegressor[${this.id}].estimators_`;
      return this._py`attr_VotingRegressor_estimators_.tolist() if hasattr(attr_VotingRegressor_estimators_, 'tolist') else attr_VotingRegressor_estimators_`;
    })();
  }
  /**
    Attribute to access any fitted sub-estimators by name.
   */
  get named_estimators_() {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingRegressor must call init() before accessing named_estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_VotingRegressor_named_estimators_ = bridgeVotingRegressor[${this.id}].named_estimators_`;
      return this._py`attr_VotingRegressor_named_estimators_.tolist() if hasattr(attr_VotingRegressor_named_estimators_, 'tolist') else attr_VotingRegressor_named_estimators_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying estimators expose such an attribute when fit.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error("This VotingRegressor instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "VotingRegressor must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_VotingRegressor_feature_names_in_ = bridgeVotingRegressor[${this.id}].feature_names_in_`;
      return this._py`attr_VotingRegressor_feature_names_in_.tolist() if hasattr(attr_VotingRegressor_feature_names_in_, 'tolist') else attr_VotingRegressor_feature_names_in_`;
    })();
  }
};
export {
  AdaBoostClassifier,
  AdaBoostRegressor,
  BaggingClassifier,
  BaggingRegressor,
  ExtraTreesClassifier,
  ExtraTreesRegressor,
  GradientBoostingClassifier,
  GradientBoostingRegressor,
  HistGradientBoostingClassifier,
  HistGradientBoostingRegressor,
  IsolationForest,
  RandomForestClassifier,
  RandomForestRegressor,
  RandomTreesEmbedding,
  StackingClassifier,
  StackingRegressor,
  VotingClassifier,
  VotingRegressor
};
//# sourceMappingURL=index.js.map