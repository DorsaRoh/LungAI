// src/generated/ensemble/GradientBoostingClassifier.ts
import crypto from "node:crypto";
var GradientBoostingClassifier = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `GradientBoostingClassifier${crypto.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error(
        "GradientBoostingClassifier.init requires a PythonBridge instance"
      );
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier
try: bridgeGradientBoostingClassifier
except NameError: bridgeGradientBoostingClassifier = {}
`;
    await this._py.ex`ctor_GradientBoostingClassifier = {'loss': ${this.opts["loss"] ?? void 0}, 'learning_rate': ${this.opts["learning_rate"] ?? void 0}, 'n_estimators': ${this.opts["n_estimators"] ?? void 0}, 'subsample': ${this.opts["subsample"] ?? void 0}, 'criterion': ${this.opts["criterion"] ?? void 0}, 'min_samples_split': ${this.opts["min_samples_split"] ?? void 0}, 'min_samples_leaf': ${this.opts["min_samples_leaf"] ?? void 0}, 'min_weight_fraction_leaf': ${this.opts["min_weight_fraction_leaf"] ?? void 0}, 'max_depth': ${this.opts["max_depth"] ?? void 0}, 'min_impurity_decrease': ${this.opts["min_impurity_decrease"] ?? void 0}, 'init': ${this.opts["init"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'max_leaf_nodes': ${this.opts["max_leaf_nodes"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'validation_fraction': ${this.opts["validation_fraction"] ?? void 0}, 'n_iter_no_change': ${this.opts["n_iter_no_change"] ?? void 0}, 'tol': ${this.opts["tol"] ?? void 0}, 'ccp_alpha': ${this.opts["ccp_alpha"] ?? void 0}}

ctor_GradientBoostingClassifier = {k: v for k, v in ctor_GradientBoostingClassifier.items() if v is not None}`;
    await this._py.ex`bridgeGradientBoostingClassifier[${this.id}] = GradientBoostingClassifier(**ctor_GradientBoostingClassifier)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeGradientBoostingClassifier[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Apply trees in the ensemble to X, return leaf indices.
   */
  async apply(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before apply()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_apply = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_apply = {k: v for k, v in pms_GradientBoostingClassifier_apply.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_apply = bridgeGradientBoostingClassifier[${this.id}].apply(**pms_GradientBoostingClassifier_apply)`;
    return this._py`res_GradientBoostingClassifier_apply.tolist() if hasattr(res_GradientBoostingClassifier_apply, 'tolist') else res_GradientBoostingClassifier_apply`;
  }
  /**
    Compute the decision function of `X`.
   */
  async decision_function(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before decision_function()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_decision_function = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_decision_function = {k: v for k, v in pms_GradientBoostingClassifier_decision_function.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_decision_function = bridgeGradientBoostingClassifier[${this.id}].decision_function(**pms_GradientBoostingClassifier_decision_function)`;
    return this._py`res_GradientBoostingClassifier_decision_function.tolist() if hasattr(res_GradientBoostingClassifier_decision_function, 'tolist') else res_GradientBoostingClassifier_decision_function`;
  }
  /**
    Fit the gradient boosting model.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before fit()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None, 'monitor': ${opts["monitor"] ?? void 0}}

pms_GradientBoostingClassifier_fit = {k: v for k, v in pms_GradientBoostingClassifier_fit.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_fit = bridgeGradientBoostingClassifier[${this.id}].fit(**pms_GradientBoostingClassifier_fit)`;
    return this._py`res_GradientBoostingClassifier_fit.tolist() if hasattr(res_GradientBoostingClassifier_fit, 'tolist') else res_GradientBoostingClassifier_fit`;
  }
  /**
      Get metadata routing of this object.
  
      Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
     */
  async get_metadata_routing(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before get_metadata_routing()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_get_metadata_routing = {'routing': ${opts["routing"] ?? void 0}}

pms_GradientBoostingClassifier_get_metadata_routing = {k: v for k, v in pms_GradientBoostingClassifier_get_metadata_routing.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_get_metadata_routing = bridgeGradientBoostingClassifier[${this.id}].get_metadata_routing(**pms_GradientBoostingClassifier_get_metadata_routing)`;
    return this._py`res_GradientBoostingClassifier_get_metadata_routing.tolist() if hasattr(res_GradientBoostingClassifier_get_metadata_routing, 'tolist') else res_GradientBoostingClassifier_get_metadata_routing`;
  }
  /**
    Predict class for X.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before predict()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_predict = {k: v for k, v in pms_GradientBoostingClassifier_predict.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_predict = bridgeGradientBoostingClassifier[${this.id}].predict(**pms_GradientBoostingClassifier_predict)`;
    return this._py`res_GradientBoostingClassifier_predict.tolist() if hasattr(res_GradientBoostingClassifier_predict, 'tolist') else res_GradientBoostingClassifier_predict`;
  }
  /**
    Predict class log-probabilities for X.
   */
  async predict_log_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before predict_log_proba()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_predict_log_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_predict_log_proba = {k: v for k, v in pms_GradientBoostingClassifier_predict_log_proba.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_predict_log_proba = bridgeGradientBoostingClassifier[${this.id}].predict_log_proba(**pms_GradientBoostingClassifier_predict_log_proba)`;
    return this._py`res_GradientBoostingClassifier_predict_log_proba.tolist() if hasattr(res_GradientBoostingClassifier_predict_log_proba, 'tolist') else res_GradientBoostingClassifier_predict_log_proba`;
  }
  /**
    Predict class probabilities for X.
   */
  async predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before predict_proba()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_predict_proba = {k: v for k, v in pms_GradientBoostingClassifier_predict_proba.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_predict_proba = bridgeGradientBoostingClassifier[${this.id}].predict_proba(**pms_GradientBoostingClassifier_predict_proba)`;
    return this._py`res_GradientBoostingClassifier_predict_proba.tolist() if hasattr(res_GradientBoostingClassifier_predict_proba, 'tolist') else res_GradientBoostingClassifier_predict_proba`;
  }
  /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before score()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_GradientBoostingClassifier_score = {k: v for k, v in pms_GradientBoostingClassifier_score.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_score = bridgeGradientBoostingClassifier[${this.id}].score(**pms_GradientBoostingClassifier_score)`;
    return this._py`res_GradientBoostingClassifier_score.tolist() if hasattr(res_GradientBoostingClassifier_score, 'tolist') else res_GradientBoostingClassifier_score`;
  }
  /**
      Request metadata passed to the `fit` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_fit_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before set_fit_request()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_set_fit_request = {'monitor': ${opts["monitor"] ?? void 0}, 'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_GradientBoostingClassifier_set_fit_request = {k: v for k, v in pms_GradientBoostingClassifier_set_fit_request.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_set_fit_request = bridgeGradientBoostingClassifier[${this.id}].set_fit_request(**pms_GradientBoostingClassifier_set_fit_request)`;
    return this._py`res_GradientBoostingClassifier_set_fit_request.tolist() if hasattr(res_GradientBoostingClassifier_set_fit_request, 'tolist') else res_GradientBoostingClassifier_set_fit_request`;
  }
  /**
      Request metadata passed to the `score` method.
  
      Note that this method is only relevant if `enable\_metadata\_routing=True` (see [`sklearn.set\_config`](sklearn.set_config.html#sklearn.set_config "sklearn.set_config")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.
  
      The options for each parameter are:
     */
  async set_score_request(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before set_score_request()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_set_score_request = {'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_GradientBoostingClassifier_set_score_request = {k: v for k, v in pms_GradientBoostingClassifier_set_score_request.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_set_score_request = bridgeGradientBoostingClassifier[${this.id}].set_score_request(**pms_GradientBoostingClassifier_set_score_request)`;
    return this._py`res_GradientBoostingClassifier_set_score_request.tolist() if hasattr(res_GradientBoostingClassifier_set_score_request, 'tolist') else res_GradientBoostingClassifier_set_score_request`;
  }
  /**
      Compute decision function of `X` for each iteration.
  
      This method allows monitoring (i.e. determine error on testing set) after each stage.
     */
  async staged_decision_function(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before staged_decision_function()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_staged_decision_function = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_staged_decision_function = {k: v for k, v in pms_GradientBoostingClassifier_staged_decision_function.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_staged_decision_function = bridgeGradientBoostingClassifier[${this.id}].staged_decision_function(**pms_GradientBoostingClassifier_staged_decision_function)`;
    return this._py`res_GradientBoostingClassifier_staged_decision_function.tolist() if hasattr(res_GradientBoostingClassifier_staged_decision_function, 'tolist') else res_GradientBoostingClassifier_staged_decision_function`;
  }
  /**
      Predict class at each stage for X.
  
      This method allows monitoring (i.e. determine error on testing set) after each stage.
     */
  async staged_predict(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before staged_predict()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_staged_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_staged_predict = {k: v for k, v in pms_GradientBoostingClassifier_staged_predict.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_staged_predict = bridgeGradientBoostingClassifier[${this.id}].staged_predict(**pms_GradientBoostingClassifier_staged_predict)`;
    return this._py`res_GradientBoostingClassifier_staged_predict.tolist() if hasattr(res_GradientBoostingClassifier_staged_predict, 'tolist') else res_GradientBoostingClassifier_staged_predict`;
  }
  /**
      Predict class probabilities at each stage for X.
  
      This method allows monitoring (i.e. determine error on testing set) after each stage.
     */
  async staged_predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before staged_predict_proba()"
      );
    }
    await this._py.ex`pms_GradientBoostingClassifier_staged_predict_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_GradientBoostingClassifier_staged_predict_proba = {k: v for k, v in pms_GradientBoostingClassifier_staged_predict_proba.items() if v is not None}`;
    await this._py.ex`res_GradientBoostingClassifier_staged_predict_proba = bridgeGradientBoostingClassifier[${this.id}].staged_predict_proba(**pms_GradientBoostingClassifier_staged_predict_proba)`;
    return this._py`res_GradientBoostingClassifier_staged_predict_proba.tolist() if hasattr(res_GradientBoostingClassifier_staged_predict_proba, 'tolist') else res_GradientBoostingClassifier_staged_predict_proba`;
  }
  /**
    The number of estimators as selected by early stopping (if `n\_iter\_no\_change` is specified). Otherwise it is set to `n\_estimators`.
   */
  get n_estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing n_estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_n_estimators_ = bridgeGradientBoostingClassifier[${this.id}].n_estimators_`;
      return this._py`attr_GradientBoostingClassifier_n_estimators_.tolist() if hasattr(attr_GradientBoostingClassifier_n_estimators_, 'tolist') else attr_GradientBoostingClassifier_n_estimators_`;
    })();
  }
  /**
    The improvement in loss on the out-of-bag samples relative to the previous iteration. `oob\_improvement\_\[0\]` is the improvement in loss of the first stage over the `init` estimator. Only available if `subsample < 1.0`.
   */
  get oob_improvement_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing oob_improvement_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_oob_improvement_ = bridgeGradientBoostingClassifier[${this.id}].oob_improvement_`;
      return this._py`attr_GradientBoostingClassifier_oob_improvement_.tolist() if hasattr(attr_GradientBoostingClassifier_oob_improvement_, 'tolist') else attr_GradientBoostingClassifier_oob_improvement_`;
    })();
  }
  /**
    The full history of the loss values on the out-of-bag samples. Only available if `subsample < 1.0`.
   */
  get oob_scores_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing oob_scores_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_oob_scores_ = bridgeGradientBoostingClassifier[${this.id}].oob_scores_`;
      return this._py`attr_GradientBoostingClassifier_oob_scores_.tolist() if hasattr(attr_GradientBoostingClassifier_oob_scores_, 'tolist') else attr_GradientBoostingClassifier_oob_scores_`;
    })();
  }
  /**
    The last value of the loss on the out-of-bag samples. It is the same as `oob\_scores\_\[-1\]`. Only available if `subsample < 1.0`.
   */
  get oob_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing oob_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_oob_score_ = bridgeGradientBoostingClassifier[${this.id}].oob_score_`;
      return this._py`attr_GradientBoostingClassifier_oob_score_.tolist() if hasattr(attr_GradientBoostingClassifier_oob_score_, 'tolist') else attr_GradientBoostingClassifier_oob_score_`;
    })();
  }
  /**
    The i-th score `train\_score\_\[i\]` is the loss of the model at iteration `i` on the in-bag sample. If `subsample \== 1` this is the loss on the training data.
   */
  get train_score_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing train_score_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_train_score_ = bridgeGradientBoostingClassifier[${this.id}].train_score_`;
      return this._py`attr_GradientBoostingClassifier_train_score_.tolist() if hasattr(attr_GradientBoostingClassifier_train_score_, 'tolist') else attr_GradientBoostingClassifier_train_score_`;
    })();
  }
  /**
    The estimator that provides the initial predictions. Set via the `init` argument or `loss.init\_estimator`.
   */
  get init_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing init_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_init_ = bridgeGradientBoostingClassifier[${this.id}].init_`;
      return this._py`attr_GradientBoostingClassifier_init_.tolist() if hasattr(attr_GradientBoostingClassifier_init_, 'tolist') else attr_GradientBoostingClassifier_init_`;
    })();
  }
  /**
    The collection of fitted sub-estimators. `loss\_.K` is 1 for binary classification, otherwise n\_classes.
   */
  get estimators_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing estimators_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_estimators_ = bridgeGradientBoostingClassifier[${this.id}].estimators_`;
      return this._py`attr_GradientBoostingClassifier_estimators_.tolist() if hasattr(attr_GradientBoostingClassifier_estimators_, 'tolist') else attr_GradientBoostingClassifier_estimators_`;
    })();
  }
  /**
    The classes labels.
   */
  get classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_classes_ = bridgeGradientBoostingClassifier[${this.id}].classes_`;
      return this._py`attr_GradientBoostingClassifier_classes_.tolist() if hasattr(attr_GradientBoostingClassifier_classes_, 'tolist') else attr_GradientBoostingClassifier_classes_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_n_features_in_ = bridgeGradientBoostingClassifier[${this.id}].n_features_in_`;
      return this._py`attr_GradientBoostingClassifier_n_features_in_.tolist() if hasattr(attr_GradientBoostingClassifier_n_features_in_, 'tolist') else attr_GradientBoostingClassifier_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_feature_names_in_ = bridgeGradientBoostingClassifier[${this.id}].feature_names_in_`;
      return this._py`attr_GradientBoostingClassifier_feature_names_in_.tolist() if hasattr(attr_GradientBoostingClassifier_feature_names_in_, 'tolist') else attr_GradientBoostingClassifier_feature_names_in_`;
    })();
  }
  /**
    The number of classes.
   */
  get n_classes_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing n_classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_n_classes_ = bridgeGradientBoostingClassifier[${this.id}].n_classes_`;
      return this._py`attr_GradientBoostingClassifier_n_classes_.tolist() if hasattr(attr_GradientBoostingClassifier_n_classes_, 'tolist') else attr_GradientBoostingClassifier_n_classes_`;
    })();
  }
  /**
    The inferred value of max\_features.
   */
  get max_features_() {
    if (this._isDisposed) {
      throw new Error(
        "This GradientBoostingClassifier instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "GradientBoostingClassifier must call init() before accessing max_features_"
      );
    }
    return (async () => {
      await this._py.ex`attr_GradientBoostingClassifier_max_features_ = bridgeGradientBoostingClassifier[${this.id}].max_features_`;
      return this._py`attr_GradientBoostingClassifier_max_features_.tolist() if hasattr(attr_GradientBoostingClassifier_max_features_, 'tolist') else attr_GradientBoostingClassifier_max_features_`;
    })();
  }
};
export {
  GradientBoostingClassifier
};
//# sourceMappingURL=GradientBoostingClassifier.js.map