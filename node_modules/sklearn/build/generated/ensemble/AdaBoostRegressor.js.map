{"version":3,"sources":["../../../src/generated/ensemble/AdaBoostRegressor.ts"],"sourcesContent":["/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  An AdaBoost regressor.\n\n  An AdaBoost \\[1\\] regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. As such, subsequent regressors focus more on difficult cases.\n\n  This class implements the algorithm known as AdaBoost.R2 \\[2\\].\n\n  Read more in the [User Guide](../ensemble.html#adaboost).\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html)\n */\nexport class AdaBoostRegressor {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The base estimator from which the boosted ensemble is built. If `undefined`, then the base estimator is [`DecisionTreeRegressor`](sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor \"sklearn.tree.DecisionTreeRegressor\") initialized with `max\\_depth=3`.\n     */\n    estimator?: any\n\n    /**\n      The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early. Values must be in the range `\\[1, inf)`.\n\n      @defaultValue `50`\n     */\n    n_estimators?: number\n\n    /**\n      Weight applied to each regressor at each boosting iteration. A higher learning rate increases the contribution of each regressor. There is a trade-off between the `learning\\_rate` and `n\\_estimators` parameters. Values must be in the range `(0.0, inf)`.\n\n      @defaultValue `1`\n     */\n    learning_rate?: number\n\n    /**\n      The loss function to use when updating the weights after each boosting iteration.\n\n      @defaultValue `'linear'`\n     */\n    loss?: 'linear' | 'square' | 'exponential'\n\n    /**\n      Controls the random seed given at each `estimator` at each boosting iteration. Thus, it is only used when `estimator` exposes a `random\\_state`. In addition, it controls the bootstrap of the weights used to train the `estimator` at each boosting iteration. Pass an int for reproducible output across multiple function calls. See [Glossary](../../glossary.html#term-random_state).\n     */\n    random_state?: number\n\n    /**\n      The base estimator from which the boosted ensemble is built. If `undefined`, then the base estimator is [`DecisionTreeRegressor`](sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor \"sklearn.tree.DecisionTreeRegressor\") initialized with `max\\_depth=3`.\n     */\n    base_estimator?: any\n  }) {\n    this.id = `AdaBoostRegressor${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('AdaBoostRegressor.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.ensemble import AdaBoostRegressor\ntry: bridgeAdaBoostRegressor\nexcept NameError: bridgeAdaBoostRegressor = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_AdaBoostRegressor = {'estimator': ${\n      this.opts['estimator'] ?? undefined\n    }, 'n_estimators': ${\n      this.opts['n_estimators'] ?? undefined\n    }, 'learning_rate': ${this.opts['learning_rate'] ?? undefined}, 'loss': ${\n      this.opts['loss'] ?? undefined\n    }, 'random_state': ${\n      this.opts['random_state'] ?? undefined\n    }, 'base_estimator': ${this.opts['base_estimator'] ?? undefined}}\n\nctor_AdaBoostRegressor = {k: v for k, v in ctor_AdaBoostRegressor.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeAdaBoostRegressor[${this.id}] = AdaBoostRegressor(**ctor_AdaBoostRegressor)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeAdaBoostRegressor[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Build a boosted classifier/regressor from the training set (X, y).\n   */\n  async fit(opts: {\n    /**\n      The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n     */\n    X?: ArrayLike | SparseMatrix[]\n\n    /**\n      The target values.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights. If `undefined`, the sample weights are initialized to 1 / n\\_samples.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('AdaBoostRegressor must call init() before fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_AdaBoostRegressor_fit = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_AdaBoostRegressor_fit = {k: v for k, v in pms_AdaBoostRegressor_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_AdaBoostRegressor_fit = bridgeAdaBoostRegressor[${this.id}].fit(**pms_AdaBoostRegressor_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_AdaBoostRegressor_fit.tolist() if hasattr(res_AdaBoostRegressor_fit, 'tolist') else res_AdaBoostRegressor_fit`\n  }\n\n  /**\n    Get metadata routing of this object.\n\n    Please check [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.\n   */\n  async get_metadata_routing(opts: {\n    /**\n      A [`MetadataRequest`](sklearn.utils.metadata_routing.MetadataRequest.html#sklearn.utils.metadata_routing.MetadataRequest \"sklearn.utils.metadata_routing.MetadataRequest\") encapsulating routing information.\n     */\n    routing?: any\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'AdaBoostRegressor must call init() before get_metadata_routing()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_AdaBoostRegressor_get_metadata_routing = {'routing': ${\n      opts['routing'] ?? undefined\n    }}\n\npms_AdaBoostRegressor_get_metadata_routing = {k: v for k, v in pms_AdaBoostRegressor_get_metadata_routing.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_AdaBoostRegressor_get_metadata_routing = bridgeAdaBoostRegressor[${this.id}].get_metadata_routing(**pms_AdaBoostRegressor_get_metadata_routing)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_AdaBoostRegressor_get_metadata_routing.tolist() if hasattr(res_AdaBoostRegressor_get_metadata_routing, 'tolist') else res_AdaBoostRegressor_get_metadata_routing`\n  }\n\n  /**\n    Predict regression value for X.\n\n    The predicted regression value of an input sample is computed as the weighted median prediction of the regressors in the ensemble.\n   */\n  async predict(opts: {\n    /**\n      The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n     */\n    X?: ArrayLike | SparseMatrix[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('AdaBoostRegressor must call init() before predict()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_AdaBoostRegressor_predict = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_AdaBoostRegressor_predict = {k: v for k, v in pms_AdaBoostRegressor_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_AdaBoostRegressor_predict = bridgeAdaBoostRegressor[${this.id}].predict(**pms_AdaBoostRegressor_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_AdaBoostRegressor_predict.tolist() if hasattr(res_AdaBoostRegressor_predict, 'tolist') else res_AdaBoostRegressor_predict`\n  }\n\n  /**\n    Return the coefficient of determination of the prediction.\n\n    The coefficient of determination \\\\(R^2\\\\) is defined as \\\\((1 - \\\\frac{u}{v})\\\\), where \\\\(u\\\\) is the residual sum of squares `((y\\_true \\- y\\_pred)\\*\\* 2).sum()` and \\\\(v\\\\) is the total sum of squares `((y\\_true \\- y\\_true.mean()) \\*\\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\\\(R^2\\\\) score of 0.0.\n   */\n  async score(opts: {\n    /**\n      Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape `(n\\_samples, n\\_samples\\_fitted)`, where `n\\_samples\\_fitted` is the number of samples used in the fitting for the estimator.\n     */\n    X?: ArrayLike[]\n\n    /**\n      True values for `X`.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('AdaBoostRegressor must call init() before score()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_AdaBoostRegressor_score = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_AdaBoostRegressor_score = {k: v for k, v in pms_AdaBoostRegressor_score.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_AdaBoostRegressor_score = bridgeAdaBoostRegressor[${this.id}].score(**pms_AdaBoostRegressor_score)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_AdaBoostRegressor_score.tolist() if hasattr(res_AdaBoostRegressor_score, 'tolist') else res_AdaBoostRegressor_score`\n  }\n\n  /**\n    Request metadata passed to the `fit` method.\n\n    Note that this method is only relevant if `enable\\_metadata\\_routing=True` (see [`sklearn.set\\_config`](sklearn.set_config.html#sklearn.set_config \"sklearn.set_config\")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.\n\n    The options for each parameter are:\n   */\n  async set_fit_request(opts: {\n    /**\n      Metadata routing for `sample\\_weight` parameter in `fit`.\n     */\n    sample_weight?: string | boolean\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'AdaBoostRegressor must call init() before set_fit_request()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_AdaBoostRegressor_set_fit_request = {'sample_weight': ${\n      opts['sample_weight'] ?? undefined\n    }}\n\npms_AdaBoostRegressor_set_fit_request = {k: v for k, v in pms_AdaBoostRegressor_set_fit_request.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_AdaBoostRegressor_set_fit_request = bridgeAdaBoostRegressor[${this.id}].set_fit_request(**pms_AdaBoostRegressor_set_fit_request)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_AdaBoostRegressor_set_fit_request.tolist() if hasattr(res_AdaBoostRegressor_set_fit_request, 'tolist') else res_AdaBoostRegressor_set_fit_request`\n  }\n\n  /**\n    Request metadata passed to the `score` method.\n\n    Note that this method is only relevant if `enable\\_metadata\\_routing=True` (see [`sklearn.set\\_config`](sklearn.set_config.html#sklearn.set_config \"sklearn.set_config\")). Please see [User Guide](../../metadata_routing.html#metadata-routing) on how the routing mechanism works.\n\n    The options for each parameter are:\n   */\n  async set_score_request(opts: {\n    /**\n      Metadata routing for `sample\\_weight` parameter in `score`.\n     */\n    sample_weight?: string | boolean\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'AdaBoostRegressor must call init() before set_score_request()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_AdaBoostRegressor_set_score_request = {'sample_weight': ${\n      opts['sample_weight'] ?? undefined\n    }}\n\npms_AdaBoostRegressor_set_score_request = {k: v for k, v in pms_AdaBoostRegressor_set_score_request.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_AdaBoostRegressor_set_score_request = bridgeAdaBoostRegressor[${this.id}].set_score_request(**pms_AdaBoostRegressor_set_score_request)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_AdaBoostRegressor_set_score_request.tolist() if hasattr(res_AdaBoostRegressor_set_score_request, 'tolist') else res_AdaBoostRegressor_set_score_request`\n  }\n\n  /**\n    Return staged predictions for X.\n\n    The predicted regression value of an input sample is computed as the weighted median prediction of the regressors in the ensemble.\n\n    This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.\n   */\n  async staged_predict(opts: {\n    /**\n      The training input samples.\n     */\n    X?: ArrayLike | SparseMatrix[]\n  }): Promise<any[]> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'AdaBoostRegressor must call init() before staged_predict()'\n      )\n    }\n\n    // set up method params\n    await this._py.ex`pms_AdaBoostRegressor_staged_predict = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_AdaBoostRegressor_staged_predict = {k: v for k, v in pms_AdaBoostRegressor_staged_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_AdaBoostRegressor_staged_predict = bridgeAdaBoostRegressor[${this.id}].staged_predict(**pms_AdaBoostRegressor_staged_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_AdaBoostRegressor_staged_predict.tolist() if hasattr(res_AdaBoostRegressor_staged_predict, 'tolist') else res_AdaBoostRegressor_staged_predict`\n  }\n\n  /**\n    Return staged scores for X, y.\n\n    This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.\n   */\n  async staged_score(opts: {\n    /**\n      The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n     */\n    X?: ArrayLike | SparseMatrix[]\n\n    /**\n      Labels for X.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'AdaBoostRegressor must call init() before staged_score()'\n      )\n    }\n\n    // set up method params\n    await this._py.ex`pms_AdaBoostRegressor_staged_score = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_AdaBoostRegressor_staged_score = {k: v for k, v in pms_AdaBoostRegressor_staged_score.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_AdaBoostRegressor_staged_score = bridgeAdaBoostRegressor[${this.id}].staged_score(**pms_AdaBoostRegressor_staged_score)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_AdaBoostRegressor_staged_score.tolist() if hasattr(res_AdaBoostRegressor_staged_score, 'tolist') else res_AdaBoostRegressor_staged_score`\n  }\n\n  /**\n    The base estimator from which the ensemble is grown.\n   */\n  get estimator_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'AdaBoostRegressor must call init() before accessing estimator_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_AdaBoostRegressor_estimator_ = bridgeAdaBoostRegressor[${this.id}].estimator_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_AdaBoostRegressor_estimator_.tolist() if hasattr(attr_AdaBoostRegressor_estimator_, 'tolist') else attr_AdaBoostRegressor_estimator_`\n    })()\n  }\n\n  /**\n    The collection of fitted sub-estimators.\n   */\n  get estimators_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'AdaBoostRegressor must call init() before accessing estimators_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_AdaBoostRegressor_estimators_ = bridgeAdaBoostRegressor[${this.id}].estimators_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_AdaBoostRegressor_estimators_.tolist() if hasattr(attr_AdaBoostRegressor_estimators_, 'tolist') else attr_AdaBoostRegressor_estimators_`\n    })()\n  }\n\n  /**\n    Weights for each estimator in the boosted ensemble.\n   */\n  get estimator_weights_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'AdaBoostRegressor must call init() before accessing estimator_weights_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_AdaBoostRegressor_estimator_weights_ = bridgeAdaBoostRegressor[${this.id}].estimator_weights_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_AdaBoostRegressor_estimator_weights_.tolist() if hasattr(attr_AdaBoostRegressor_estimator_weights_, 'tolist') else attr_AdaBoostRegressor_estimator_weights_`\n    })()\n  }\n\n  /**\n    Regression error for each estimator in the boosted ensemble.\n   */\n  get estimator_errors_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'AdaBoostRegressor must call init() before accessing estimator_errors_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_AdaBoostRegressor_estimator_errors_ = bridgeAdaBoostRegressor[${this.id}].estimator_errors_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_AdaBoostRegressor_estimator_errors_.tolist() if hasattr(attr_AdaBoostRegressor_estimator_errors_, 'tolist') else attr_AdaBoostRegressor_estimator_errors_`\n    })()\n  }\n\n  /**\n    Number of features seen during [fit](../../glossary.html#term-fit).\n   */\n  get n_features_in_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'AdaBoostRegressor must call init() before accessing n_features_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_AdaBoostRegressor_n_features_in_ = bridgeAdaBoostRegressor[${this.id}].n_features_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_AdaBoostRegressor_n_features_in_.tolist() if hasattr(attr_AdaBoostRegressor_n_features_in_, 'tolist') else attr_AdaBoostRegressor_n_features_in_`\n    })()\n  }\n\n  /**\n    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.\n   */\n  get feature_names_in_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This AdaBoostRegressor instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'AdaBoostRegressor must call init() before accessing feature_names_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_AdaBoostRegressor_feature_names_in_ = bridgeAdaBoostRegressor[${this.id}].feature_names_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_AdaBoostRegressor_feature_names_in_.tolist() if hasattr(attr_AdaBoostRegressor_feature_names_in_, 'tolist') else attr_AdaBoostRegressor_feature_names_in_`\n    })()\n  }\n}\n"],"mappings":";AAGA,OAAO,YAAY;AAeZ,IAAM,oBAAN,MAAwB;AAAA,EAQ7B,YAAY,MAoCT;AAvCH,0BAA0B;AAC1B,uBAAuB;AAuCrB,SAAK,KAAK,oBAAoB,OAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC9D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,yDAAyD;AAAA,IAC3E;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,4CACb,KAAK,KAAK,WAAW,KAAK,2BAE1B,KAAK,KAAK,cAAc,KAAK,4BACT,KAAK,KAAK,eAAe,KAAK,mBAClD,KAAK,KAAK,MAAM,KAAK,2BAErB,KAAK,KAAK,cAAc,KAAK,6BACR,KAAK,KAAK,gBAAgB,KAAK;AAAA;AAAA;AAItD,UAAM,KAAK,IACR,6BAA6B,KAAK;AAErC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,iCAAiC,KAAK;AAErD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,IAAI,MAeO;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACnE;AAGA,UAAM,KAAK,IAAI,gDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,yDAAyD,KAAK;AAGjE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,qBAAqB,MAKV;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,8DACD,KAAK,SAAS,KAAK;AAAA;AAAA;AAMrB,UAAM,KAAK,IACR,0EAA0E,KAAK;AAGlF,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,QAAQ,MAKO;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAGA,UAAM,KAAK,IAAI,oDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,6DAA6D,KAAK;AAGrE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,MAAM,MAeQ;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAGA,UAAM,KAAK,IAAI,kDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,2DAA2D,KAAK;AAGnE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,gBAAgB,MAKL;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,+DACD,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,qEAAqE,KAAK;AAG7E,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,kBAAkB,MAKP;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,iEACD,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,uEAAuE,KAAK;AAG/E,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,eAAe,MAKF;AACjB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IAAI,2DACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,oEAAoE,KAAK;AAG5E,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,aAAa,MAeC;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IAAI,yDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,kEAAkE,KAAK;AAG1E,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,aAA2B;AAC7B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,iEAAiE,KAAK;AAGzE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,cAA4B;AAC9B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,kEAAkE,KAAK;AAG1E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,qBAAmC;AACrC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,yEAAyE,KAAK;AAGjF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAkC;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,wEAAwE,KAAK;AAGhF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iBAAkC;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,qEAAqE,KAAK;AAG7E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAsC;AACxC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,wEAAwE,KAAK;AAGhF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;","names":[]}